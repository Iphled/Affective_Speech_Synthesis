{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-09T22:20:43.142458Z",
     "start_time": "2024-11-09T22:20:40.420128Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/BERT_training_data.csv\")\n",
    "df"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                     text emotions\n",
       "0       i feel awful about it too because it s my job ...  sadness\n",
       "1                                   im alone i feel awful  sadness\n",
       "2       ive probably mentioned this before but i reall...      joy\n",
       "3                i was feeling a little low few days back  sadness\n",
       "4       i am one of those people who feels like going ...      joy\n",
       "...                                                   ...      ...\n",
       "367278  that was what i felt when i was finally accept...      joy\n",
       "367279  i take every day as it comes i m just focussin...     fear\n",
       "367280      i just suddenly feel that everything was fake  sadness\n",
       "367281  im feeling more eager than ever to claw back w...      joy\n",
       "367282  i give you plenty of attention even when i fee...  sadness\n",
       "\n",
       "[367283 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i feel awful about it too because it s my job ...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>im alone i feel awful</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ive probably mentioned this before but i reall...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i was feeling a little low few days back</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am one of those people who feels like going ...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367278</th>\n",
       "      <td>that was what i felt when i was finally accept...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367279</th>\n",
       "      <td>i take every day as it comes i m just focussin...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367280</th>\n",
       "      <td>i just suddenly feel that everything was fake</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367281</th>\n",
       "      <td>im feeling more eager than ever to claw back w...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367282</th>\n",
       "      <td>i give you plenty of attention even when i fee...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>367283 rows Ã— 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T13:45:43.020771Z",
     "start_time": "2024-11-10T13:45:19.055068Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import transformers\n",
    "from transformers import AutoModel, BertTokenizerFast\n",
    "\n",
    "device = torch.device(\"cuda\")"
   ],
   "id": "2532a70fcc11e62f",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T13:47:55.617948Z",
     "start_time": "2024-11-10T13:45:46.331073Z"
    }
   },
   "cell_type": "code",
   "source": [
    "bert = AutoModel.from_pretrained('bert-base-uncased')\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n"
   ],
   "id": "76441b9e8b24aea1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "688b69dee63541d09bacd7701dfc618b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Julia Rennert\\miniconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:159: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Julia Rennert\\.cache\\huggingface\\hub\\models--bert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "eecf346b1f9c48e2bf48d9349665e671"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "976cfcb372e84ec1ae15d8690a7dc9b1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "391ecbb786034c269b00dfdf3d4d8d0a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a103c08487b64dc4befc1660e08e9231"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T13:59:20.765137Z",
     "start_time": "2024-11-10T13:59:15.600186Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/BERT_training_data.csv\")\n",
    "df"
   ],
   "id": "c5e606e7277efa89",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                     text  emotions\n",
       "0       i feel awful about it too because it s my job ...         3\n",
       "1                                   im alone i feel awful         3\n",
       "2       ive probably mentioned this before but i reall...         2\n",
       "3                i was feeling a little low few days back         3\n",
       "4       i am one of those people who feels like going ...         2\n",
       "...                                                   ...       ...\n",
       "367278  that was what i felt when i was finally accept...         2\n",
       "367279  i take every day as it comes i m just focussin...         1\n",
       "367280      i just suddenly feel that everything was fake         3\n",
       "367281  im feeling more eager than ever to claw back w...         2\n",
       "367282  i give you plenty of attention even when i fee...         3\n",
       "\n",
       "[367283 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i feel awful about it too because it s my job ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>im alone i feel awful</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ive probably mentioned this before but i reall...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i was feeling a little low few days back</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am one of those people who feels like going ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367278</th>\n",
       "      <td>that was what i felt when i was finally accept...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367279</th>\n",
       "      <td>i take every day as it comes i m just focussin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367280</th>\n",
       "      <td>i just suddenly feel that everything was fake</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367281</th>\n",
       "      <td>im feeling more eager than ever to claw back w...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367282</th>\n",
       "      <td>i give you plenty of attention even when i fee...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>367283 rows Ã— 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T13:59:26.235059Z",
     "start_time": "2024-11-10T13:59:25.834224Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_text, temp_text, train_labels, temp_labels = train_test_split(df['text'],\n",
    "                                                                    df['emotions'], \n",
    "                                                                    random_state=2018, \n",
    "                                                                    test_size=0.3, \n",
    "                                                                    stratify=df['emotions'])\n",
    "\n",
    "val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels, \n",
    "                                                                random_state=2018, \n",
    "                                                                test_size=0.5, \n",
    "                                                                stratify=temp_labels)"
   ],
   "id": "801a229aa73565ad",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T13:59:52.908410Z",
     "start_time": "2024-11-10T13:59:47.023190Z"
    }
   },
   "cell_type": "code",
   "source": [
    "seq_len = [len(i.split()) for i in train_text]\n",
    "\n",
    "pd.Series(seq_len).hist(bins = 30)"
   ],
   "id": "82b53b3f21160a65",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T14:01:38.356414Z",
     "start_time": "2024-11-10T14:00:26.931307Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokens_train = tokenizer.batch_encode_plus(\n",
    "    train_text.tolist(),\n",
    "    max_length = 25,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True\n",
    ")\n",
    "\n",
    "# tokenize and encode sequences in the validation set\n",
    "tokens_val = tokenizer.batch_encode_plus(\n",
    "    val_text.tolist(),\n",
    "    max_length = 25,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True\n",
    ")\n",
    "\n",
    "# tokenize and encode sequences in the test set\n",
    "tokens_test = tokenizer.batch_encode_plus(\n",
    "    test_text.tolist(),\n",
    "    max_length = 25,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True\n",
    ")"
   ],
   "id": "cdd57637f02c1611",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Julia Rennert\\miniconda3\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2829: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T14:03:53.674553Z",
     "start_time": "2024-11-10T14:03:46.979904Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_seq = torch.tensor(tokens_train['input_ids'])\n",
    "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
    "train_y = torch.tensor(train_labels.tolist())\n",
    "\n",
    "val_seq = torch.tensor(tokens_val['input_ids'])\n",
    "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
    "val_y = torch.tensor(val_labels.tolist())\n",
    "\n",
    "test_seq = torch.tensor(tokens_test['input_ids'])\n",
    "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
    "test_y = torch.tensor(test_labels.tolist())"
   ],
   "id": "a2da6529d8a432ff",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T14:04:42.489999Z",
     "start_time": "2024-11-10T14:04:41.516956Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "#define a batch size\n",
    "batch_size = 32\n",
    "\n",
    "# wrap tensors\n",
    "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
    "\n",
    "# sampler for sampling the data during training\n",
    "train_sampler = RandomSampler(train_data)\n",
    "\n",
    "# dataLoader for train set\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# wrap tensors\n",
    "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
    "\n",
    "# sampler for sampling the data during training\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "\n",
    "# dataLoader for validation set\n",
    "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)"
   ],
   "id": "d9f360219a624f45",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T14:05:27.936035Z",
     "start_time": "2024-11-10T14:05:27.901166Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for param in bert.parameters():\n",
    "    param.requires_grad = False"
   ],
   "id": "61bec48e3db8e6c8",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T14:05:59.285048Z",
     "start_time": "2024-11-10T14:05:58.680104Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class BERT_Arch(nn.Module):\n",
    "\n",
    "    def __init__(self, bert):\n",
    "        super(BERT_Arch, self).__init__()\n",
    "        \n",
    "        self.bert = bert \n",
    "        \n",
    "        # dropout layer\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "      \n",
    "        # relu activation function\n",
    "        self.relu =  nn.ReLU()\n",
    "\n",
    "        # dense layer 1\n",
    "        self.fc1 = nn.Linear(768,512)\n",
    "      \n",
    "        # dense layer 2 (Output layer)\n",
    "        self.fc2 = nn.Linear(512,2)\n",
    "\n",
    "        #softmax activation function\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    #define the forward pass\n",
    "    def forward(self, sent_id, mask):\n",
    "        \n",
    "        #pass the inputs to the model  \n",
    "        _, cls_hs = self.bert(sent_id, attention_mask=mask, return_dict=False)\n",
    "      \n",
    "        x = self.fc1(cls_hs)\n",
    "\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # output layer\n",
    "        x = self.fc2(x)\n",
    "      \n",
    "        # apply softmax activation\n",
    "        x = self.softmax(x)\n",
    "\n",
    "        return x"
   ],
   "id": "7e6f6f77a005448c",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T15:16:13.890484Z",
     "start_time": "2024-11-10T15:16:13.877483Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ],
   "id": "45249dbc99f23a90",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T15:16:24.590805Z",
     "start_time": "2024-11-10T15:16:21.843785Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = BERT_Arch(bert)\n",
    "\n",
    "# push the model to GPU\n",
    "model = model.to(device)"
   ],
   "id": "f74a45a31c18e22a",
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[25], line 4\u001B[0m\n\u001B[0;32m      1\u001B[0m model \u001B[38;5;241m=\u001B[39m BERT_Arch(bert)\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m# push the model to GPU\u001B[39;00m\n\u001B[1;32m----> 4\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1173\u001B[0m, in \u001B[0;36mModule.to\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1170\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1171\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m\n\u001B[1;32m-> 1173\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconvert\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:779\u001B[0m, in \u001B[0;36mModule._apply\u001B[1;34m(self, fn, recurse)\u001B[0m\n\u001B[0;32m    777\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m recurse:\n\u001B[0;32m    778\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren():\n\u001B[1;32m--> 779\u001B[0m         \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    781\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[0;32m    782\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[0;32m    783\u001B[0m         \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[0;32m    784\u001B[0m         \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    789\u001B[0m         \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[0;32m    790\u001B[0m         \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:779\u001B[0m, in \u001B[0;36mModule._apply\u001B[1;34m(self, fn, recurse)\u001B[0m\n\u001B[0;32m    777\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m recurse:\n\u001B[0;32m    778\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren():\n\u001B[1;32m--> 779\u001B[0m         \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    781\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[0;32m    782\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[0;32m    783\u001B[0m         \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[0;32m    784\u001B[0m         \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    789\u001B[0m         \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[0;32m    790\u001B[0m         \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:779\u001B[0m, in \u001B[0;36mModule._apply\u001B[1;34m(self, fn, recurse)\u001B[0m\n\u001B[0;32m    777\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m recurse:\n\u001B[0;32m    778\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren():\n\u001B[1;32m--> 779\u001B[0m         \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    781\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[0;32m    782\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[0;32m    783\u001B[0m         \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[0;32m    784\u001B[0m         \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    789\u001B[0m         \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[0;32m    790\u001B[0m         \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:804\u001B[0m, in \u001B[0;36mModule._apply\u001B[1;34m(self, fn, recurse)\u001B[0m\n\u001B[0;32m    800\u001B[0m \u001B[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001B[39;00m\n\u001B[0;32m    801\u001B[0m \u001B[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001B[39;00m\n\u001B[0;32m    802\u001B[0m \u001B[38;5;66;03m# `with torch.no_grad():`\u001B[39;00m\n\u001B[0;32m    803\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[1;32m--> 804\u001B[0m     param_applied \u001B[38;5;241m=\u001B[39m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparam\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    805\u001B[0m p_should_use_set_data \u001B[38;5;241m=\u001B[39m compute_should_use_set_data(param, param_applied)\n\u001B[0;32m    807\u001B[0m \u001B[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1159\u001B[0m, in \u001B[0;36mModule.to.<locals>.convert\u001B[1;34m(t)\u001B[0m\n\u001B[0;32m   1152\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m convert_to_format \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m t\u001B[38;5;241m.\u001B[39mdim() \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;241m4\u001B[39m, \u001B[38;5;241m5\u001B[39m):\n\u001B[0;32m   1153\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m t\u001B[38;5;241m.\u001B[39mto(\n\u001B[0;32m   1154\u001B[0m             device,\n\u001B[0;32m   1155\u001B[0m             dtype \u001B[38;5;28;01mif\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_floating_point() \u001B[38;5;129;01mor\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_complex() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   1156\u001B[0m             non_blocking,\n\u001B[0;32m   1157\u001B[0m             memory_format\u001B[38;5;241m=\u001B[39mconvert_to_format,\n\u001B[0;32m   1158\u001B[0m         )\n\u001B[1;32m-> 1159\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1160\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1161\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mis_floating_point\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mis_complex\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m   1162\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnon_blocking\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1163\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1164\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m   1165\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mstr\u001B[39m(e) \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot copy out of meta tensor; no data!\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\torch\\cuda\\__init__.py:284\u001B[0m, in \u001B[0;36m_lazy_init\u001B[1;34m()\u001B[0m\n\u001B[0;32m    279\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[0;32m    280\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    281\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmultiprocessing, you must use the \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mspawn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m start method\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    282\u001B[0m     )\n\u001B[0;32m    283\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(torch\u001B[38;5;241m.\u001B[39m_C, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_cuda_getDeviceCount\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m--> 284\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTorch not compiled with CUDA enabled\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    285\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _cudart \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    286\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\n\u001B[0;32m    287\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    288\u001B[0m     )\n",
      "\u001B[1;31mAssertionError\u001B[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "execution_count": 25
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
