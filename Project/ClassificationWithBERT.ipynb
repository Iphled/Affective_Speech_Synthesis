{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-09T22:20:43.142458Z",
     "start_time": "2024-11-09T22:20:40.420128Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/BERT_training_data.csv\")\n",
    "df"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                     text emotions\n",
       "0       i feel awful about it too because it s my job ...  sadness\n",
       "1                                   im alone i feel awful  sadness\n",
       "2       ive probably mentioned this before but i reall...      joy\n",
       "3                i was feeling a little low few days back  sadness\n",
       "4       i am one of those people who feels like going ...      joy\n",
       "...                                                   ...      ...\n",
       "367278  that was what i felt when i was finally accept...      joy\n",
       "367279  i take every day as it comes i m just focussin...     fear\n",
       "367280      i just suddenly feel that everything was fake  sadness\n",
       "367281  im feeling more eager than ever to claw back w...      joy\n",
       "367282  i give you plenty of attention even when i fee...  sadness\n",
       "\n",
       "[367283 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i feel awful about it too because it s my job ...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>im alone i feel awful</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ive probably mentioned this before but i reall...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i was feeling a little low few days back</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am one of those people who feels like going ...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367278</th>\n",
       "      <td>that was what i felt when i was finally accept...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367279</th>\n",
       "      <td>i take every day as it comes i m just focussin...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367280</th>\n",
       "      <td>i just suddenly feel that everything was fake</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367281</th>\n",
       "      <td>im feeling more eager than ever to claw back w...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367282</th>\n",
       "      <td>i give you plenty of attention even when i fee...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>367283 rows Ã— 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T22:55:35.771098Z",
     "start_time": "2024-11-09T22:55:29.576792Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')"
   ],
   "id": "2532a70fcc11e62f",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T22:55:39.555581Z",
     "start_time": "2024-11-09T22:55:39.541812Z"
    }
   },
   "cell_type": "code",
   "source": [
    "bert_model_name = 'small_bert/bert_en_uncased_L-4_H-512_A-8' \n",
    "\n",
    "map_name_to_handle = {\n",
    "    'bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3',\n",
    "    'bert_en_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/3',\n",
    "    'bert_multi_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-768_A-12/1',\n",
    "    'albert_en_base':\n",
    "        'https://tfhub.dev/tensorflow/albert_en_base/2',\n",
    "    'electra_small':\n",
    "        'https://tfhub.dev/google/electra_small/2',\n",
    "    'electra_base':\n",
    "        'https://tfhub.dev/google/electra_base/2',\n",
    "    'experts_pubmed':\n",
    "        'https://tfhub.dev/google/experts/bert/pubmed/2',\n",
    "    'experts_wiki_books':\n",
    "        'https://tfhub.dev/google/experts/bert/wiki_books/2',\n",
    "    'talking-heads_base':\n",
    "        'https://tfhub.dev/tensorflow/talkheads_ggelu_bert_en_base/1',\n",
    "}\n",
    "\n",
    "map_model_to_preprocess = {\n",
    "    'bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'bert_en_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_cased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'bert_multi_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3',\n",
    "    'albert_en_base':\n",
    "        'https://tfhub.dev/tensorflow/albert_en_preprocess/3',\n",
    "    'electra_small':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'electra_base':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'experts_pubmed':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'experts_wiki_books':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'talking-heads_base':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "}\n",
    "\n",
    "tfhub_handle_encoder = map_name_to_handle[bert_model_name]\n",
    "tfhub_handle_preprocess = map_model_to_preprocess[bert_model_name]\n"
   ],
   "id": "76441b9e8b24aea1",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T22:56:11.476675Z",
     "start_time": "2024-11-09T22:56:11.470148Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "print(f'BERT model selected           : {tfhub_handle_encoder}')\n",
    "print(f'Preprocess model auto-selected: {tfhub_handle_preprocess}')"
   ],
   "id": "801a229aa73565ad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT model selected           : https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n",
      "Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "import tensorflow_text as text",
   "id": "82b53b3f21160a65"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T22:57:34.467104Z",
     "start_time": "2024-11-09T22:57:11.340326Z"
    }
   },
   "cell_type": "code",
   "source": "bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)",
   "id": "cdd57637f02c1611",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Op type not registered 'CaseFoldUTF8' in binary running on JULIALAPTOP2017. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib (e.g. `tf.contrib.resampler`), accessing should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:3080\u001B[0m, in \u001B[0;36mGraph.op_def_for_type\u001B[1;34m(self, type)\u001B[0m\n\u001B[0;32m   3079\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 3080\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_op_def_cache\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mtype\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[0;32m   3081\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m:\n",
      "\u001B[1;31mKeyError\u001B[0m: 'CaseFoldUTF8'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[12], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m bert_preprocess_model \u001B[38;5;241m=\u001B[39m \u001B[43mhub\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mKerasLayer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtfhub_handle_preprocess\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\tensorflow_hub\\keras_layer.py:165\u001B[0m, in \u001B[0;36mKerasLayer.__init__\u001B[1;34m(self, handle, trainable, arguments, _sentinel, tags, signature, signature_outputs_as_dict, output_key, output_shape, load_options, **kwargs)\u001B[0m\n\u001B[0;32m    161\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_output_shape \u001B[38;5;241m=\u001B[39m data_structures\u001B[38;5;241m.\u001B[39mNoDependency(\n\u001B[0;32m    162\u001B[0m       _convert_nest_to_shapes(output_shape))\n\u001B[0;32m    164\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_load_options \u001B[38;5;241m=\u001B[39m load_options\n\u001B[1;32m--> 165\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_func \u001B[38;5;241m=\u001B[39m \u001B[43mload_module\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtags\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_load_options\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    166\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_is_hub_module_v1 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_func, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_is_hub_module_v1\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m    168\u001B[0m \u001B[38;5;66;03m# Update with the defaults when using legacy TF1 Hub format.\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\tensorflow_hub\\keras_layer.py:467\u001B[0m, in \u001B[0;36mload_module\u001B[1;34m(handle, tags, load_options)\u001B[0m\n\u001B[0;32m    465\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m:  \u001B[38;5;66;03m# Expected before TF2.4.\u001B[39;00m\n\u001B[0;32m    466\u001B[0m       set_load_options \u001B[38;5;241m=\u001B[39m load_options\n\u001B[1;32m--> 467\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmodule_v2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtags\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtags\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mset_load_options\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\tensorflow_hub\\module_v2.py:126\u001B[0m, in \u001B[0;36mload\u001B[1;34m(handle, tags, options)\u001B[0m\n\u001B[0;32m    123\u001B[0m   obj \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mcompat\u001B[38;5;241m.\u001B[39mv1\u001B[38;5;241m.\u001B[39msaved_model\u001B[38;5;241m.\u001B[39mload_v2(\n\u001B[0;32m    124\u001B[0m       module_path, tags\u001B[38;5;241m=\u001B[39mtags, options\u001B[38;5;241m=\u001B[39moptions)\n\u001B[0;32m    125\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 126\u001B[0m   obj \u001B[38;5;241m=\u001B[39m \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompat\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mv1\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msaved_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_v2\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodule_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtags\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtags\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    127\u001B[0m obj\u001B[38;5;241m.\u001B[39m_is_hub_module_v1 \u001B[38;5;241m=\u001B[39m is_hub_module_v1  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[0;32m    128\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m obj\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\saved_model\\load.py:912\u001B[0m, in \u001B[0;36mload\u001B[1;34m(export_dir, tags, options)\u001B[0m\n\u001B[0;32m    910\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(export_dir, os\u001B[38;5;241m.\u001B[39mPathLike):\n\u001B[0;32m    911\u001B[0m   export_dir \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mfspath(export_dir)\n\u001B[1;32m--> 912\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mload_partial\u001B[49m\u001B[43m(\u001B[49m\u001B[43mexport_dir\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtags\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptions\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mroot\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m    913\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\saved_model\\load.py:1042\u001B[0m, in \u001B[0;36mload_partial\u001B[1;34m(export_dir, filters, tags, options)\u001B[0m\n\u001B[0;32m   1040\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m ops\u001B[38;5;241m.\u001B[39minit_scope():\n\u001B[0;32m   1041\u001B[0m   \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1042\u001B[0m     loader \u001B[38;5;241m=\u001B[39m \u001B[43mLoader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobject_graph_proto\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msaved_model_proto\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexport_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1043\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mckpt_options\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfilters\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1044\u001B[0m   \u001B[38;5;28;01mexcept\u001B[39;00m errors\u001B[38;5;241m.\u001B[39mNotFoundError \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[0;32m   1045\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mFileNotFoundError\u001B[39;00m(\n\u001B[0;32m   1046\u001B[0m         \u001B[38;5;28mstr\u001B[39m(err) \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m You may be trying to load on a different device \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1047\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfrom the computational device. Consider setting the \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1048\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`experimental_io_device` option in `tf.saved_model.LoadOptions` \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1049\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mto the io_device such as \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/job:localhost\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\saved_model\\load.py:161\u001B[0m, in \u001B[0;36mLoader.__init__\u001B[1;34m(self, object_graph_proto, saved_model_proto, export_dir, ckpt_options, save_options, filters)\u001B[0m\n\u001B[0;32m    158\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_proto \u001B[38;5;241m=\u001B[39m object_graph_proto\n\u001B[0;32m    159\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_export_dir \u001B[38;5;241m=\u001B[39m export_dir\n\u001B[0;32m    160\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_concrete_functions \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m--> 161\u001B[0m     \u001B[43mfunction_deserialization\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_function_def_library\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    162\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlibrary\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmeta_graph\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgraph_def\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlibrary\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    163\u001B[0m \u001B[43m        \u001B[49m\u001B[43msaved_object_graph\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_proto\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    164\u001B[0m \u001B[43m        \u001B[49m\u001B[43mwrapper_function\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_WrapperFunction\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m    165\u001B[0m \u001B[38;5;66;03m# Store a set of all concrete functions that have been set up with\u001B[39;00m\n\u001B[0;32m    166\u001B[0m \u001B[38;5;66;03m# captures.\u001B[39;00m\n\u001B[0;32m    167\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_restored_concrete_functions \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\saved_model\\function_deserialization.py:456\u001B[0m, in \u001B[0;36mload_function_def_library\u001B[1;34m(library, saved_object_graph, load_shared_name_suffix, wrapper_function)\u001B[0m\n\u001B[0;32m    450\u001B[0m \u001B[38;5;66;03m# There is no need to copy all functions into the function def graph. It\u001B[39;00m\n\u001B[0;32m    451\u001B[0m \u001B[38;5;66;03m# leads to a O(n^2) increase of memory when importing functions and the\u001B[39;00m\n\u001B[0;32m    452\u001B[0m \u001B[38;5;66;03m# extra function definitions are a no-op since they already imported as a\u001B[39;00m\n\u001B[0;32m    453\u001B[0m \u001B[38;5;66;03m# function before and passed in explicitly (due to the topologic sort\u001B[39;00m\n\u001B[0;32m    454\u001B[0m \u001B[38;5;66;03m# import).\u001B[39;00m\n\u001B[0;32m    455\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m graph\u001B[38;5;241m.\u001B[39mas_default():\n\u001B[1;32m--> 456\u001B[0m   func_graph \u001B[38;5;241m=\u001B[39m \u001B[43mfunction_def_lib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction_def_to_graph\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    457\u001B[0m \u001B[43m      \u001B[49m\u001B[43mfdef\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    458\u001B[0m \u001B[43m      \u001B[49m\u001B[43mstructured_input_signature\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstructured_input_signature\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    459\u001B[0m \u001B[43m      \u001B[49m\u001B[43mstructured_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstructured_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    460\u001B[0m \u001B[38;5;66;03m# Restores gradients for function-call ops (not the same as ops that use\u001B[39;00m\n\u001B[0;32m    461\u001B[0m \u001B[38;5;66;03m# custom gradients)\u001B[39;00m\n\u001B[0;32m    462\u001B[0m _restore_gradient_functions(func_graph, renamed_functions, loaded_gradients)\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\function_def_to_graph.py:91\u001B[0m, in \u001B[0;36mfunction_def_to_graph\u001B[1;34m(fdef, structured_input_signature, structured_outputs, input_shapes, propagate_device_spec, include_library_functions)\u001B[0m\n\u001B[0;32m     88\u001B[0m       \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     89\u001B[0m         input_shapes\u001B[38;5;241m.\u001B[39mappend(input_shape)\n\u001B[1;32m---> 91\u001B[0m graph_def, nested_to_flat_tensor_name \u001B[38;5;241m=\u001B[39m \u001B[43mfunction_def_to_graph_def\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     92\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfdef\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_shapes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minclude_library_functions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minclude_library_functions\u001B[49m\n\u001B[0;32m     93\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     95\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m func_graph\u001B[38;5;241m.\u001B[39mas_default():\n\u001B[0;32m     96\u001B[0m   \u001B[38;5;66;03m# Add all function nodes to the graph.\u001B[39;00m\n\u001B[0;32m     97\u001B[0m   importer\u001B[38;5;241m.\u001B[39mimport_graph_def_for_function(\n\u001B[0;32m     98\u001B[0m       graph_def, name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m, propagate_device_spec\u001B[38;5;241m=\u001B[39mpropagate_device_spec)\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\function_def_to_graph.py:330\u001B[0m, in \u001B[0;36mfunction_def_to_graph_def\u001B[1;34m(fdef, input_shapes, include_library_functions)\u001B[0m\n\u001B[0;32m    328\u001B[0m       graph_def\u001B[38;5;241m.\u001B[39mlibrary\u001B[38;5;241m.\u001B[39mgradient\u001B[38;5;241m.\u001B[39mextend([grad_def])\n\u001B[0;32m    329\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 330\u001B[0m   op_def \u001B[38;5;241m=\u001B[39m \u001B[43mdefault_graph\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mop_def_for_type\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnode_def\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mop\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[0;32m    332\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m attr \u001B[38;5;129;01min\u001B[39;00m op_def\u001B[38;5;241m.\u001B[39mattr:\n\u001B[0;32m    333\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m attr\u001B[38;5;241m.\u001B[39mtype \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfunc\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:3083\u001B[0m, in \u001B[0;36mGraph.op_def_for_type\u001B[1;34m(self, type)\u001B[0m\n\u001B[0;32m   3080\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_op_def_cache[\u001B[38;5;28mtype\u001B[39m]\n\u001B[0;32m   3081\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m:\n\u001B[0;32m   3082\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_op_def_cache[\u001B[38;5;28mtype\u001B[39m] \u001B[38;5;241m=\u001B[39m op_def_pb2\u001B[38;5;241m.\u001B[39mOpDef\u001B[38;5;241m.\u001B[39mFromString(\n\u001B[1;32m-> 3083\u001B[0m       \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_op_def_for_type\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mtype\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3084\u001B[0m   )\n\u001B[0;32m   3085\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_op_def_cache[\u001B[38;5;28mtype\u001B[39m]\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Op type not registered 'CaseFoldUTF8' in binary running on JULIALAPTOP2017. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib (e.g. `tf.contrib.resampler`), accessing should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed."
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a2da6529d8a432ff"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
