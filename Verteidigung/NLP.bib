@inproceedings{saravia-etal-2018-carer,
    title = "{CARER}: Contextualized Affect Representations for Emotion Recognition",
    author = "Saravia, Elvis  and
      Liu, Hsien-Chi Toby  and
      Huang, Yen-Hao  and
      Wu, Junlin  and
      Chen, Yi-Shin",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    month = oct # "-" # nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D18-1404",
    doi = "10.18653/v1/D18-1404",
    pages = "3687--3697",
    abstract = "Emotions are expressed in nuanced ways, which varies by collective or individual experiences, knowledge, and beliefs. Therefore, to understand emotion, as conveyed through text, a robust mechanism capable of capturing and modeling different linguistic nuances and phenomena is needed. We propose a semi-supervised, graph-based algorithm to produce rich structural descriptors which serve as the building blocks for constructing contextualized affect representations from text. The pattern-based representations are further enriched with word embeddings and evaluated through several emotion recognition tasks. Our experimental results demonstrate that the proposed method outperforms state-of-the-art techniques on emotion recognition tasks.",
}

@misc{hartmann2022emotionenglish,
  author={Hartmann, Jochen},
  title={Emotion English DistilRoBERTa-base},
  year={2022},
  howpublished = {\url{https://huggingface.co/j-hartmann/emotion-english-distilroberta-base/}},
}

@inproceedings{cao_data,
    title = "CREMA-D: Crowd-sourced Emotional Multimodal Actors Dataset",
    author = "H Cao and
    DG Cooper and
    Keutmann MK and
    Gur RC and
    Nenkova A and
    Verma R",
    booktitle = "IEEE Trans Affect Comput",
    year = "2014",
    publisher = "IEEE Trans Affect Comput",
    doi = "10.1109/TAFFC.2014.2336244",
    pages = "5(4):377-390",
}

@incollection{gervasi_using_2017,
	address = {Cham},
	title = {Using {Ontology} for {Personalised} {Course} {Recommendation} {Applications}},
	volume = {10404},
	isbn = {978-3-319-62391-7 978-3-319-62392-4},
	url = {http://link.springer.com/10.1007/978-3-319-62392-4_31},
	abstract = {The primary data source for universities and courses for students is increasingly becoming the web, and with a vast amount of information about thousands of courses on different websites, it is quite a task to find one that matches a student’s needs. That is why we are proposing the “Course Recommendation System”, a system that suggests the course best suited for prospective students. As there has been a huge increase in course content on the Internet, finding the course you really need has become time-consuming, so we are proposing to use an ontology-based approach to semantic content recommendation. The aim is to enhance the efficiency and effectiveness of providing students with suitable recommendations. The recommender takes into consideration knowledge about the user (the student’s profile) and course content, as well as knowledge about the domain that is being learned. Ontology is used to both models and represent such forms of knowledge. There are four steps to this: extracting information from multiple sources, applying ontologies by using Protégé tools, semantic relevance calculation and refining the recommendation. A personalised, complete and augmented course is then suggested for the student, based on these steps.},
	language = {en},
	urldate = {2023-05-21},
	booktitle = {Computational {Science} and {Its} {Applications} – {ICCSA} 2017},
	publisher = {Springer International Publishing},
	author = {Ibrahim, Mohammed Essmat and Yang, Yanyan and Ndzi, David},
	editor = {Gervasi, Osvaldo and Murgante, Beniamino and Misra, Sanjay and Borruso, Giuseppe and Torre, Carmelo M. and Rocha, Ana Maria A.C. and Taniar, David and Apduhan, Bernady O. and Stankova, Elena and Cuzzocrea, Alfredo},
	year = {2017},
	doi = {10.1007/978-3-319-62392-4_31},
	note = {Series Title: Lecture Notes in Computer Science},
	keywords = {nutzen, gelesen, Ontology, Similarity},
	pages = {426--438},
	file = {ontologies for courses.pdf:D\:\\Dokumente\\05 Uni\\6. Semester\\03 Acad\\Course ontologies\\ontologies for courses.pdf:application/pdf},
}

@article{ibrahim_ontology-based_2019,
	title = {Ontology-{Based} {Personalized} {Course} {Recommendation} {Framework}},
	volume = {7},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/document/8587168/},
	doi = {10.1109/ACCESS.2018.2889635},
	abstract = {Choosing a higher education course at university is not an easy task for students. A wide range of courses is offered by individual universities whose delivery mode and entry requirements all differ. A personalised recommendation system can be an effective way of suggesting relevant courses to prospective students. This paper introduces a novel approach that personalises course recommendations that will match the individual needs of users. The proposed approach developed a framework of an ontology-based hybridfiltering system called OPCR. This approach aims to integrate information from multiple sources based on hierarchical ontology similarity with a view to enhancing efficiency and user satisfaction and to provide students with appropriate recommendations. OPCR combines collaborative based filtering with contentbased filtering. It also considers familiar related concepts that are evident in the profiles of both the student and the course, determining the similarity between them. Furthermore, OPCR uses an ontology mapping technique, recommending jobs that will be available following completion of each course. This method can enable students to gain a comprehensive knowledge of courses based on their relevance, using dynamic ontology mapping to link course profiles and student profiles with job profiles. Results show that a filtering algorithm that uses hierarchically related concepts produces better outcomes compared to a filtering method that considers only keyword similarity. In addition, the quality of the recommendations improved when the ontology similarity between the items’ profiles and the users’ profiles were utilised. This approach, using a dynamic ontology mapping, is flexible and can be adapted to different domains. The proposed framework can be used to filter items for both postgraduate courses and items from other domains.},
	language = {en},
	urldate = {2023-05-21},
	journal = {IEEE Access},
	author = {Ibrahim, Mohammed E. and Yang, Yanyan and Ndzi, David L. and Yang, Guangguang and Al-Maliki, Murtadha},
	year = {2019},
	keywords = {gelesen, sekundaer, Ontology},
	pages = {5180--5199},
	file = {example.pdf:D\:\\Dokumente\\05 Uni\\6. Semester\\03 Acad\\Course ontologies\\example.pdf:application/pdf},
}

@book{andreasen_flexible_2021,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Flexible {Query} {Answering} {Systems}: 14th {International} {Conference}, {FQAS} 2021, {Bratislava}, {Slovakia}, {September} 19–24, 2021, {Proceedings}},
	volume = {12871},
	isbn = {978-3-030-86966-3 978-3-030-86967-0},
	shorttitle = {Flexible {Query} {Answering} {Systems}},
	url = {https://link.springer.com/10.1007/978-3-030-86967-0},
	language = {en},
	urldate = {2023-05-21},
	publisher = {Springer International Publishing},
	editor = {Andreasen, Troels and De Tré, Guy and Kacprzyk, Janusz and Legind Larsen, Henrik and Bordogna, Gloria and Zadrożny, Sławomir},
	year = {2021},
	doi = {10.1007/978-3-030-86967-0},
	keywords = {ungelesen},
	file = {978-3-030-86967-0.pdf:D\:\\Dokumente\\05 Uni\\6. Semester\\03 Acad\\other papers\\978-3-030-86967-0.pdf:application/pdf},
}

@article{sarwar_exploiting_2021,
	title = {Exploiting {Ontology} {Recommendation} {Using} {Text} {Categorization} {Approach}},
	volume = {9},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/document/9308899/},
	doi = {10.1109/ACCESS.2020.3047364},
	abstract = {Semantic Web is considered as the backbone of web 3.0 and ontologies are an integral part of the Semantic Web. Though an increase of ontologies in different domains is reported due to various beneﬁts which include data heterogeneity, automated information analysis, and reusability, however, ﬁnding an appropriate ontology according to user requirement remains cumbersome task due to time and efforts required, context-awareness, and computational complexity. To overcome these issues, an ontology recommendation framework is proposed. The Proposed framework employs text categorization and unsupervised learning techniques. The beneﬁts of the proposed framework are twofold: 1) ontology organization according to the opinion of domain experts and 2) ontology recommendation with respect to user requirement. Moreover, an evaluation model is also proposed to assess the effectiveness of the proposed framework in terms of ontologies organization and recommendation. The main consequences of the proposed framework are 1) ontologies of a corpus can be organized effectively, 2) no effort and time are required to select an appropriate ontology, 3) computational complexity is only limited to the use of unsupervised learning techniques, and 4) due to no requirement of context awareness, the proposed framework can be effective for any corpus or online libraries of ontologies.},
	language = {en},
	urldate = {2023-05-21},
	journal = {IEEE Access},
	author = {Sarwar, Muhammad Azeem and Ahmed, Mansoor and Habib, Asad and Khalid, Muhammad and Ali, M. Akhtar and Raza, Mohsin and Hussain, Shahid and Ahmed, Ghufran},
	year = {2021},
	keywords = {nicht nuetzlich, Ontology},
	pages = {27304--27322},
	file = {rec using text cat.pdf:D\:\\Dokumente\\05 Uni\\6. Semester\\03 Acad\\Course ontologies\\rec using text cat.pdf:application/pdf},
}

@inproceedings{chung-yi_huang_course-recommendation_2013,
	address = {Tianjin, China},
	title = {Course-recommendation system based on ontology},
	isbn = {978-1-4799-0260-6},
	url = {https://ieeexplore.ieee.org/document/6890767},
	doi = {10.1109/ICMLC.2013.6890767},
	abstract = {To train students to learn a skill and increase the competitiveness for jobs, aU the tertiary institutions design special curriculum program to have a goal as learning to meet the demand of professional skills for students. This study used ontology technology to implement the Course-recommendation System, to provide students adaptive learning recommendations, and let students to learn a complete knowledge required to enter the workplace in the future.},
	language = {en},
	urldate = {2023-05-21},
	booktitle = {2013 {International} {Conference} on {Machine} {Learning} and {Cybernetics}},
	publisher = {IEEE},
	author = {{Chung-Yi Huang} and {Rung-Ching Chen} and {Long-Sheng Chen}},
	month = jul,
	year = {2013},
	keywords = {gelesen, Ontology},
	pages = {1168--1173},
	file = {Course-recommendation_system_based_on_ontology.pdf:D\:\\Dokumente\\05 Uni\\6. Semester\\03 Acad\\Course ontologies\\Course-recommendation_system_based_on_ontology.pdf:application/pdf},
}

@book{ciuciu_move_2017,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {On the {Move} to {Meaningful} {Internet} {Systems}: {OTM} 2016 {Workshops}: {Confederated} {International} {Workshops}: {EI2N}, {FBM}, {ICSP}, {Meta4eS}, and {OTMA} 2016, {Rhodes}, {Greece}, {October} 24–28, 2016, {Revised} {Selected} {Papers}},
	volume = {10034},
	isbn = {978-3-319-55960-5 978-3-319-55961-2},
	shorttitle = {On the {Move} to {Meaningful} {Internet} {Systems}},
	url = {http://link.springer.com/10.1007/978-3-319-55961-2},
	language = {en},
	urldate = {2023-05-21},
	publisher = {Springer International Publishing},
	editor = {Ciuciu, Ioana and Debruyne, Christophe and Panetto, Hervé and Weichhart, Georg and Bollen, Peter and Fensel, Anna and Vidal, Maria-Esther},
	year = {2017},
	doi = {10.1007/978-3-319-55961-2},
	keywords = {ungelesen, Ontology},
	file = {978-3-319-55961-2.pdf:D\:\\Dokumente\\05 Uni\\6. Semester\\03 Acad\\other papers\\978-3-319-55961-2.pdf:application/pdf},
}

@inproceedings{tapia-leon_ontological_2017,
	address = {Seville, Spain},
	title = {{ONTOLOGICAL} {MODEL} {OF} {STUDY} {PLANS} {FOR} {STUDENT} {MOBILITY} {PROGRAMS}: {ERASMUS}+ {CASE} {STUDY}},
	shorttitle = {{ONTOLOGICAL} {MODEL} {OF} {STUDY} {PLANS} {FOR} {STUDENT} {MOBILITY} {PROGRAMS}},
	url = {http://library.iated.org/view/TAPIALEON2017ONT},
	doi = {10.21125/iceri.2017.1557},
	abstract = {Erasmus+ is a program of the European Union aimed to promote student’s mobility and cooperation in the field of higher education. This program allows students to carry out a period of their studies in another participating country and to receive a full recognition of those studies in their university of origin. Besides being a purely academic exchange, Erasmus+ also offers a life experience: it enables active learning of foreign languages, facilitates a direct contact with the culture of a foreign country, and it brings students an experience that provides an improvement in their personal and academic development. The mobility program should complement the studies of a graduate, master or doctoral student and must ensure that mobility activities perform with high-quality standards and thus provide a positive impact on students. Unfortunately, the information that a student can obtain from the subjects to be taken in a destination mobility program is scarce. In some cases, the information available is limited to people´s comments about study plans or limited to the information someone can get after doing their own searches on official university websites. The latter represents an issue since the information of the subjects or study plans offered by the universities is dispersed. Furthermore, each university has its own repositories or databases, which are usually restricted to people outside the institution. Thirty-four countries are part of the Erasmus+ program, the number of institutions participating in student mobility totals around 3.720. The number increases significantly when multiplied by the different study plans that a university degree offers. Given the amount of information to be processed, which is difficult for humans to handle, it is necessary to analyze a model of information representation that will make it easier for computers to find the study plan that best suits the student's' academic needs. The following work aims to develop an ontological model of the study plans available within the Erasmus+ mobility program. This model would help the participating universities to share, reuse, communicate and collaborate with the construction of knowledge regarding their study plans. For this purpose, an ontology was created based on the methodology and for the development of the model, the Protégé tool was used. The ontological representation of the study plans will allow offering recommendations to students who opt for mobility programs.},
	language = {en},
	urldate = {2023-05-21},
	author = {Tapia-Leon, Mariela and Carrera-Rivera, Abdon and Chicaiza Espinosa, Janneth and Luján-Mora, Sergio},
	month = nov,
	year = {2017},
	keywords = {Important, nutzen, gelesen, Ontology},
	pages = {5944--5953},
	file = {1557.pdf:D\:\\Dokumente\\05 Uni\\6. Semester\\03 Acad\\Course ontologies\\1557.pdf:application/pdf},
}

@inproceedings{karaoglan_course_2013,
	address = {Chania, Greece},
	title = {Course prescription using ontologies},
	isbn = {978-1-4799-0044-2 978-1-4799-0042-8 978-1-4799-0043-5},
	url = {http://ieeexplore.ieee.org/document/6576526/},
	doi = {10.1109/EAEEIE.2013.6576526},
	abstract = {Information related to the same “information need”, is available from many different sources widely spread on the web. This information may be differently worded or organized based on the conceptualization of the domain by different people and design autonomy. Ontologies are seen as way out for overcoming this semantic heterogeneity and bringing a common understanding for an integrated access, that is formulating a consolidated answer to a single query. In this work we propose an ontology based course prescription for individuals who are willing to enhance their competencies in certain areas.},
	language = {en},
	urldate = {2023-05-21},
	booktitle = {2013 24th {EAEEIE} {Annual} {Conference} ({EAEEIE} 2013)},
	publisher = {IEEE},
	author = {Karaoglan, Bahar and Kisla, Tarik},
	month = may,
	year = {2013},
	keywords = {gelesen, sekundaer, Ontology, basic},
	pages = {184--186},
	file = {Course_prescription_using_ontologies.pdf:D\:\\Dokumente\\05 Uni\\6. Semester\\03 Acad\\Course ontologies\\Course_prescription_using_ontologies.pdf:application/pdf},
}

@article{mathiesen_model_2007,
	title = {A {Model} for {Developing} {International} {Student} {Exchanges}},
	volume = {26},
	issn = {0261-5479, 1470-1227},
	url = {http://www.tandfonline.com/doi/full/10.1080/02615470601049867},
	doi = {10.1080/02615470601049867},
	language = {en},
	number = {3},
	urldate = {2023-06-12},
	journal = {Social Work Education},
	author = {Mathiesen, Sally G. and Lager, Patricia},
	month = apr,
	year = {2007},
	keywords = {gelesen},
	pages = {280--291},
	file = {A Model for Developing International Student Exchanges.pdf:D\:\\Dokumente\\05 Uni\\6. Semester\\03 Acad\\other papers\\A Model for Developing International Student Exchanges.pdf:application/pdf},
}

@article{hansel_international_1986,
	title = {International {Student} {Exchange} {Programs}—{Are} the {Educational} {Benefits} {Real}?},
	volume = {70},
	issn = {0192-6365, 1930-1405},
	url = {http://journals.sagepub.com/doi/10.1177/019263658607048718},
	doi = {10.1177/019263658607048718},
	abstract = {Educators who have "assumed" that travel and exchange pro grams abroad are educationally beneficial will breathe easier after reading this article. The authors explain the details of a study that validates scientifically what most people have be lieved.},
	language = {en},
	number = {487},
	urldate = {2023-06-12},
	journal = {NASSP Bulletin},
	author = {Hansel, Bettina and Grove, Neal},
	month = feb,
	year = {1986},
	keywords = {gelesen},
	pages = {84--90},
	file = {hansel-grove-1986-international-student-exchange-programs-are-the-educational-benefits-real.pdf:D\:\\Dokumente\\05 Uni\\6. Semester\\03 Acad\\other papers\\hansel-grove-1986-international-student-exchange-programs-are-the-educational-benefits-real.pdf:application/pdf},
}

@article{politechnika_slaska_wydzial_organizacji_i_zarzadzania_zabrze_international_2019,
	title = {{INTERNATIONAL} {STUDENT} {EXCHANGE} – {MOTIVES}, {BENEFITS} {AND} {BARRIERS} {OF} {PARTICIPATION}},
	volume = {2019},
	issn = {16413466},
	url = {https://www.polsl.pl/Wydzialy/ROZ/ZN/Documents/Number%20133/Marciniak,%20Winnicki.pdf},
	doi = {10.29119/1641-3466.2019.133.8},
	abstract = {Erasmus mobility is one of the most important manifestations of internationalization of education in Europe. The aim of the study is to ascertain the participants’ motives and the benefits coming from this international exchange of students as well as to diversify the results with regard to gender. The article, in its theoretical part, characterizes the concept of internationalization of education, describes the factors motivating for educational mobility, the benefits and the barriers of participation. The empirical part contains own researches carried out on a group of 125 students from Polish and foreign universities, using the CAWI (Computer-Assisted Web Interview) tool. It turns out that the main motivators to participate in student international education mobility is, among women, desire to travel as well as development of language skills. Men are mainly motivated by having fun and good time. Regardless of the research results it can be noticed that, generally, employers are more likely to decide to hire people who participated in and international student exchange, and the risk of long-term unemployment among graduates with international experience is lower by half than among graduates without such international experience. On the other hand, internationalization of education involves risks, including commercial profits, academic colonization and difficulties in providing high-quality education.},
	language = {en},
	number = {133},
	urldate = {2023-06-12},
	journal = {Scientific Papers of Silesian University of Technology. Organization and Management Series},
	author = {{Politechnika Śląska, Wydział Organizacji i Zarządzania, Zabrze} and Marciniak, Dominika and Winnicki, Michał and {Politechnika Śląska, Wydział Organizacji i Zarządzania, Zabrze}},
	year = {2019},
	keywords = {gelesen, benefits},
	pages = {93--105},
	file = {Marciniak, Winnicki_ZN_PSl_Org.Zarz_2019_z.133.pdf:D\:\\Dokumente\\05 Uni\\6. Semester\\03 Acad\\other papers\\Marciniak, Winnicki_ZN_PSl_Org.Zarz_2019_z.133.pdf:application/pdf},
}

@article{chen_research_nodate,
	title = {Research on international student flows from a macro perspective: {A} network analysis of 1985, 1989 and 1995},
	abstract = {By analyzing the 64 countries that represent the largest number of international student exchanges, this article describes international student ﬂows from a macro perspective. The ﬁndings indicate that the international student exchange network remained relatively stable. The United States and most Western industrialized countries maintained their position at the center of the network, while East European and Asian countries have become more central and the African and Middle East countries have stayed peripheral. The results suggest an academic hegemony consistent with world economic and political performance. Allied with World System Theory, the higher a country’s position in the world system, the more central it is in the international student exchange network.},
	language = {en},
	author = {Chen, Tse-Mei and Barnett, George A},
	keywords = {nicht nuetzlich},
	file = {A_1003961327009.pdf:D\:\\Dokumente\\05 Uni\\6. Semester\\03 Acad\\other papers\\A_1003961327009.pdf:application/pdf},
}

@article{papasalouros_automatic_2008,
	title = {{AUTOMATIC} {GENERATION} {OF} {MULTIPLE} {CHOICE} {QUESTIONS} {FROM} {DOMAIN} {ONTOLOGIES}},
	abstract = {The aim of this paper is to present an innovative approach for generating multiple choice questions in automatic way. Although other approaches have been already reported in the literature, the approach presented in this paper is based on domain specific ontologies and it is independent of lexicons such as WordNet or other linguistic resources. The paper also reports on a first prototype implementation of such an approach which creates multiple choice question items using the Semantic Web standard technology OWL (Ontology Web Language). The proposed approach is independent of the domain since questions are generated according to specific ontology-based strategies. In current implementation, simple natural language generation techniques are used in order to provide the items in the questionnaires.},
	language = {en},
	author = {Papasalouros, Andreas and Kanaris, Konstantinos and Kotis, Konstantinos},
	year = {2008},
	keywords = {gelesen, OntologyQuestionaire, Ontology},
	file = {Automatic_generation_of_multiple_choice.pdf:D\:\\Dokumente\\05 Uni\\6. Semester\\03 Acad\\other papers\\Automatic_generation_of_multiple_choice.pdf:application/pdf},
}

@article{gruber_translation_1993,
	title = {A translation approach to portable ontology specifications},
	volume = {5},
	issn = {10428143},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1042814383710083},
	doi = {10.1006/knac.1993.1008},
	abstract = {To support the sharing and reuse of formally represented knowledge among AI systems, it is useful to define the common vocabulary in which shared knowledge is represented. A specification of a representational vocabulary for a shared domain of discourse — definitions of classes, relations, functions, and other objects — is called an ontology. This paper describes a mechanism for defining ontologies that are portable over representation systems. Definitions written in a standard format for predicate calculus are translated by a system called Ontolingua into specialized representations, including frame-based systems as well as relational languages. This allows researchers to share and reuse ontologies, while retaining the computational benefits of specialized implementations. We discuss how the translation approach to portability addresses several technical problems. One problem is how to accommodate the stylistic and organizational differences among representations while preserving declarative content. Another is how to translate from a very expressive language into restricted languages, remaining system-independent while preserving the computational efficiency of implemented systems. We describe how these problems are addressed by basing Ontolingua itself on an ontology of domain-independent, representational idioms.},
	language = {en},
	number = {2},
	urldate = {2023-06-12},
	journal = {Knowledge Acquisition},
	author = {Gruber, Thomas R.},
	month = jun,
	year = {1993},
	keywords = {gelesen, sekundaer, Ontology, basic},
	pages = {199--220},
	file = {ontolingua-kaj-1993.pdf:D\:\\Dokumente\\05 Uni\\6. Semester\\03 Acad\\Course ontologies\\ontolingua-kaj-1993.pdf:application/pdf},
}

@article{uschold_building_nodate,
	title = {Building {Ontologies}: {Towards} a {Uni} ed {Methodology}},
	abstract = {The use and importance of ontologies is becoming more widespread, however building ontologies is largely a black art. The aim of this paper is to identify and characterise what we currently know and to move towards the longer term goal of developing a comprehensive uni ed methodology. We rst identify dimensions for characterising ontologies, to be used as a basis for noting which techniques and guidelines for building ontologies apply in di erent circumstances. We then give an overview of the current state of the art, noting that most work addresses just a small part of the life cycle. The very few more complete methods are limited to case studies involving single ontologies and they are hard to compare. In the main part of this paper, we examine two such methods and give a framework for comparing and unifying them. We emphasise that di erent approaches are required for di erence circumstances, and give some guidelines for when to use which techniques. We conclude by considering how to further advance our understanding of building ontologies.},
	language = {en},
	author = {Uschold, Mike},
	keywords = {ungelesen, Ontology, OntologyCreation},
	file = {document.pdf:D\:\\Dokumente\\05 Uni\\6. Semester\\03 Acad\\Course ontologies\\document.pdf:application/pdf},
}

@misc{fan_semantics-aware_2023,
	title = {Semantics-aware {Dataset} {Discovery} from {Data} {Lakes} with {Contextualized} {Column}-based {Representation} {Learning}},
	url = {http://arxiv.org/abs/2210.01922},
	abstract = {Dataset discovery from data lakes is essential in many real application scenarios. In this paper, we propose Starmie, an end-toend framework for dataset discovery from data lakes (with table union search as the main use case). Our proposed framework features a contrastive learning method to train column encoders from pre-trained language models in a fully unsupervised manner. The column encoder of Starmie captures the rich contextual semantic information within tables by leveraging a contrastive multi-column pre-training strategy. We utilize the cosine similarity between column embedding vectors as the column unionability score and propose a filter-and-verification framework that allows exploring a variety of design choices to compute the unionability score between two tables accordingly. Empirical results on real table benchmarks show that Starmie outperforms the best-known solutions in the effectiveness of table union search by 6.8 in MAP and recall. Moreover, Starmie is the first to employ the HNSW (Hierarchical Navigable Small World) index to accelerate query processing of table union search which provides a 3,000X performance gain over the linear scan baseline and a 400X performance gain over an LSH index (the state-of-the-art solution for data lake indexing).},
	language = {en},
	urldate = {2023-11-17},
	publisher = {arXiv},
	author = {Fan, Grace and Wang, Jin and Li, Yuliang and Zhang, Dan and Miller, Renée},
	month = jan,
	year = {2023},
	note = {arXiv:2210.01922 [cs]},
	file = {data_lakes.pdf:D\:\\Dokumente\\05 Uni\\7. Semester\\05 DB\\Presentation_Papers\\data_lakes.pdf:application/pdf},
}

@misc{li_auto-tables_2023,
	title = {Auto-{Tables}: {Synthesizing} {Multi}-{Step} {Transformations} to {Relationalize} {Tables} without {Using} {Examples}},
	shorttitle = {Auto-{Tables}},
	url = {http://arxiv.org/abs/2307.14565},
	abstract = {Relational tables, where each row corresponds to an entity and each column corresponds to an attribute, have been the standard for tables in relational databases. However, such a standard cannot be taken for granted when dealing with tables “in the wild”. Our survey of real spreadsheet-tables and web-tables shows that over 30\% of such tables do not conform to the relational standard, for which complex table-restructuring transformations are needed before these tables can be queried easily using SQL-based tools. Unfortunately, the required transformations are non-trivial to program, which has become a substantial pain point for technical and non-technical users alike, as evidenced by large numbers of forum questions in places like StackOverflow and Excel/Tableau forums. We develop an Auto-Tables system that can automatically synthesize pipelines with multi-step transformations (in Python or other languages), to transform non-relational tables into standard relational forms for downstream analytics, obviating the need for users to manually program transformations. We compile an extensive benchmark for this new task, by collecting 244 real test cases from user spreadsheets and online forums. Our evaluation suggests that Auto-Tables can successfully synthesize transformations for over 70\% of test cases at interactive speeds, without requiring any input from users, making this an effective tool for both technical and non-technical users to prepare data for analytics.},
	language = {en},
	urldate = {2023-11-17},
	publisher = {arXiv},
	author = {Li, Peng and He, Yeye and Yan, Cong and Wang, Yue and Chaudhuri, Surajit},
	month = aug,
	year = {2023},
	note = {arXiv:2307.14565 [cs]},
	keywords = {Auszeichnung},
	annote = {Comment: full version of a paper accepted to VLDB 2023},
	file = {db_transform.pdf:D\:\\Dokumente\\05 Uni\\7. Semester\\05 DB\\Presentation_Papers\\db_transform.pdf:application/pdf},
}

@misc{qin_adore_2023,
	title = {Adore: {Differentially} {Oblivious} {Relational} {Database} {Operators}},
	shorttitle = {Adore},
	url = {http://arxiv.org/abs/2212.05176},
	abstract = {There has been a recent effort in applying differential privacy on memory access patterns to enhance data privacy. This is called differential obliviousness. Differential obliviousness is a promising direction because it provides a principled trade-off between performance and desired level of privacy. To date, it is still an open question whether differential obliviousness can speed up database processing with respect to full obliviousness. In this paper, we present the design and implementation of Adore: A set of Differentially Oblivious RElational database operators. Adore includes selection with projection, grouping with aggregation, and foreign key join. We prove that they satisfy the notion of differential obliviousness. Our differentially oblivious operators have reduced cache complexity, runtime complexity, and output size compared to their state-of-the-art fully oblivious counterparts. We also demonstrate that our implementation of these differentially oblivious operators can outperform their state-of-the-art fully oblivious counterparts by up to 7.4×.},
	language = {en},
	urldate = {2023-11-17},
	publisher = {arXiv},
	author = {Qin, Lianke and Jayaram, Rajesh and Shi, Elaine and Song, Zhao and Zhuo, Danyang and Chu, Shumo},
	month = sep,
	year = {2023},
	note = {arXiv:2212.05176 [cs]},
	annote = {Comment: VLDB 2023},
	file = {differentially_oblivious.pdf:D\:\\Dokumente\\05 Uni\\7. Semester\\05 DB\\Presentation_Papers\\differentially_oblivious.pdf:application/pdf},
}

@misc{kang_pim-tree_2022,
	title = {{PIM}-tree: {A} {Skew}-resistant {Index} for {Processing}-in-{Memory}},
	shorttitle = {{PIM}-tree},
	url = {http://arxiv.org/abs/2211.10516},
	abstract = {The performance of today’s in-memory indexes is bottlenecked by the memory latency/bandwidth wall. Processing-in-memory (PIM) is an emerging approach that potentially mitigates this bottleneck, by enabling low-latency memory access whose aggregate memory bandwidth scales with the number of PIM nodes. There is an inherent tension, however, between minimizing inter-node communication and achieving load balance in PIM systems, in the presence of workload skew. This paper presents PIM-tree, an ordered index for PIM systems that achieves both low communication and high load balance, regardless of the degree of skew in the data and the queries. Our skew-resistant index is based on a novel division of labor between the multi-core host CPU and the PIM nodes, which leverages the strengths of each. We introduce push-pull search, which dynamically decides whether to push queries to a PIM-tree node (CPU → PIM-node) or pull the node’s keys back to the CPU (PIM-node → CPU) based on workload skew. Combined with other PIM-friendly optimizations (shadow subtrees and chunked skip lists), our PIM-tree provides high-throughput, (guaranteed) low communication, and (guaranteed) high load balance, for batches of point queries, updates, and range scans. We implement the PIM-tree structure, in addition to prior proposed PIM indexes, on the latest PIM system from UPMEM, with 32 CPU cores and 2048 PIM nodes. On workloads with 500 million keys and batches of 1 million queries, the throughput using PIM-trees is up to 69.7× and 59.1× higher than the two best prior PIM-based methods. As far as we know these are the first implementations of an ordered index on a real PIM system.},
	language = {en},
	urldate = {2023-11-17},
	publisher = {arXiv},
	author = {Kang, Hongbo and Zhao, Yiwei and Blelloch, Guy E. and Dhulipala, Laxman and Gu, Yan and McGuffey, Charles and Gibbons, Phillip B.},
	month = nov,
	year = {2022},
	note = {arXiv:2211.10516 [cs]},
	file = {index_processing-in-memory.pdf:D\:\\Dokumente\\05 Uni\\7. Semester\\05 DB\\Presentation_Papers\\index_processing-in-memory.pdf:application/pdf},
}

@article{liu_deep_2023,
	title = {A {Deep} {Dive} into {Common} {Open} {Formats} for {Analytical} {DBMSs}},
	volume = {16},
	issn = {2150-8097},
	url = {https://dl.acm.org/doi/10.14778/3611479.3611507},
	doi = {10.14778/3611479.3611507},
	abstract = {This paper evaluates the suitability of Apache Arrow, Parquet, and ORC as formats for subsumption in an analytical DBMS. We systematically identify and explore the high-level features that are important to support efficient querying in modern OLAP DBMSs and evaluate the ability of each format to support these features. We find that each format has trade-offs that make it more or less suitable for use as a format in a DBMS and identify opportunities to more holistically co-design a unified in-memory and on-disk data representation. Our hope is that this study can be used as a guide for system developers designing and using these formats, as well as provide the community with directions to pursue for improving these common open formats.},
	language = {en},
	number = {11},
	urldate = {2023-11-17},
	journal = {Proceedings of the VLDB Endowment},
	author = {Liu, Chunwei and Pavlenko, Anna and Interlandi, Matteo and Haynes, Brandon},
	month = jul,
	year = {2023},
	keywords = {gelesen, Auszeichnung},
	pages = {3044--3056},
	file = {open_formats.pdf:D\:\\Dokumente\\05 Uni\\7. Semester\\05 DB\\Presentation_Papers\\open_formats.pdf:application/pdf},
}

@misc{shaham_models_2022,
	title = {Models and {Mechanisms} for {Spatial} {Data} {Fairness}},
	url = {http://arxiv.org/abs/2204.01880},
	abstract = {Fairness in data-driven decision-making studies scenarios where individuals from certain population segments may be unfairly treated when being considered for loan or job applications, access to public resources, or other types of services. In location-based applications, decisions are based on individual whereabouts, which often correlate with sensitive attributes such as race, income, and education.},
	language = {en},
	urldate = {2023-11-17},
	publisher = {arXiv},
	author = {Shaham, Sina and Ghinita, Gabriel and Shahabi, Cyrus},
	month = oct,
	year = {2022},
	note = {arXiv:2204.01880 [cs]},
	file = {spacial_fairness.pdf:D\:\\Dokumente\\05 Uni\\7. Semester\\05 DB\\Presentation_Papers\\spacial_fairness.pdf:application/pdf},
}

@misc{aghasadeghi_temporal_2022,
	title = {Temporal graph patterns by timed automata},
	url = {http://arxiv.org/abs/2205.14269},
	abstract = {Temporal graphs represent graph evolution over time, and have been receiving considerable research attention. Work on expressing temporal graph patterns or discovering temporal motifs typically assumes relatively simple temporal constraints, such as journeys or, more generally, existential constraints, possibly with ﬁnite delays. In this paper we propose to use timed automata to express temporal constraints, leading to a general and powerful notion of temporal basic graph pattern (BGP).},
	language = {en},
	urldate = {2023-11-17},
	publisher = {arXiv},
	author = {Aghasadeghi, Amir Pouya and Bussche, Jan Van den and Stoyanovich, Julia},
	month = may,
	year = {2022},
	note = {arXiv:2205.14269 [cs]},
	file = {temporal graph.pdf:D\:\\Dokumente\\05 Uni\\7. Semester\\05 DB\\Presentation_Papers\\temporal graph.pdf:application/pdf},
}

@misc{budiu_dbsp_2022,
	title = {{DBSP}: {Automatic} {Incremental} {View} {Maintenance} for {Rich} {Query} {Languages}},
	shorttitle = {{DBSP}},
	url = {http://arxiv.org/abs/2203.16684},
	abstract = {Incremental view maintenance has been for a long time a central problem in database theory [15]. Many solutions have been proposed for restricted classes of database languages, such as the relational algebra, or Datalog. These techniques do not naturally generalize to richer languages. In this paper we give a general solution to this problem in 3 steps: (1) we describe a simple but expressive language called DBSP for describing computations over data streams; (2) we give a general algorithm for solving the incremental view maintenance problem for arbitrary DBSP programs, and (3) we show how to model many rich database query languages (including the full relational queries, grouping and aggregation, monotonic and non-monotonic recursion, and streaming aggregation) using DBSP. As a consequence, we obtain eﬃcient incremental view maintenance techniques for all these rich languages.},
	language = {en},
	urldate = {2023-11-17},
	publisher = {arXiv},
	author = {Budiu, Mihai and McSherry, Frank and Ryzhyk, Leonid and Tannen, Val},
	month = mar,
	year = {2022},
	note = {arXiv:2203.16684 [cs]},
	keywords = {Auszeichnung},
	file = {view_maintenance.pdf:D\:\\Dokumente\\05 Uni\\7. Semester\\05 DB\\Presentation_Papers\\view_maintenance.pdf:application/pdf},
}

@inproceedings{gavriilidis_-situ_2023,
	address = {Anaheim, CA, USA},
	title = {In-{Situ} {Cross}-{Database} {Query} {Processing}},
	isbn = {9798350322279},
	url = {https://ieeexplore.ieee.org/document/10184600/},
	doi = {10.1109/ICDE55515.2023.00214},
	abstract = {Today’s organizations utilize a plethora of heterogeneous and autonomous DBMSes, many of those being spread across different geo-locations. It is therefore crucial to have effective and efﬁcient cross-database query processing capabilities. We present XDB, an efﬁcient middleware system that runs crossdatabase analytics over existing DBMSes. In contrast to traditional query processing systems, XDB does not rely on any mediating execution engine to perform cross-database operations (e.g., joining data from two DBMSes). It delegates an entire query execution including cross-database operations to underlying DBMSes. At its core, it comprises an optimizer and a delegation engine: the optimizer rewrites cross-database queries into a delegation plan, which captures the semantics as well as the mechanics of a fully decentralized query execution; the delegation engine then deploys the plan to the underlying DBMSes via their declarative interfaces. Our experimental study based on the TPC-H benchmark data shows that XDB outperforms state-of-the-art systems (Garlic and Presto) by up to 6× in terms of runtime and up to 3 orders of magnitude in terms of data transfer.},
	language = {en},
	urldate = {2023-12-03},
	booktitle = {2023 {IEEE} 39th {International} {Conference} on {Data} {Engineering} ({ICDE})},
	publisher = {IEEE},
	author = {Gavriilidis, Haralampos and Beedkar, Kaustubh and Quiané-Ruiz, Jorge-Arnulfo and Markl, Volker},
	month = apr,
	year = {2023},
	keywords = {Second Round},
	pages = {2794--2807},
	file = {In-Situ_Cross-Database_Query_Processing.pdf:D\:\\Dokumente\\05 Uni\\7. Semester\\05 DB\\Presentation_Papers\\In-Situ_Cross-Database_Query_Processing.pdf:application/pdf},
}

@misc{anadiotis_integrating_2022,
	title = {Integrating connection search in graph queries},
	url = {http://arxiv.org/abs/2208.04802},
	abstract = {Graph data management and querying has many practical applications. When graphs are very heterogeneous and/or users are unfamiliar with their structure, they may need to find how two or more groups of nodes are connected in a graph, even when users are not able to describe the connections. This is only partially supported by existing query languages, which allow searching for paths, but not for trees connecting three or more node groups. The latter is related to the NP-hard Group Steiner Tree problem, and has been previously considered for keyword search in databases. In this work, we formally show how to integrate connecting tree patterns (CTPs, in short) within a graph query language such as SPARQL or Cypher, leading to an Extended Query Language (or EQL, in short). We then study a set of algorithms for evaluating CTPs; we generalize prior keyword search work, most importantly by (𝑖) considering bidirectional edge traversal and (𝑖𝑖) allowing users to select any score function for ranking CTP results. To cope with very large search spaces, we propose an efficient pruning technique and formally establish a large set of cases where our algorithm, MoLESP, is complete even with pruning. Our experiments validate the performance of our CTP and EQL evaluation algorithms on a large set of synthetic and real-world workloads.},
	language = {en},
	urldate = {2023-12-03},
	publisher = {arXiv},
	author = {Anadiotis, Angelos Christos and Manolescu, Ioana and Mohanty, Madhulika},
	month = aug,
	year = {2022},
	note = {arXiv:2208.04802 [cs]},
	keywords = {Second Round},
	file = {Integrating_connection_search_graph_queries.pdf:D\:\\Dokumente\\05 Uni\\7. Semester\\05 DB\\Presentation_Papers\\Integrating_connection_search_graph_queries.pdf:application/pdf},
}

@misc{khatiwada_santos_2022,
	title = {{SANTOS}: {Relationship}-based {Semantic} {Table} {Union} {Search}},
	shorttitle = {{SANTOS}},
	url = {http://arxiv.org/abs/2209.13589},
	abstract = {Existing techniques for unionable table search define unionability using metadata (tables must have the same or similar schemas) or column-based metrics (for example, the values in a table should be drawn from the same domain). In this work, we introduce the use of semantic relationships between pairs of columns in a table to improve the accuracy of union search. Consequently, we introduce a new notion of unionability that considers relationships between columns, together with the semantics of columns, in a principled way. To do so, we present two new methods to discover semantic relationship between pairs of columns. The first uses an existing knowledge base (KB), the second (which we call a “synthesized KB”) uses knowledge from the data lake itself. We adopt an existing Table Union Search benchmark and present new (open) benchmarks that represent small and large real data lakes. We show that our new unionability search algorithm, called SANTOS, outperforms a stateof-the-art union search that uses a wide variety of column-based semantics, including word embeddings and regular expressions. We show empirically that our synthesized KB improves the accuracy of union search by representing relationship semantics that may not be contained in an available KB. This result hints at a promising future of creating a synthesized KBs from data lakes with limited KB coverage and using them for union search.},
	language = {en},
	urldate = {2023-12-03},
	publisher = {arXiv},
	author = {Khatiwada, Aamod and Fan, Grace and Shraga, Roee and Chen, Zixuan and Gatterbauer, Wolfgang and Miller, Renée J. and Riedewald, Mirek},
	month = sep,
	year = {2022},
	note = {arXiv:2209.13589 [cs]},
	keywords = {Second Round},
	annote = {Comment: 15 pages, 10 figures, to appear at SIGMOD 2023},
	file = {SANTOS_rs-based_union_search.pdf:D\:\\Dokumente\\05 Uni\\7. Semester\\05 DB\\Presentation_Papers\\SANTOS_rs-based_union_search.pdf:application/pdf},
}

@article{pierre-yves_production_2003,
	title = {The production and recognition of emotions in speech: features and algorithms},
	abstract = {This paper presents algorithms that allow a robot to express its emotions by modulating the intonation of its voice. They are very simple and efﬁciently provide life-like speech thanks to the use of concatenative speech synthesis. We describe a technique which allows to continuously control both the age of a synthetic voice and the quantity of emotions that are expressed. Also, we present the ﬁrst large-scale data mining experiment about the automatic recognition of basic emotions in informal everyday short utterances. We focus on the speaker-dependent problem. We compare a large set of machine learning algorithms, ranging from neural networks, Support Vector Machines or decision trees, together with 200 features, using a large database of several thousands examples. We show that the difference of performance among learning schemes can be substantial, and that some features which were previously unexplored are of crucial importance. An optimal feature set is derived through the use of a genetic algorithm. Finally, we explain how this study can be applied to real world situations in which very few examples are available. Furthermore, we describe a game to play with a personal robot which facilitates teaching of examples of emotional utterances in a natural and rather unconstrained manner.},
	language = {en},
	journal = {Computer Studies},
	author = {Pierre-Yves, Oudeyer},
	year = {2003},
	file = {1-s2.0-S1071581902001416-main.pdf:D\:\\Dokumente\\05 Uni\\7. Semester\\06 NLP\\Papers\\1-s2.0-S1071581902001416-main.pdf:application/pdf},
}

@article{ghazi_detecting_nodate,
	title = {Detecting {Emotion} {Stimuli} in {Emotion}-{Bearing} {Sentences}},
	abstract = {Emotion, a pervasive aspect of human experience, has long been of interest to social and behavioural sciences. It is now the subject of multi-disciplinary research also in computational linguistics. Emotion recognition, studied in the area of sentiment analysis, has focused on detecting the expressed emotion. A related challenging question, why the experiencer feels that emotion, has, to date, received very little attention. The task is difﬁcult and there are no annotated English resources. FrameNet refers to the person, event or state of affairs which evokes the emotional response in the experiencer as emotion stimulus.1 We automatically build a dataset annotated with both the emotion and the stimulus using FrameNet’s emotions-directed frame. We address the problem as information extraction: we build a CRF learner, a sequential learning model to detect the emotion stimulus spans in emotion-bearing sentences. We show that our model signiﬁcantly outperforms all the baselines.},
	language = {en},
	author = {Ghazi, Diman and Inkpen, Diana and Szpakowicz, Stan},
	file = {90420152.pdf:D\:\\Dokumente\\05 Uni\\7. Semester\\06 NLP\\Papers\\90420152.pdf:application/pdf},
}

@article{arias_beyond_2020,
	title = {Beyond {Correlation}: {Acoustic} {Transformation} {Methods} for the {Experimental} {Study} of {Emotional} {Voice} and {Speech}},
	abstract = {While acoustic analysis methods have become a commodity in voice emotion research, experiments that attempt not only to describe but to computationally manipulate expressive cues in emotional voice and speech have remained relatively rare. We give here a nontechnical overview of voice-transformation techniques from the audio signal-processing community that we believe are ripe for adoption in this context. We provide sound examples of what they can achieve, examples of experimental questions for which they can be used, and links to open-source implementations. We point at a number of methodological properties of these algorithms, such as being specific, parametric, exhaustive, and real-time, and describe the new possibilities that these open for the experimental study of the emotional voice.},
	language = {en},
	author = {Arias, Pablo and Rachman, Laura and Liuni, Marco and Aucouturier, Jean-Julien},
	year = {2020},
	file = {arias-et-al-2020-beyond-correlation-acoustic-transformation-methods-for-the-experimental-study-of-emotional-voice-and.pdf:D\:\\Dokumente\\05 Uni\\7. Semester\\06 NLP\\Papers\\arias-et-al-2020-beyond-correlation-acoustic-transformation-methods-for-the-experimental-study-of-emotional-voice-and.pdf:application/pdf},
}

@inproceedings{park_emotion_2020,
	address = {Busan, Korea (South)},
	title = {Emotion {Recognition} from {Text} {Stories} {Using} an {Emotion} {Embedding} {Model}},
	isbn = {978-1-72816-034-4},
	url = {https://ieeexplore.ieee.org/document/9070506/},
	doi = {10.1109/BigComp48618.2020.00014},
	abstract = {In this paper, we analyze emotions in a story text using an emotion embedding model. Firstly, we collected 144,701 tweets, and each tweet is given an emotional hashtag. Using the emotion hashtag as an emotion label, we built a CNN model for emotion classiﬁcation. We then extracted the embedding model created during the learning process. We then extracted word embedding layer created during the emotion classiﬁcation learning process.},
	language = {en},
	urldate = {2023-12-17},
	booktitle = {2020 {IEEE} {International} {Conference} on {Big} {Data} and {Smart} {Computing} ({BigComp})},
	publisher = {IEEE},
	author = {Park, Seo-Hui and Bae, Byung-Chull and Cheong, Yun-Gyung},
	month = feb,
	year = {2020},
	pages = {579--583},
	file = {Emotion_Recognition_from_Text_Stories_Using_an_Emotion_Embedding_Model.pdf:D\:\\Dokumente\\05 Uni\\7. Semester\\06 NLP\\Papers\\Emotion_Recognition_from_Text_Stories_Using_an_Emotion_Embedding_Model.pdf:application/pdf},
}

@article{hirat_survey_nodate,
	title = {A {Survey} {On} {Emotion} {Detection} {Techniques} using {Text} in {Blogposts}},
	abstract = {People express emotions as part of everyday communication. Emotions can be judged by facial expressions, prosodies, gestures, actions and written texts. Emotion is an important aspect in the interaction and communication between peoples. The communication of emotions through text messaging and personal blogs poses the informal style of writing is a challenge for researchers. Extraction of emotions from text can applied for deciding the human computer interaction which governs the communications. Emotions may be expressed by a persons speech, face expression and written text known as speech, facial and text based emotion respectively. This work is drawn from emotion theories in the ﬁelds of psychology and linguistics, and use natural language processing and machine learning techniques for automatic emotion detection. In this work, it is described that studies in manual and automatic recognition of expressions of the eight basic emotions Angry, Anticipate, Disgust, Fear, Joy, Sadness, Surprise, Trust in text form.},
	language = {en},
	author = {Hirat, Ruchi and Mittal, Namita},
	file = {International_Bulletin_of_Mathematical_R.pdf:D\:\\Dokumente\\05 Uni\\7. Semester\\06 NLP\\Papers\\International_Bulletin_of_Mathematical_R.pdf:application/pdf},
}

@article{murthy_review_2021,
	title = {A {Review} of {Different} {Approaches} for {Detecting} {Emotion} from {Text}},
	volume = {1110},
	issn = {1757-8981, 1757-899X},
	url = {https://iopscience.iop.org/article/10.1088/1757-899X/1110/1/012009},
	doi = {10.1088/1757-899X/1110/1/012009},
	abstract = {Emotion detection and analysis is one of the challenging and emerging issues in the field of natural language processing (NLP). Detecting an individual's emotional state from textual data is an active area of study, along with identifying emotions from facial and audio records. The study of emotions can benefit from many applications in various fields, including neuroscience, data mining, psychology, human-computer interaction, e-learning, information filtering systems and cognitive science. The rich source of text available in the Social media, blogs, customer review, news articles can be a useful resource to explore various insights in text mining, including emotions. The purpose of this study is to provide a survey of existing approaches, models, datasets, lexicons, metrics and their limitations in the detection of emotions from the text useful for researchers in carrying out emotion detection activities.},
	language = {en},
	number = {1},
	urldate = {2023-12-17},
	journal = {IOP Conference Series: Materials Science and Engineering},
	author = {Murthy, Ashritha R and Anil Kumar, K M},
	month = mar,
	year = {2021},
	pages = {012009},
	file = {Murthy_2021_IOP_Conf._Ser.__Mater._Sci._Eng._1110_012009.pdf:D\:\\Dokumente\\05 Uni\\7. Semester\\06 NLP\\Papers\\Murthy_2021_IOP_Conf._Ser.__Mater._Sci._Eng._1110_012009.pdf:application/pdf},
}

@article{scherer_emotions_2009,
	title = {Emotions are emergent processes: they require a dynamic computational architecture},
	volume = {364},
	issn = {0962-8436, 1471-2970},
	shorttitle = {Emotions are emergent processes},
	url = {https://royalsocietypublishing.org/doi/10.1098/rstb.2009.0141},
	doi = {10.1098/rstb.2009.0141},
	abstract = {Emotion is a cultural and psychobiological adaptation mechanism which allows each individual to react flexibly and dynamically to environmental contingencies. From this claim flows a description of the elements theoretically needed to construct a virtual agent with the ability to display human-like emotions and to respond appropriately to human emotional expression. This article offers a brief survey of the desirable features of emotion theories that make them ideal blueprints for agent models. In particular, the component process model of emotion is described, a theory which postulates emotion-antecedent appraisal on different levels of processing that drive response system patterning predictions. In conclusion, investing seriously in emergent computational modelling of emotion using a nonlinear dynamic systems approach is suggested.},
	language = {en},
	number = {1535},
	urldate = {2023-12-17},
	journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
	author = {Scherer, Klaus R.},
	month = dec,
	year = {2009},
	pages = {3459--3474},
	file = {Phil. Trans. R. Soc. B-2009-Scherer-3459-74.pdf:D\:\\Dokumente\\05 Uni\\7. Semester\\06 NLP\\Papers\\Phil. Trans. R. Soc. B-2009-Scherer-3459-74.pdf:application/pdf},
}

@article{nandwani_review_2021,
	title = {A review on sentiment analysis and emotion detection from text},
	volume = {11},
	issn = {1869-5450, 1869-5469},
	url = {https://link.springer.com/10.1007/s13278-021-00776-6},
	doi = {10.1007/s13278-021-00776-6},
	abstract = {Social networking platforms have become an essential means for communicating feelings to the entire world due to rapid expansion in the Internet era. Several people use textual content, pictures, audio, and video to express their feelings or viewpoints. Text communication via Web-based networking media, on the other hand, is somewhat overwhelming. Every second, a massive amount of unstructured data is generated on the Internet due to social media platforms. The data must be processed as rapidly as generated to comprehend human psychology, and it can be accomplished using sentiment analysis, which recognizes polarity in texts. It assesses whether the author has a negative, positive, or neutral attitude toward an item, administration, individual, or location. In some applications, sentiment analysis is insufficient and hence requires emotion detection, which determines an individual’s emotional/mental state precisely. This review paper provides understanding into levels of sentiment analysis, various emotion models, and the process of sentiment analysis and emotion detection from text. Finally, this paper discusses the challenges faced during sentiment and emotion analysis.},
	language = {en},
	number = {1},
	urldate = {2023-12-17},
	journal = {Social Network Analysis and Mining},
	author = {Nandwani, Pansy and Verma, Rupali},
	month = dec,
	year = {2021},
	pages = {81},
	file = {s13278-021-00776-6.pdf:D\:\\Dokumente\\05 Uni\\7. Semester\\06 NLP\\Papers\\s13278-021-00776-6.pdf:application/pdf},
}

@article{he_quantifying_2023,
	title = {Quantifying the retention of emotions across story retellings},
	volume = {13},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-023-29178-8},
	doi = {10.1038/s41598-023-29178-8},
	abstract = {Abstract
            Story retelling is a fundamental medium for the transmission of information between individuals and among social groups. Besides conveying factual information, stories also contain affective information. Though natural language processing techniques have advanced considerably in recent years, the extent to which machines can be trained to identify and track emotions across retellings is unknown. This study leverages the powerful RoBERTa model, based on a transformer architecture, to derive emotion-rich story embeddings from a unique dataset of 25,728 story retellings. The initial stories were centered around five emotional events (joy, sadness, embarrassment, risk, and disgust—though the stories did not contain these emotion words) and three intensities (high, medium, and low). Our results indicate (1) that RoBERTa can identify emotions in stories it was not trained on, (2) that the five emotions and their intensities are preserved when they are transmitted in the form of retellings, (3) that the emotions in stories are increasingly well-preserved as they experience additional retellings, and (4) that among the five emotions, risk and disgust are least well-preserved, compared with joy, sadness, and embarrassment. This work is a first step toward quantifying situation-driven emotions with machines.},
	language = {en},
	number = {1},
	urldate = {2023-12-17},
	journal = {Scientific Reports},
	author = {He, Tianyou and Breithaupt, Fritz and Kübler, Sandra and Hills, Thomas T.},
	month = feb,
	year = {2023},
	pages = {2448},
	file = {s41598-023-29178-8.pdf:D\:\\Dokumente\\05 Uni\\7. Semester\\06 NLP\\Papers\\s41598-023-29178-8.pdf:application/pdf},
}

@inproceedings{bohra_smart_2022,
	address = {Mumbai, India},
	title = {Smart {Story} {Telling} {Model} with {Emotion}-{Based} {Enunciation} and an {Interactive} {Query} {Resolver}},
	isbn = {978-1-66542-168-3},
	url = {https://ieeexplore.ieee.org/document/9825363/},
	doi = {10.1109/I2CT54291.2022.9825363},
	abstract = {Emotion detection from text is a field of research that involves the recognition of emotions such as anger, disgust, fear, happiness, sadness, and surprise from text. The conversion of text to audio with enunciation based on the detected emotions from text is a contemporary field of study that has short explorations done. The paper presents a methodology and design to classify the emotional affinity of sentences in the narrative domain of children’s fairytales using a transformer-based natural language processing technique called the BERT model for subsequent usage in the appropriate expressive rendering of text to speech synthesis using statistical models. The paper also presents a methodology to implement a question-answering system to resolve queries regarding the story by producing an audio clip containing the most appropriate answer extracted through a natural language processing technique called the ALBERT model. The model developed can detect emotions from text with an accuracy of 83\%, convert text to audio with emotion-based enunciation with an accuracy of 90\%, and the question-answering system produces an accuracy of 80\%. The future work will focus on increasing the features taken into consideration for manipulating neutral audio. Detection of sarcasm and handling of complex sentences having multiple emotions will also be included.},
	language = {en},
	urldate = {2023-12-17},
	booktitle = {2022 {IEEE} 7th {International} conference for {Convergence} in {Technology} ({I2CT})},
	publisher = {IEEE},
	author = {Bohra, Arushi and Sethi, Laksh and Nag, Karthik and Kanwal, Preet},
	month = apr,
	year = {2022},
	keywords = {gelesen},
	pages = {1--4},
	file = {Smart_Story_Telling_Model_with_Emotion-Based_Enunciation_and_an_Interactive_Query_Resolver.pdf:D\:\\Dokumente\\05 Uni\\7. Semester\\06 NLP\\Papers\\Smart_Story_Telling_Model_with_Emotion-Based_Enunciation_and_an_Interactive_Query_Resolver.pdf:application/pdf},
}

@article{triantafyllopoulos_overview_2023,
	title = {An {Overview} of {Affective} {Speech} {Synthesis} and {Conversion} in the {Deep} {Learning} {Era}},
	volume = {111},
	issn = {0018-9219, 1558-2256},
	url = {http://arxiv.org/abs/2210.03538},
	doi = {10.1109/JPROC.2023.3250266},
	abstract = {Speech is the fundamental mode of human communication, and its synthesis has long been a core priority in human-computer interaction research. In recent years, machines have managed to master the art of generating speech that is understandable by humans. But the linguistic content of an utterance encompasses only a part of its meaning. Affect, or expressivity, has the capacity to turn speech into a medium capable of conveying intimate thoughts, feelings, and emotions –aspects that are essential for engaging and naturalistic interpersonal communication. While the goal of imparting expressivity to synthesised utterances has so far remained elusive, following recent advances in text-to-speech synthesis, a paradigm shift is well under way in the ﬁelds of affective speech synthesis and conversion as well. Deep learning, as the technology which underlies most of the recent advances in artiﬁcial intelligence, is spearheading these efforts. In the present overview, we outline ongoing trends and summarise state-of-the-art approaches in an attempt to provide a comprehensive overview of this exciting ﬁeld.},
	language = {en},
	number = {10},
	urldate = {2023-12-29},
	journal = {Proceedings of the IEEE},
	author = {Triantafyllopoulos, Andreas and Schuller, Björn W. and İymen, Gökçe and Sezgin, Metin and He, Xiangheng and Yang, Zijiang and Tzirakis, Panagiotis and Liu, Shuo and Mertes, Silvan and André, Elisabeth and Fu, Ruibo and Tao, Jianhua},
	month = oct,
	year = {2023},
	note = {arXiv:2210.03538 [cs]},
	keywords = {gelesen, Computer Science - Machine Learning, Computer Science - Sound},
	pages = {1355--1381},
	annote = {Comment: Submitted to the Proceedings of IEEE},
	file = {An_Overview_of_Affective_Speech_Synthesis_and_Conv.pdf:D\:\\Dokumente\\05 Uni\\7. Semester\\06 NLP\\Papers\\An_Overview_of_Affective_Speech_Synthesis_and_Conv.pdf:application/pdf},
}

@book{hogan_literature_2018,
	address = {London},
	series = {Literature and contemporary thought},
	title = {Literature and emotion},
	isbn = {978-1-138-18520-3 978-1-138-18521-0},
	language = {en},
	publisher = {Routledge, Taylor \& Francis group},
	author = {Hogan, Patrick Colm},
	year = {2018},
	file = {9781315644639_previewpdf.pdf:D\:\\Dokumente\\05 Uni\\7. Semester\\06 NLP\\Papers\\9781315644639_previewpdf.pdf:application/pdf},
}

@article{kaplanski_automated_2017,
	title = {Automated reasoning based user interface},
	volume = {71},
	issn = {09574174},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0957417416306686},
	doi = {10.1016/j.eswa.2016.11.033},
	language = {en},
	urldate = {2024-03-17},
	journal = {Expert Systems with Applications},
	author = {Kapłański, Paweł and Seganti, Alessandro and Cieśliński, Krzysztof and Chrabrowa, Aleksandra and Ługowska, Iwona},
	month = apr,
	year = {2017},
	keywords = {gelesen, CNL},
	pages = {125--137},
	file = {1-s2.0-S0957417416306686-main.pdf:D\:\\Dokumente\\05 Uni\\8. Semester\\01 Großer Beleg\\Literaturrecherche\\Empfehlungen Paper Dr. Borgwardt\\1-s2.0-S0957417416306686-main.pdf:application/pdf},
}

@book{payne_semantic_2023,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {The {Semantic} {Web} – {ISWC} 2023: 22nd {International} {Semantic} {Web} {Conference}, {Athens}, {Greece}, {November} 6–10, 2023, {Proceedings}, {Part} {II}},
	volume = {14266},
	isbn = {978-3-031-47242-8 978-3-031-47243-5},
	shorttitle = {The {Semantic} {Web} – {ISWC} 2023},
	url = {https://link.springer.com/10.1007/978-3-031-47243-5},
	language = {en},
	urldate = {2024-03-17},
	publisher = {Springer Nature Switzerland},
	editor = {Payne, Terry R. and Presutti, Valentina and Qi, Guilin and Poveda-Villalón, María and Stoilos, Giorgos and Hollink, Laura and Kaoudi, Zoi and Cheng, Gong and Li, Juanzi},
	year = {2023},
	doi = {10.1007/978-3-031-47243-5},
	keywords = {gelesen},
	file = {978-3-031-47243-5.pdf:D\:\\Dokumente\\05 Uni\\8. Semester\\01 Großer Beleg\\Literaturrecherche\\Empfehlungen Paper Dr. Borgwardt\\978-3-031-47243-5.pdf:application/pdf},
}

@book{baroglio_reasoning_2008,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Reasoning {Web}: 4th {International} {Summer} {School} 2008, {Venice}, {Italy}, {September} 7-11, 2008, {Tutorial} {Lectures}},
	volume = {5224},
	isbn = {978-3-540-85656-6 978-3-540-85658-0},
	shorttitle = {Reasoning {Web}},
	url = {http://link.springer.com/10.1007/978-3-540-85658-0},
	language = {en},
	urldate = {2024-03-17},
	publisher = {Springer Berlin Heidelberg},
	editor = {Baroglio, Cristina and Bonatti, Piero A. and Małuszyński, Jan and Marchiori, Massimo and Polleres, Axel and Schaffert, Sebastian},
	year = {2008},
	doi = {10.1007/978-3-540-85658-0},
	keywords = {gelesen, CNL},
	file = {978-3-540-85658-0.pdf:D\:\\Dokumente\\05 Uni\\8. Semester\\01 Großer Beleg\\Literaturrecherche\\Empfehlungen Paper Dr. Borgwardt\\978-3-540-85658-0.pdf:application/pdf},
}

@article{wong_ontology_2012,
	title = {Ontology learning from text: {A} look back and into the future},
	volume = {44},
	issn = {0360-0300, 1557-7341},
	shorttitle = {Ontology learning from text},
	url = {https://dl.acm.org/doi/10.1145/2333112.2333115},
	doi = {10.1145/2333112.2333115},
	abstract = {Ontologies are often viewed as the answer to the need for interoperable semantics in modern information systems. The explosion of textual information on the Read/Write Web coupled with the increasing demand for ontologies to power the Semantic Web have made (semi-)automatic ontology learning from text a very promising research area. This together with the advanced state in related areas, such as natural language processing, have fueled research into ontology learning over the past decade. This survey looks at how far we have come since the turn of the millennium and discusses the remaining challenges that will define the research directions in this area in the near future.},
	language = {en},
	number = {4},
	urldate = {2024-03-17},
	journal = {ACM Computing Surveys},
	author = {Wong, Wilson and Liu, Wei and Bennamoun, Mohammed},
	month = aug,
	year = {2012},
	keywords = {gelesen},
	pages = {1--36},
	file = {2333112.2333115.pdf:D\:\\Dokumente\\05 Uni\\8. Semester\\01 Großer Beleg\\Literaturrecherche\\Empfehlungen Paper Dr. Borgwardt\\2333112.2333115.pdf:application/pdf},
}

@article{murray_fundamental_1999,
	title = {Fundamental issues in questionnaire design},
	volume = {7},
	issn = {09652302},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0965230299800745},
	doi = {10.1016/S0965-2302(99)80074-5},
	language = {en},
	number = {3},
	urldate = {2024-03-17},
	journal = {Accident and Emergency Nursing},
	author = {Murray, P.},
	month = jul,
	year = {1999},
	keywords = {gelesen},
	pages = {148--153},
	file = {1-s2.0-S0965230299800745-main.pdf:D\:\\Dokumente\\05 Uni\\8. Semester\\01 Großer Beleg\\Literaturrecherche\\Fragebogen Typen\\1-s2.0-S0965230299800745-main.pdf:application/pdf},
}

@article{greco_questionnaire_1987,
	title = {Questionnaire development: 1. {Formulation}},
	volume = {136},
	language = {en},
	journal = {Clinical Epidemiology},
	author = {Greco, Linda Del and Walop, Wikke},
	year = {1987},
	keywords = {gelesen},
	file = {cmaj00138-0033.pdf:D\:\\Dokumente\\05 Uni\\8. Semester\\01 Großer Beleg\\Literaturrecherche\\Fragebogen Typen\\cmaj00138-0033.pdf:application/pdf},
}

@article{colosi_designing_2006,
	title = {Designing an {Effective} {Questionnaire}},
	abstract = {When writing questions for an evaluative survey, it is important to recall the objective of the program delivered, and the information required to measure the success in meeting the objectives. Educators need also to focus on the type of information needed to assess the program impact, deciding whether to include knowledge, attitudes, skills and/or behavior. Good survey design also includes attention to the audience completing the questions (e.g., literacy, language, etc.), and the purpose of the question (outcome data, qualitative feedback, satisfaction with the program and/or audience demographics). The flow of the entire questionnaire is also critical, and educators need to ensure that each question is clear and the directions are equally easy to understand. Most importantly, remember that the quality of the information gathered from a survey instrument is dependent on the clarity of each question asked on a questionnaire. This reinforces the importance of thoughtful design for questionnaires to capture and report the true experience and change of participants in programs.},
	language = {en},
	journal = {2006 Cornell Cooperative Extension},
	author = {Colosi, Laura},
	year = {2006},
	keywords = {gelesen},
	file = {Colosi - 2002 - Designing an Effective Questionnaire.pdf:D\:\\Dokumente\\05 Uni\\8. Semester\\01 Großer Beleg\\Literaturrecherche\\Fragebogen Typen\\Colosi - 2002 - Designing an Effective Questionnaire.pdf:application/pdf},
}

@article{kohler_gesundheitsberichterstattung_2005,
	title = {Gesundheitsberichterstattung des {Bundes}},
	language = {de},
	journal = {Robert Koch Institut},
	author = {Kohler, Martin and Rieck, Angelika and Borch, Susan and Ziese, Thomas},
	year = {2005},
	keywords = {gelesen},
	file = {gstel_methoden.pdf:D\:\\Dokumente\\05 Uni\\8. Semester\\01 Großer Beleg\\Literaturrecherche\\Fragebogen Typen\\gstel_methoden.pdf:application/pdf},
}

@book{bowling_handbook_2009,
	address = {Maidenhead},
	edition = {Reprinted},
	title = {Handbook of health research methods: investigation, measurement and analysis},
	isbn = {978-0-335-21460-0 978-0-335-21461-7},
	shorttitle = {Handbook of health research methods},
	language = {en},
	publisher = {Open Univ. Press},
	editor = {Bowling, Ann},
	year = {2009},
	keywords = {gelesen},
	annote = {394
},
	annote = {424
},
	file = {Handbook of Research Methods in Health by Ann Bowling, Shah Ebrahim (z-lib.org).pdf:D\:\\Dokumente\\05 Uni\\8. Semester\\01 Großer Beleg\\Literaturrecherche\\Fragebogen Typen\\Handbook of Research Methods in Health by Ann Bowling, Shah Ebrahim (z-lib.org).pdf:application/pdf},
}

@book{miller_handbook_1999,
	address = {New York},
	series = {Public administration and public policy},
	title = {Handbook of research methods in public administration},
	isbn = {978-0-8247-0213-7},
	language = {en},
	number = {71},
	publisher = {M. Dekker},
	editor = {Miller, Gerald and Whicker, Marcia Lynn},
	year = {1999},
	keywords = {gelesen},
	annote = {87
},
	file = {Handbook-of-Research-Methods-in-Public-Administration-Analytics.NG_.pdf:D\:\\Dokumente\\05 Uni\\8. Semester\\01 Großer Beleg\\Literaturrecherche\\Fragebogen Typen\\Handbook-of-Research-Methods-in-Public-Administration-Analytics.NG_.pdf:application/pdf},
}

@article{leung_how_2001,
	title = {How to design a questionnaire},
	volume = {322},
	issn = {1756-1833},
	url = {https://www.bmj.com/lookup/doi/10.1136/sbmj.0106187},
	doi = {10.1136/sbmj.0106187},
	language = {en},
	number = {Suppl S6},
	urldate = {2024-03-17},
	journal = {BMJ},
	author = {Leung, Wai-Ching},
	month = jun,
	year = {2001},
	keywords = {gelesen},
	pages = {0106187},
	file = {How to design a questionnaire _ The BMJ.pdf:D\:\\Dokumente\\05 Uni\\8. Semester\\01 Großer Beleg\\Literaturrecherche\\Fragebogen Typen\\How to design a questionnaire _ The BMJ.pdf:application/pdf},
}

@book{noauthor_notitle_nodate,
}

@article{bidhan_questionnaire_2010,
	title = {Questionnaire {Design}},
	journal = {University Grants Commission Nepal},
	author = {Bidhan, Acharya},
	year = {2010},
	keywords = {gelesen},
	file = {6.4 Questionnaire Design_Acharya Bidhan.pdf:D\:\\Dokumente\\05 Uni\\8. Semester\\01 Großer Beleg\\Literaturrecherche\\Fragebogen Typen\\6.4 Questionnaire Design_Acharya Bidhan.pdf:application/pdf},
}

@article{murray_fundamental_1999-1,
	title = {Fundamental issues in questionnaire design},
	volume = {7},
	issn = {09652302},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0965230299800745},
	doi = {10.1016/S0965-2302(99)80074-5},
	language = {en},
	number = {3},
	urldate = {2024-03-18},
	journal = {Accident and Emergency Nursing},
	author = {Murray, P.},
	month = jul,
	year = {1999},
	pages = {148--153},
	file = {1-s2.0-S0965230299800745-main.pdf:D\:\\Dokumente\\05 Uni\\8. Semester\\01 Großer Beleg\\Literaturrecherche\\Fragebogen Typen\\1-s2.0-S0965230299800745-main.pdf:application/pdf},
}

@article{greco_questionnaire_1987-1,
	title = {Questionnaire development: 1. {Formulation}},
	volume = {136},
	language = {en},
	author = {Greco, Linda Del and Walop, Wikke},
	year = {1987},
	file = {cmaj00138-0033.pdf:D\:\\Dokumente\\05 Uni\\8. Semester\\01 Großer Beleg\\Literaturrecherche\\Fragebogen Typen\\cmaj00138-0033.pdf:application/pdf},
}

@article{colosi_designing_nodate,
	title = {Designing an {Effective} {Questionnaire}},
	abstract = {When writing questions for an evaluative survey, it is important to recall the objective of the program delivered, and the information required to measure the success in meeting the objectives. Educators need also to focus on the type of information needed to assess the program impact, deciding whether to include knowledge, attitudes, skills and/or behavior. Good survey design also includes attention to the audience completing the questions (e.g., literacy, language, etc.), and the purpose of the question (outcome data, qualitative feedback, satisfaction with the program and/or audience demographics). The flow of the entire questionnaire is also critical, and educators need to ensure that each question is clear and the directions are equally easy to understand. Most importantly, remember that the quality of the information gathered from a survey instrument is dependent on the clarity of each question asked on a questionnaire. This reinforces the importance of thoughtful design for questionnaires to capture and report the true experience and change of participants in programs.},
	language = {en},
	author = {Colosi, Laura},
	file = {Colosi - 2002 - Designing an Effective Questionnaire.pdf:D\:\\Dokumente\\05 Uni\\8. Semester\\01 Großer Beleg\\Literaturrecherche\\Fragebogen Typen\\Colosi - 2002 - Designing an Effective Questionnaire.pdf:application/pdf},
}

@article{kohler_gesundheitsberichterstattung_nodate,
	title = {Gesundheitsberichterstattung des {Bundes}},
	language = {de},
	author = {Kohler, Martin and Rieck, Angelika and Borch, Susan and Ziese, Thomas},
	file = {gstel_methoden.pdf:D\:\\Dokumente\\05 Uni\\8. Semester\\01 Großer Beleg\\Literaturrecherche\\Fragebogen Typen\\gstel_methoden.pdf:application/pdf},
}

@book{bowling_handbook_2009-1,
	address = {Maidenhead},
	edition = {Reprinted},
	title = {Handbook of health research methods: investigation, measurement and analysis},
	isbn = {978-0-335-21460-0 978-0-335-21461-7},
	shorttitle = {Handbook of health research methods},
	language = {en},
	publisher = {Open Univ. Press},
	editor = {Bowling, Ann},
	year = {2009},
	file = {Handbook of Research Methods in Health by Ann Bowling, Shah Ebrahim (z-lib.org).pdf:D\:\\Dokumente\\05 Uni\\8. Semester\\01 Großer Beleg\\Literaturrecherche\\Fragebogen Typen\\Handbook of Research Methods in Health by Ann Bowling, Shah Ebrahim (z-lib.org).pdf:application/pdf},
}

@book{miller_handbook_1999-1,
	address = {New York},
	series = {Public administration and public policy},
	title = {Handbook of research methods in public administration},
	isbn = {978-0-8247-0213-7},
	language = {en},
	number = {71},
	publisher = {M. Dekker},
	editor = {Miller, Gerald and Whicker, Marcia Lynn},
	year = {1999},
	keywords = {Public administration, Research Methodology},
	file = {Handbook-of-Research-Methods-in-Public-Administration-Analytics.NG_.pdf:D\:\\Dokumente\\05 Uni\\8. Semester\\01 Großer Beleg\\Literaturrecherche\\Fragebogen Typen\\Handbook-of-Research-Methods-in-Public-Administration-Analytics.NG_.pdf:application/pdf},
}

@article{leung_how_2001-1,
	title = {How to design a questionnaire},
	volume = {322},
	issn = {1756-1833},
	url = {https://www.bmj.com/lookup/doi/10.1136/sbmj.0106187},
	doi = {10.1136/sbmj.0106187},
	language = {en},
	number = {Suppl S6},
	urldate = {2024-03-18},
	journal = {BMJ},
	author = {Leung, Wai-Ching},
	month = jun,
	year = {2001},
	pages = {0106187},
	file = {How to design a questionnaire _ The BMJ.pdf:D\:\\Dokumente\\05 Uni\\8. Semester\\01 Großer Beleg\\Literaturrecherche\\Fragebogen Typen\\How to design a questionnaire _ The BMJ.pdf:application/pdf},
}

@article{lang_role_1990,
	title = {The role of questioning in knowledge engineering and the interface of expert systems},
	volume = {19},
	issn = {0304422X},
	url = {https://linkinghub.elsevier.com/retrieve/pii/0304422X90900343},
	doi = {10.1016/0304-422X(90)90034-3},
	language = {en},
	number = {1-2},
	urldate = {2024-03-18},
	journal = {Poetics},
	author = {Lang, Kathy L. and Graesser, Arthur C. and Hemphill, Darold D.},
	month = apr,
	year = {1990},
	keywords = {gelesen},
	pages = {143--166},
	file = {1-s2.0-0304422X90900343-main.pdf:D\:\\Dokumente\\05 Uni\\8. Semester\\01 Großer Beleg\\Literaturrecherche\\Knowledge Acquisition\\1-s2.0-0304422X90900343-main.pdf:application/pdf},
}

@article{borst_engineering_1997,
	title = {Engineering ontologies},
	volume = {46},
	issn = {10715819},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1071581996900968},
	doi = {10.1006/ijhc.1996.0096},
	language = {en},
	number = {2-3},
	urldate = {2024-03-18},
	journal = {International Journal of Human-Computer Studies},
	author = {Borst, Pim and Akkermans, Hans and Top, Jan},
	month = feb,
	year = {1997},
	keywords = {irrelevant},
	pages = {365--406},
	file = {1-s2.0-S1071581996900968-main.pdf:D\:\\Dokumente\\05 Uni\\8. Semester\\01 Großer Beleg\\Literaturrecherche\\Knowledge Acquisition\\1-s2.0-S1071581996900968-main.pdf:application/pdf},
}

@book{almeida_conceptual_2023,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Conceptual {Modeling}: 42nd {International} {Conference}, {ER} 2023, {Lisbon}, {Portugal}, {November} 6–9, 2023, {Proceedings}},
	volume = {14320},
	isbn = {978-3-031-47261-9 978-3-031-47262-6},
	shorttitle = {Conceptual {Modeling}},
	url = {https://link.springer.com/10.1007/978-3-031-47262-6},
	language = {en},
	urldate = {2024-03-18},
	publisher = {Springer Nature Switzerland},
	editor = {Almeida, João Paulo A. and Borbinha, José and Guizzardi, Giancarlo and Link, Sebastian and Zdravkovic, Jelena},
	year = {2023},
	doi = {10.1007/978-3-031-47262-6},
	keywords = {irrelevant},
	file = {978-3-031-47262-6.pdf:D\:\\Dokumente\\05 Uni\\8. Semester\\01 Großer Beleg\\Literaturrecherche\\Knowledge Acquisition\\978-3-031-47262-6.pdf:application/pdf},
}

@book{presutti_semantic_2014,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {The {Semantic} {Web}: {Trends} and {Challenges}: 11th {International} {Conference}, {ESWC} 2014, {Anissaras}, {Crete}, {Greece}, {May} 25-29, 2014. {Proceedings}},
	volume = {8465},
	isbn = {978-3-319-07442-9 978-3-319-07443-6},
	shorttitle = {The {Semantic} {Web}},
	url = {http://link.springer.com/10.1007/978-3-319-07443-6},
	abstract = {The 11th edition of ESWC took place in Crete (Greece), during May 25–29, 2014. Its exciting program included three keynotes by: Steﬀen Staab (Universita¨t Koblenz-Landau), Luciano Floridi (University of Oxford), and Lise Getoor (University of Maryland). The main scientiﬁc program of the conference comprised 50 papers: 41 research and nine in-use, selected out of 204 submissions, which corresponds to an acceptance rate of 23\% for research papers, and of 34.6\% for in-use papers. The program was completed by a demonstration and poster session, in which researchers had the chance to present their latest results and advances in the form of live demos. In addition, the conference program included 13 workshops, eight tutorials, as well as a PhD Symposium, the AI Mashup Challenge, the LinkedUp Challenge, the Semantic Web Evaluation Track (featuring three challenges), the EU Project Networking session and a panel on “data protection and security on the Web.” The PhD Symposium program included 11 contributions, selected out of 15 submissions.},
	language = {en},
	urldate = {2024-03-18},
	publisher = {Springer International Publishing},
	editor = {Presutti, Valentina and d’Amato, Claudia and Gandon, Fabien and d’Aquin, Mathieu and Staab, Steffen and Tordai, Anna and Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Kobsa, Alfred and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Terzopoulos, Demetri and Tygar, Doug and Weikum, Gerhard},
	year = {2014},
	doi = {10.1007/978-3-319-07443-6},
	keywords = {gelesen},
	annote = {752
},
	file = {978-3-319-07443-6.pdf:D\:\\Dokumente\\05 Uni\\8. Semester\\01 Großer Beleg\\Literaturrecherche\\Knowledge Acquisition\\978-3-319-07443-6.pdf:application/pdf},
}

@misc{rodler_new_2022,
	title = {A {New} {Expert} {Questioning} {Approach} to {More} {Efficient} {Fault} {Localization} in {Ontologies}},
	url = {http://arxiv.org/abs/1904.00317},
	abstract = {When ontologies reach a certain size and complexity, faults such as inconsistencies, unsatisﬁable classes or wrong entailments are hardly avoidable. Locating the incorrect axioms that cause these faults is a hard and time-consuming task. Addressing this issue, several techniques for semi-automatic fault localization in ontologies have been proposed. Often, these approaches involve a human expert who provides answers to system-generated questions about the intended (correct) ontology in order to reduce the possible fault locations. To suggest as informative questions as possible, existing methods draw on various algorithmic optimizations as well as heuristics. However, these computations are often based on certain assumptions about the interacting user.},
	language = {en},
	urldate = {2024-03-18},
	publisher = {arXiv},
	author = {Rodler, Patrick and Eichholzer, Michael},
	month = aug,
	year = {2022},
	note = {arXiv:1904.00317 [cs]},
	keywords = {irrelevant},
	annote = {Comment: This is a preprint of the article "Patrick Rodler. One step at a time: An efficient approach to query-based ontology debugging. Knowledge-Based Systems 108987, 2022."},
	file = {1904.00317.pdf:D\:\\Dokumente\\05 Uni\\8. Semester\\01 Großer Beleg\\Literaturrecherche\\Knowledge Acquisition\\1904.00317.pdf:application/pdf},
}

@article{goos_automatic_2006,
	title = {Automatic {Extraction} of {Hierarchical} {Relations} from {Text}},
	language = {en},
	journal = {Lecture Notes in Computer Science},
	author = {Goos, Gerhard and Hartmanis, Juris and van Leeuwen, Jan and Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M and Mattern, Friedemann and Mitchell, John C and Naor, Moni and Nierstrasz, Oscar and Rangan, C Pandu and Steffen, Bernhard},
	year = {2006},
	keywords = {gelesen},
	file = {11762256.pdf:D\:\\Dokumente\\05 Uni\\8. Semester\\01 Großer Beleg\\Literaturrecherche\\Knowledge Acquisition\\11762256.pdf:application/pdf},
}

@article{chan_knowledge_2002,
	title = {Knowledge acquisition and ontology modelling for construction of a control and monitoring expert system},
	volume = {33},
	issn = {0020-7721, 1464-5319},
	url = {http://www.tandfonline.com/doi/abs/10.1080/00207720210133679},
	doi = {10.1080/00207720210133679},
	language = {en},
	number = {6},
	urldate = {2024-03-18},
	journal = {International Journal of Systems Science},
	author = {Chan, C. W. and Peng, Yao and Chen, Lin-Li},
	month = jan,
	year = {2002},
	keywords = {gelesen},
	pages = {485--503},
	file = {Knowledge acquisition and ontology modelling for construction of a control and monitoring expert system.pdf:D\:\\Dokumente\\05 Uni\\8. Semester\\01 Großer Beleg\\Literaturrecherche\\Knowledge Acquisition\\Knowledge acquisition and ontology modelling for construction of a control and monitoring expert system.pdf:application/pdf},
}

@book{payne_semantic_2023-1,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {The {Semantic} {Web} – {ISWC} 2023: 22nd {International} {Semantic} {Web} {Conference}, {Athens}, {Greece}, {November} 6–10, 2023, {Proceedings}, {Part} {I}},
	volume = {14265},
	isbn = {978-3-031-47239-8 978-3-031-47240-4},
	shorttitle = {The {Semantic} {Web} – {ISWC} 2023},
	url = {https://link.springer.com/10.1007/978-3-031-47240-4},
	language = {en},
	urldate = {2024-03-18},
	publisher = {Springer Nature Switzerland},
	editor = {Payne, Terry R. and Presutti, Valentina and Qi, Guilin and Poveda-Villalón, María and Stoilos, Giorgos and Hollink, Laura and Kaoudi, Zoi and Cheng, Gong and Li, Juanzi},
	year = {2023},
	doi = {10.1007/978-3-031-47240-4},
	keywords = {überflogen},
	annote = {408
},
	file = {978-3-031-47240-4.pdf:D\:\\Dokumente\\05 Uni\\8. Semester\\01 Großer Beleg\\Literaturrecherche\\Current Research\\978-3-031-47240-4.pdf:application/pdf},
}

@misc{caufield_structured_2023,
	title = {Structured prompt interrogation and recursive extraction of semantics ({SPIRES}): {A} method for populating knowledge bases using zero-shot learning},
	shorttitle = {Structured prompt interrogation and recursive extraction of semantics ({SPIRES})},
	url = {http://arxiv.org/abs/2304.02711},
	abstract = {Creating knowledge bases and ontologies is a time consuming task that relies on manual curation. AI/NLP approaches can assist expert curators in populating these knowledge bases, but current approaches rely on extensive training data, and are not able to populate arbitrarily complex nested knowledge schemas.},
	language = {en},
	urldate = {2024-03-18},
	publisher = {arXiv},
	author = {Caufield, J. Harry and Hegde, Harshad and Emonet, Vincent and Harris, Nomi L. and Joachimiak, Marcin P. and Matentzoglu, Nicolas and Kim, HyeongSik and Moxon, Sierra A. T. and Reese, Justin T. and Haendel, Melissa A. and Robinson, Peter N. and Mungall, Christopher J.},
	month = dec,
	year = {2023},
	note = {arXiv:2304.02711 [cs]},
	keywords = {gelesen},
	annote = {Comment: Updated 2023-12-22},
	file = {2304.02711v2.pdf:D\:\\Dokumente\\05 Uni\\8. Semester\\01 Großer Beleg\\Literaturrecherche\\Current Research\\2304.02711v2.pdf:application/pdf},
}

@article{sivoronova_academics_2024,
	title = {Academics’ {Epistemological} {Attitudes} toward {Sources} of {Knowledge} {Questionnaire}},
	volume = {19},
	issn = {2327-011X, 2327-2570},
	url = {https://cgscholar.com/bookstore/works/academics-epistemological-attitudes-toward-sources-of-knowledge-questionnaire},
	doi = {10.18848/2327-011X/CGP/v19i02/1-24},
	abstract = {The role of knowledge and its sources in the academic field is central to cognition and action. The present research provides a theoretical and methodological viewpoint on evaluating sources of knowledge. This article presents a novel model and method for studying the epistemological attitudes (EAs) of academics toward sources of knowledge. The EA is an epistemological phenomenon and mechanism presenting the cognition of knowledge sources as a process occurring in epistemological, contextual, and subjective realms. Adhering to the model, the EA incorporates four concepts that embody the epistemological strategy and epistemological approach for knowledge acquisition, the context of relevant usage, the motivation for utilizing the source, and the inherent personal value acquired. Based on the model, a new method has been developed to study the sources of knowledge used by academics and represent their constructs. The development process consisted of three stages: formal, substantive, and procedural. In the formal and substantive stages, the content and methodology were developed, and in the procedural stage, the appropriateness of the content was assessed by adapting the expert review approach. A panel of seven experts comprising university academics and subject-matter experts in philosophy, methodology, education research, and psychology participated in the expert review study. The results present the experts’ analysis of the method regarding the content validity index (CVI). A questionnaire that explores academics’ EAs toward various sources of knowledge has been developed. The method reflects how well knowledge sources transfer objective and meta-knowledge dimensions. These help determine essential sources for education, research, and science.},
	language = {en},
	number = {2},
	urldate = {2024-03-18},
	journal = {The International Journal of Interdisciplinary Educational Studies},
	author = {Sivoronova, Jevgenija and Vorobjovs, Aleksejs},
	year = {2024},
	keywords = {irrelevant},
	pages = {1--24},
	file = {watermarked_academics-epistemological-attitudes-toward-sources-of-knowledge-questionnaire_jan-16-2024-04-46-11.pdf:D\:\\Dokumente\\05 Uni\\8. Semester\\01 Großer Beleg\\Literaturrecherche\\Current Research\\watermarked_academics-epistemological-attitudes-toward-sources-of-knowledge-questionnaire_jan-16-2024-04-46-11.pdf:application/pdf},
}

@article{mizoguchi_knowledge_1993,
	title = {Knowledge {Acquisition} {Ontology}},
	journal = {KB\&KS'93},
	author = {Mizoguchi, Riichiri},
	year = {1993},
	keywords = {gelesen},
	file = {KnowledgeAckOntologyKBKS93.PDF:D\:\\Dokumente\\05 Uni\\8. Semester\\01 Großer Beleg\\Literaturrecherche\\Knowledge Acquisition\\KnowledgeAckOntologyKBKS93.PDF:application/pdf},
}

@article{wawrzik_ontology_2023,
	title = {Ontology {Learning} {Applications} of {Knowledge} {Base} {Construction} for {Microelectronic} {Systems} {Information}},
	volume = {14},
	issn = {2078-2489},
	url = {https://www.mdpi.com/2078-2489/14/3/176},
	doi = {10.3390/info14030176},
	abstract = {Knowledge base construction (KBC) using AI has been one of the key goals of this highly popular technology since its emergence, as it helps to comprehend everything, including relations, around us. The construction of knowledge bases can summarize a piece of text in a machineprocessable and understandable way. This can prove to be valuable and assistive to knowledge engineers. In this paper, we present the application of natural language processing in the construction of knowledge bases. We demonstrate how a trained bidirectional long short-term memory or biLSTM neural network model can be used to construct knowledge bases in accordance with the exact ISO26262 deﬁnitions as deﬁned in the GENIAL! Basic Ontology. We provide the system with an electronic text document from the microelectronics domain and the system attempts to create a knowledge base from the available information in textual format. This information is then expressed in the form of graphs when queried by the user. This method of information retrieval presents the user with a much more technical and comprehensive understanding of an expert piece of text. This is achieved by applying the process of named entity recognition (NER) for knowledge extraction. This paper provides a result report of the current status of our knowledge construction process and knowledge base content, as well as describes our challenges and experiences.},
	language = {en},
	number = {3},
	urldate = {2024-03-18},
	journal = {Information},
	author = {Wawrzik, Frank and Rafique, Khushnood Adil and Rahman, Farin and Grimm, Christoph},
	month = mar,
	year = {2023},
	keywords = {irrelevant},
	pages = {176},
	file = {information-14-00176.pdf:D\:\\Dokumente\\05 Uni\\8. Semester\\01 Großer Beleg\\Literaturrecherche\\Current Research\\information-14-00176.pdf:application/pdf},
}

@article{spoladore_novel_2023,
	title = {A novel agile ontology engineering methodology for supporting organizations in collaborative ontology development},
	volume = {151},
	issn = {01663615},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S016636152300129X},
	doi = {10.1016/j.compind.2023.103979},
	abstract = {Ontologies can represent technological enablers for knowledge elicitation and management in different kinds of organizations, especially with the exponential growth of sources and types of data fostered by digital trans­ formation. However, their adoption in business applications is still limited, with existing Ontology Engineering Methodologies (OEMs) lacking adequate support during knowledge elicitation, authoring and reuse phases. This paper introduces a novel agile ontology engineering methodology (AgiSCOnt) to support ontologists (especially novice ones) in ontology development workflow, fostering collaboration with domain experts in an iterative, flexible and customizable approach. AgiSCOnt combines macro-level instructions with micro-level guidance, leveraging existing techniques and a management framework to help novice ontologists throughout the whole ontology engineering process. The methodology is compared to existing OEMs and assessed with three other agile methodologies (UPONLite, SAMOD, and RapidOWL). The evaluation is conducted with a sample of novice ontologists in a learning environment on Industry 4.0 technologies. Both the development process with a methodology from a user perspective and the quality of the developed ontologies were considered in the eval­ uation. Preliminary results show that AgiSCOnt effectively supports authoring and reuse, with developed on­ tologies of good quality. It is perceived as clear and simple, while being flexible and adaptable enough, thus supporting knowledge management and sharing in industrial organizations through the documentation of the ontologies.},
	language = {en},
	urldate = {2024-03-18},
	journal = {Computers in Industry},
	author = {Spoladore, Daniele and Pessot, Elena and Trombetta, Alberto},
	month = oct,
	year = {2023},
	keywords = {überflogen},
	pages = {103979},
	file = {1-s2.0-S016636152300129X-main.pdf:D\:\\Dokumente\\05 Uni\\8. Semester\\01 Großer Beleg\\Literaturrecherche\\Current Research\\1-s2.0-S016636152300129X-main.pdf:application/pdf},
}

@article{eriksson_generation_1994,
	title = {Generation of knowledge-acquisition tool from domain ontologies},
	journal = {Human-Computer Studies},
	author = {Eriksson, Henrik},
	year = {1994},
	keywords = {gelesen},
	file = {1-s2.0-S1071581984710676-main.pdf:D\:\\Dokumente\\05 Uni\\8. Semester\\01 Großer Beleg\\Literaturrecherche\\Knowledge Acquisition\\1-s2.0-S1071581984710676-main.pdf:application/pdf},
}

@article{yin_deep_2023,
	title = {A deep natural language processing-based method for ontology learning of project-specific properties from building information models},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/mice.13013},
	journal = {Computer‐Aided Civil and Infrastructure Engineering},
	author = {Yin, Mengtian},
	year = {2023},
	keywords = {überflogen},
	file = {Computer aided Civil Eng - 2023 - Yin - A deep natural language processing‐based method for ontology learning of.pdf:D\:\\Dokumente\\05 Uni\\8. Semester\\01 Großer Beleg\\Literaturrecherche\\Current Research\\Computer aided Civil Eng - 2023 - Yin - A deep natural language processing‐based method for ontology learning of.pdf:application/pdf},
}

@article{gutierrez_knowledge_2021,
	title = {Knowledge graphs},
	volume = {64},
	issn = {0001-0782, 1557-7317},
	url = {https://dl.acm.org/doi/10.1145/3418294},
	doi = {10.1145/3418294},
	abstract = {Tracking the historical events that lead to the interweaving of data and knowledge.},
	language = {en},
	number = {3},
	urldate = {2024-04-08},
	journal = {Communications of the ACM},
	author = {Gutierrez, Claudio and Sequeda, Juan F.},
	month = mar,
	year = {2021},
	keywords = {gelesen},
	pages = {96--104},
	file = {3418294.pdf:D\:\\Dokumente\\05 Uni\\8. Semester\\01 Großer Beleg\\Literaturrecherche\\Current Research\\3418294.pdf:application/pdf},
}

@article{department_of_computer_science_federal_university_of_technology_minna_nigeria_review_2020,
	title = {A {Review} on {Ontology} {Development} {Methodologies} for {Developing} {Ontological} {Knowledge} {Representation} {Systems} for various {Domains}},
	volume = {12},
	issn = {20749023, 20749031},
	url = {http://www.mecs-press.org/ijieeb/ijieeb-v12-n2/v12n2-5.html},
	doi = {10.5815/ijieeb.2020.02.05},
	abstract = {The success of machine represented web known as semantic web largely hinges on ontologies. Ontology is a data modeling technique for structured data repository premised on collection of concepts with their semantic relationships and constraints on domain. There are existing methodologies to aid ontology development process. However, there is no single correct ontology design methodology. Therefore, this paper aims to present a review on existing ontology development approaches for different domains with the goal of identifying individual methodology’s weakness and suggests for hybridization in order to strengthen ontology development in terms of its content and constructions correctness. The analysis and comparison of the review were carried out by considering these criteria but not limited to: activities of each method, the initial domain of the methodology, ontology created from scratch or reuse, frequently used ontology management tools based on literature, subject granularity, and usage across different platforms. This review based on the literature showed some approaches that exhibit the required principles of ontology engineering in tandem with software development principles. Nonetheless, the review still noted some gaps among the methodologies that when bridged or hybridized a better correctness of ontology development would be achieved in building intelligent system.},
	language = {en},
	number = {2},
	urldate = {2024-04-08},
	journal = {International Journal of Information Engineering and Electronic Business},
	author = {{Department of Computer Science, Federal University of Technology Minna, Nigeria} and Femi Aminu, Enesi and Oyefolahan, Ishaq Oyebisi and Bashir Abdullahi, Muhammad and Salaudeen, Muhammadu Tajudeen},
	month = apr,
	year = {2020},
	keywords = {gelesen},
	pages = {28--39},
	file = {A Review on Ontology Development.pdf:D\:\\Dokumente\\05 Uni\\8. Semester\\01 Großer Beleg\\Literaturrecherche\\Current Research\\A Review on Ontology Development.pdf:application/pdf},
}

@article{ji_survey_2022,
	title = {A {Survey} on {Knowledge} {Graphs}: {Representation}, {Acquisition}, and {Applications}},
	volume = {33},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	issn = {2162-237X, 2162-2388},
	shorttitle = {A {Survey} on {Knowledge} {Graphs}},
	url = {https://ieeexplore.ieee.org/document/9416312/},
	doi = {10.1109/TNNLS.2021.3070843},
	abstract = {Human knowledge provides a formal understanding of the world. Knowledge graphs that represent structural relations between entities have become an increasingly popular research direction toward cognition and human-level intelligence. In this survey, we provide a comprehensive review of the knowledge graph covering overall research topics about: 1) knowledge graph representation learning; 2) knowledge acquisition and completion; 3) temporal knowledge graph; and 4) knowledgeaware applications and summarize recent breakthroughs and perspective directions to facilitate future research. We propose a full-view categorization and new taxonomies on these topics. Knowledge graph embedding is organized from four aspects of representation space, scoring function, encoding models, and auxiliary information. For knowledge acquisition, especially knowledge graph completion, embedding methods, path inference, and logical rule reasoning are reviewed. We further explore several emerging topics, including metarelational learning, commonsense reasoning, and temporal knowledge graphs. To facilitate future research on knowledge graphs, we also provide a curated collection of data sets and open-source libraries on different tasks. In the end, we have a thorough outlook on several promising research directions.},
	language = {en},
	number = {2},
	urldate = {2024-04-08},
	journal = {IEEE Transactions on Neural Networks and Learning Systems},
	author = {Ji, Shaoxiong and Pan, Shirui and Cambria, Erik and Marttinen, Pekka and Yu, Philip S.},
	month = feb,
	year = {2022},
	keywords = {gelesen},
	pages = {494--514},
	file = {A_Survey_on_Knowledge_Graphs_Representation_Acquisition_and_Applications.pdf:D\:\\Dokumente\\05 Uni\\8. Semester\\01 Großer Beleg\\Literaturrecherche\\Current Research\\A_Survey_on_Knowledge_Graphs_Representation_Acquisition_and_Applications.pdf:application/pdf},
}

@article{li_theoryon_2020,
	title = {{TheoryOn}: {A} {Design} {Framework} and {System} for {Unlocking} {Behavioral} {Knowledge} {Through} {Ontology} {Learning}},
	volume = {44},
	issn = {02767783, 21629730},
	shorttitle = {{TheoryOn}},
	url = {https://misq.org/theoryon-a-design-framework-and-system-for-unlocking-behavioral-knowledge-through-ontology-learning.html},
	doi = {10.25300/MISQ/2020/15323},
	abstract = {The scholarly information-seeking process for behavioral research consists of three phases: searching, accessing, and processing of past research. Existing IT artifacts, such as Google Scholar, have in part addressed the searching and accessing phases, but fall short of facilitating the processing phase, creating a knowledge inaccessibility problem. We propose a behavioral ontology learning from text (BOLT) design framework that presents concrete prescriptions for developing systems capable of supporting researchers during their processing of behavioral knowledge. Based upon BOLT, we developed a search engine—TheoryOn—to allow researchers to directly search for constructs, construct relationships, antecedents, and consequents, and to easily integrate related theories. Our design framework and search engine were rigorously evaluated through a series of data mining experiments, a randomized user experiment, and an applicability check. The data mining experiment results lent credence to the design principles prescribed by BOLT. The randomized experiment compared TheoryOn with EBSCOhost and Google Scholar across four information retrieval tasks, illustrating TheoryOn’s ability to reduce false positives and false negatives during the information-seeking process. Furthermore, an in-depth applicability check with IS scholars offered qualitative support for the efficacy of an ontology-based search and the usefulness of TheoryOn during the processing phase of existing research. The evaluation results collectively underscore the significance of our proposed design artifacts for addressing the knowledge inaccessibility problem for behavioral research literature.},
	language = {en},
	number = {4},
	urldate = {2024-04-08},
	journal = {MIS Quarterly},
	author = {Li, Jingjing and Larsen, Kai and Abbasi, Ahmed},
	month = dec,
	year = {2020},
	keywords = {überflogen},
	pages = {1733--1772},
	file = {10282376.pdf:D\:\\Dokumente\\05 Uni\\8. Semester\\01 Großer Beleg\\Literaturrecherche\\Current Research\\10282376.pdf:application/pdf},
}

@article{al-aswadi_automatic_2020,
	title = {Automatic ontology construction from text: a review from shallow to deep learning trend},
	volume = {53},
	issn = {0269-2821, 1573-7462},
	shorttitle = {Automatic ontology construction from text},
	url = {http://link.springer.com/10.1007/s10462-019-09782-9},
	doi = {10.1007/s10462-019-09782-9},
	abstract = {The explosive growth of textual data on the web coupled with the increase on demand for ontologies to promote the semantic web, have made the automatic ontology construction from the text a very promising research area. Ontology learning (OL) from text is a process that aims to (semi-) automatically extract and represent the knowledge from text in machine-readable form. Ontology is considered one of the main cornerstones of representing the knowledge in a more meaningful way on the semantic web. Usage of ontologies has proven to be beneficial and efficient in different applications (e.g. information retrieval, information extraction, and question answering). Nevertheless, manually construction of ontologies is time-consuming as well extremely laborious and costly process. In recent years, many approaches and systems that try to automate the construction of ontologies have been developed. This paper reviews various approaches, systems, and challenges of automatic ontology construction from the text. In addition, it also discusses ways the ontology construction process could be enhanced in the future by presenting techniques from shallow learning to deep learning (DL).},
	language = {en},
	number = {6},
	urldate = {2024-04-08},
	journal = {Artificial Intelligence Review},
	author = {Al-Aswadi, Fatima N. and Chan, Huah Yong and Gan, Keng Hoon},
	month = aug,
	year = {2020},
	keywords = {gelesen},
	pages = {3901--3928},
	file = {s10462-019-09782-9.pdf:D\:\\Dokumente\\05 Uni\\8. Semester\\01 Großer Beleg\\Literaturrecherche\\Current Research\\s10462-019-09782-9.pdf:application/pdf},
}

@article{peng_knowledge_2023,
	title = {Knowledge {Graphs}: {Opportunities} and {Challenges}},
	volume = {56},
	issn = {0269-2821, 1573-7462},
	shorttitle = {Knowledge {Graphs}},
	url = {https://link.springer.com/10.1007/s10462-023-10465-9},
	doi = {10.1007/s10462-023-10465-9},
	abstract = {With the explosive growth of artificial intelligence (AI) and big data, it has become vitally important to organize and represent the enormous volume of knowledge appropriately. As graph data, knowledge graphs accumulate and convey knowledge of the real world. It has been well-recognized that knowledge graphs effectively represent complex information; hence, they rapidly gain the attention of academia and industry in recent years. Thus to develop a deeper understanding of knowledge graphs, this paper presents a systematic overview of this field. Specifically, we focus on the opportunities and challenges of knowledge graphs. We first review the opportunities of knowledge graphs in terms of two aspects: (1) AI systems built upon knowledge graphs; (2) potential application fields of knowledge graphs. Then, we thoroughly discuss severe technical challenges in this field, such as knowledge graph embeddings, knowledge acquisition, knowledge graph completion, knowledge fusion, and knowledge reasoning. We expect that this survey will shed new light on future research and the development of knowledge graphs.},
	language = {en},
	number = {11},
	urldate = {2024-04-08},
	journal = {Artificial Intelligence Review},
	author = {Peng, Ciyuan and Xia, Feng and Naseriparsa, Mehdi and Osborne, Francesco},
	month = nov,
	year = {2023},
	keywords = {gelesen},
	pages = {13071--13102},
	file = {s10462-023-10465-9.pdf:D\:\\Dokumente\\05 Uni\\8. Semester\\01 Großer Beleg\\Literaturrecherche\\Current Research\\s10462-023-10465-9.pdf:application/pdf},
}

@article{yang_ontology_2021,
	title = {Ontology {Learning} for {Systems} {Engineering} {Body} of {Knowledge}},
	volume = {17},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	issn = {1551-3203, 1941-0050},
	url = {https://ieeexplore.ieee.org/document/9079664/},
	doi = {10.1109/TII.2020.2990953},
	abstract = {Extant systems engineering standards are so fragmented that the conceptualization of a cohesive body of knowledge is not easy. The discrepancies between different standards lead to misunderstanding and misinterpretation, making communication between stakeholders increasingly difﬁcult. Moreover, these standards remain document centric, whereas systems engineering is transforming from paper-based to a model-based discipline. This requires the use of advanced information exchange schema and digital artifacts to enhance interoperability. Ontologies have been advocated as a mechanism to address these problems, as they can support the model-based transition and formalize the domain knowledge. However, manually creating ontologies is a time-consuming, error-prone, and tedious process. Little has been known about how to automate the development and little work has been conducted for building systems engineering ontologies. Therefore, in this article, we propose an ontology learning methodology to extract a systems engineering ontology from the extant standards. This methodology employs natural language processing techniques to carry out the lexical and morphological analyses on the standard documents. From the learning process, important terminologies, synonyms, concepts, and relations constructing the systems engineering body of knowledge are automatically recognized and classiﬁed. A formal and sophisticated system engineering ontology is achieved, which can be used to harmonize the extant standards, unify the languages, and improve the interoperability of the model-based systems engineering approach.},
	language = {en},
	number = {2},
	urldate = {2024-04-08},
	journal = {IEEE Transactions on Industrial Informatics},
	author = {Yang, Lan and Cormican, Kathryn and Yu, Ming},
	month = feb,
	year = {2021},
	keywords = {gelesen},
	pages = {1039--1047},
	file = {Ontology_Learning_for_Systems_Engineering_Body_of_Knowledge.pdf:D\:\\Dokumente\\05 Uni\\8. Semester\\01 Großer Beleg\\Literaturrecherche\\Current Research\\Ontology_Learning_for_Systems_Engineering_Body_of_Knowledge.pdf:application/pdf},
}

@book{breakwell_research_2012,
	title = {Research {Methods} in {Psychology}},
	isbn = {978-0-85702-264-6},
	url = {https://books.google.de/books?id=1Fv9auPb9a4C},
	publisher = {SAGE Publications},
	author = {Breakwell, G. M. and Smith, J. A. and Wright, D. B.},
	year = {2012},
	keywords = {irrelevant},
}

@article{kahn_strategies_1985,
	title = {Strategies for {Knowledge} {Acquisition}},
	volume = {PAMI-7},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	issn = {0162-8828},
	url = {http://ieeexplore.ieee.org/document/4767699/},
	doi = {10.1109/TPAMI.1985.4767699},
	language = {en},
	number = {5},
	urldate = {2024-04-08},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Kahn, Gary and Nowlan, Steven and McDermott, John},
	month = sep,
	year = {1985},
	keywords = {gelesen},
	pages = {511--522},
	file = {Strategies_for_Knowledge_Acquisition.pdf:D\:\\Dokumente\\05 Uni\\8. Semester\\01 Großer Beleg\\Literaturrecherche\\Knowledge Acquisition\\Strategies_for_Knowledge_Acquisition.pdf:application/pdf},
}

@article{liu_enhanced_2017,
	title = {Enhanced {Explicit} {Semantic} {Analysis} for {Product} {Model} {Retrieval} in {Construction} {Industry}},
	volume = {13},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	issn = {1551-3203, 1941-0050},
	url = {http://ieeexplore.ieee.org/document/7934460/},
	doi = {10.1109/TII.2017.2708727},
	abstract = {With the rapidly growing number of online product models in construction industry, there is an urgent need for developing effective domain-speciﬁc information retrieval methods. Explicit semantic analysis (ESA) is a method that automatically extracts concept-based features from human knowledge repositories for semantic retrieval. This avoids the requirement of constructing and maintaining an explicitly formalized ontology. However, since domain-speciﬁc knowledge repositories are relatively small, the available terminologies are insufﬁcient and concepts have coarse granularity. In this paper, we propose an enhanced ESA method for product model retrieval in construction industry. The major enhancements for the original ESA method consist of two parts. First, a novel concept expansion algorithm is proposed to solve the problem caused by insufﬁcient terminologies. Second, a reranking algorithm is developed to solve the problem caused by coarse granularity of concepts. Experimental results show that our method signiﬁcantly improves the performance of product model retrieval and outperforms the state-of-the-art methods. Our method is also applicable to product retrieval in other engineering domain if a speciﬁc knowledge repository is provided in that domain.},
	language = {en},
	number = {6},
	urldate = {2024-04-13},
	journal = {IEEE Transactions on Industrial Informatics},
	author = {Liu, Han and Liu, Yu-Shen and Pauwels, Pieter and Guo, Hongling and Gu, Ming},
	month = dec,
	year = {2017},
	keywords = {überflogen},
	pages = {3361--3369},
	file = {Enhanced_Explicit_Semantic_Analysis_for_Product_Model_Retrieval_in_Construction_Industry.pdf:D\:\\Dokumente\\05 Uni\\8. Semester\\01 Großer Beleg\\Literaturrecherche\\Current Research\\Enhanced_Explicit_Semantic_Analysis_for_Product_Model_Retrieval_in_Construction_Industry.pdf:application/pdf},
}

@article{lafrance_knowledge_1987,
	title = {The {Knowledge} {Acquisition} {Grid}: a method for training knowledge engineers},
	volume = {26},
	copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
	issn = {00207373},
	shorttitle = {The {Knowledge} {Acquisition} {Grid}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0020737387800949},
	doi = {10.1016/S0020-7373(87)80094-9},
	language = {en},
	number = {2},
	urldate = {2024-04-19},
	journal = {International Journal of Man-Machine Studies},
	author = {LaFrance, Marianne},
	month = feb,
	year = {1987},
	pages = {245--255},
	file = {1-s2.0-S0020737387800949-main.pdf:D\:\\Dokumente\\05 Uni\\8. Semester\\01 Großer Beleg\\Literaturrecherche\\Knowledge Acquisition\\1-s2.0-S0020737387800949-main.pdf:application/pdf},
}

@article{yang_alphafold2_2023,
	title = {{AlphaFold2} and its applications in the fields of biology and medicine},
	volume = {8},
	issn = {2059-3635},
	url = {https://www.nature.com/articles/s41392-023-01381-z},
	doi = {10.1038/s41392-023-01381-z},
	abstract = {Abstract
            AlphaFold2 (AF2) is an artificial intelligence (AI) system developed by DeepMind that can predict three-dimensional (3D) structures of proteins from amino acid sequences with atomic-level accuracy. Protein structure prediction is one of the most challenging problems in computational biology and chemistry, and has puzzled scientists for 50 years. The advent of AF2 presents an unprecedented progress in protein structure prediction and has attracted much attention. Subsequent release of structures of more than 200 million proteins predicted by AF2 further aroused great enthusiasm in the science community, especially in the fields of biology and medicine. AF2 is thought to have a significant impact on structural biology and research areas that need protein structure information, such as drug discovery, protein design, prediction of protein function, et al. Though the time is not long since AF2 was developed, there are already quite a few application studies of AF2 in the fields of biology and medicine, with many of them having preliminarily proved the potential of AF2. To better understand AF2 and promote its applications, we will in this article summarize the principle and system architecture of AF2 as well as the recipe of its success, and particularly focus on reviewing its applications in the fields of biology and medicine. Limitations of current AF2 prediction will also be discussed.},
	language = {en},
	number = {1},
	urldate = {2024-04-25},
	journal = {Signal Transduction and Targeted Therapy},
	author = {Yang, Zhenyu and Zeng, Xiaoxi and Zhao, Yi and Chen, Runsheng},
	month = mar,
	year = {2023},
	pages = {115},
	file = {s41392-023-01381-z.pdf:D\:\\Dokumente\\05 Uni\\8. Semester\\05 Hauptseminar\\s41392-023-01381-z.pdf:application/pdf},
}

@book{baader_introduction_2017,
	edition = {1},
	title = {An {Introduction} to {Description} {Logic}},
	copyright = {https://www.cambridge.org/core/terms},
	isbn = {978-0-521-87361-1 978-1-139-02535-5 978-0-521-69542-8},
	url = {https://www.cambridge.org/core/product/identifier/9781139025355/type/book},
	abstract = {Description logics (DLs) have a long tradition in computer science and knowledge representation, being designed so that domain knowledge can be described and so that computers can reason about this knowledge. DLs have recently gained increased importance since they form the logical basis of widely used ontology languages, in particular the web ontology language OWL. Written by four renowned experts, this is the first textbook on description logics. It is suitable for self-study by graduates and as the basis for a university course. Starting from a basic DL, the book introduces the reader to their syntax, semantics, reasoning problems and model theory and discusses the computational complexity of these reasoning problems and algorithms to solve them. It then explores a variety of reasoning techniques, knowledge-based applications and tools and it describes the relationship between DLs and OWL.},
	language = {en},
	urldate = {2024-05-04},
	publisher = {Cambridge University Press},
	author = {Baader, Franz and Horrocks, Ian and Lutz, Carsten and Sattler, Uli},
	month = apr,
	year = {2017},
	doi = {10.1017/9781139025355},
	file = {Baader et al. - 2017 - An Introduction to Description Logic.pdf:C\:\\Users\\julia\\Zotero\\storage\\QXWFEAI5\\Baader et al. - 2017 - An Introduction to Description Logic.pdf:application/pdf;Baader et al. - 2017 - An Introduction to Description Logic.pdf:C\:\\Users\\julia\\Zotero\\storage\\I9APB9U8\\Baader et al. - 2017 - An Introduction to Description Logic.pdf:application/pdf;Baader et al. - 2017 - An Introduction to Description Logic.pdf:C\:\\Users\\julia\\Zotero\\storage\\GIR4USYU\\Baader et al. - 2017 - An Introduction to Description Logic.pdf:application/pdf;Baader et al. - 2017 - An Introduction to Description Logic.pdf:C\:\\Users\\julia\\Zotero\\storage\\X9Y33AE9\\Baader et al. - 2017 - An Introduction to Description Logic.pdf:application/pdf;Baader et al. - 2017 - An Introduction to Description Logic.pdf:C\:\\Users\\julia\\Zotero\\storage\\XS7RQGTY\\Baader et al. - 2017 - An Introduction to Description Logic.pdf:application/pdf;Baader et al. - 2017 - An Introduction to Description Logic.pdf:C\:\\Users\\julia\\Zotero\\storage\\DPCN9FHR\\Baader et al. - 2017 - An Introduction to Description Logic.pdf:application/pdf;contents.pdf:C\:\\Users\\julia\\Zotero\\storage\\E949PJCR\\contents.pdf:application/pdf},
}

@book{baader_introduction_2017-1,
	edition = {1},
	title = {An {Introduction} to {Description} {Logic}},
	copyright = {https://www.cambridge.org/core/terms},
	isbn = {978-0-521-87361-1 978-1-139-02535-5 978-0-521-69542-8},
	url = {https://www.cambridge.org/core/product/identifier/9781139025355/type/book},
	abstract = {Description logics (DLs) have a long tradition in computer science and knowledge representation, being designed so that domain knowledge can be described and so that computers can reason about this knowledge. DLs have recently gained increased importance since they form the logical basis of widely used ontology languages, in particular the web ontology language OWL. Written by four renowned experts, this is the first textbook on description logics. It is suitable for self-study by graduates and as the basis for a university course. Starting from a basic DL, the book introduces the reader to their syntax, semantics, reasoning problems and model theory and discusses the computational complexity of these reasoning problems and algorithms to solve them. It then explores a variety of reasoning techniques, knowledge-based applications and tools and it describes the relationship between DLs and OWL.},
	language = {en},
	urldate = {2024-05-04},
	publisher = {Cambridge University Press},
	author = {Baader, Franz and Horrocks, Ian and Lutz, Carsten and Sattler, Uli},
	month = apr,
	year = {2017},
	doi = {10.1017/9781139025355},
}

@book{baader_introduction_2017-2,
	edition = {1},
	title = {An {Introduction} to {Description} {Logic}},
	copyright = {https://www.cambridge.org/core/terms},
	isbn = {978-0-521-87361-1 978-1-139-02535-5 978-0-521-69542-8},
	url = {https://www.cambridge.org/core/product/identifier/9781139025355/type/book},
	abstract = {Description logics (DLs) have a long tradition in computer science and knowledge representation, being designed so that domain knowledge can be described and so that computers can reason about this knowledge. DLs have recently gained increased importance since they form the logical basis of widely used ontology languages, in particular the web ontology language OWL. Written by four renowned experts, this is the first textbook on description logics. It is suitable for self-study by graduates and as the basis for a university course. Starting from a basic DL, the book introduces the reader to their syntax, semantics, reasoning problems and model theory and discusses the computational complexity of these reasoning problems and algorithms to solve them. It then explores a variety of reasoning techniques, knowledge-based applications and tools and it describes the relationship between DLs and OWL.},
	language = {en},
	urldate = {2024-05-04},
	publisher = {Cambridge University Press},
	author = {Baader, Franz and Horrocks, Ian and Lutz, Carsten and Sattler, Uli},
	month = apr,
	year = {2017},
	doi = {10.1017/9781139025355},
}

@article{hitzler_owl_2012,
	title = {{OWL} 2 {Web} {Ontology} {Language} {Primer} ({Second} {Edition})},
	language = {en},
	journal = {W3C Recommendation},
	author = {Hitzler, Pascal and Krötzsch, Markus and Parsia, Bijan and F. Patel-Schneider, Peter and Rudolph, Sebastian},
	year = {2012},
	file = {2012 - OWL 2 Web Ontology Language Primer (Second Edition.pdf:C\:\\Users\\julia\\Zotero\\storage\\3MJMZSVJ\\2012 - OWL 2 Web Ontology Language Primer (Second Edition.pdf:application/pdf},
}

@book{staab_handbook_2009,
	address = {Berlin, Heidelberg},
	title = {Handbook on {Ontologies}},
	copyright = {http://www.springer.com/tdm},
	isbn = {978-3-540-70999-2 978-3-540-92673-3},
	url = {http://link.springer.com/10.1007/978-3-540-92673-3},
	language = {en},
	urldate = {2024-05-04},
	publisher = {Springer Berlin Heidelberg},
	editor = {Staab, Steffen and Studer, Rudi},
	year = {2009},
	doi = {10.1007/978-3-540-92673-3},
	file = {Staab und Studer - 2009 - Handbook on Ontologies.pdf:C\:\\Users\\julia\\Zotero\\storage\\4X4GVNW5\\Staab und Studer - 2009 - Handbook on Ontologies.pdf:application/pdf},
}

@misc{krotzsch_description_2013,
	title = {A {Description} {Logic} {Primer}},
	url = {http://arxiv.org/abs/1201.4089},
	abstract = {This paper provides a self-contained ﬁrst introduction to description logics (DLs). The main concepts and features are explained with examples before syntax and semantics of the DL SROIQ are deﬁned in detail. Additional sections review lightweight DL languages, discuss the relationship to the OWL Web Ontology Language and give pointers to further reading.},
	language = {en},
	urldate = {2024-05-04},
	publisher = {arXiv},
	author = {Krötzsch, Markus and Simancik, Frantisek and Horrocks, Ian},
	month = jun,
	year = {2013},
	note = {arXiv:1201.4089 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Logic in Computer Science, F.4.1, I.2.4},
	file = {Krötzsch et al. - 2013 - A Description Logic Primer.pdf:C\:\\Users\\julia\\Zotero\\storage\\36ZZKFVK\\Krötzsch et al. - 2013 - A Description Logic Primer.pdf:application/pdf},
}

@book{baader_introduction_2017-3,
	edition = {1},
	title = {An {Introduction} to {Description} {Logic}},
	copyright = {https://www.cambridge.org/core/terms},
	isbn = {978-0-521-87361-1 978-1-139-02535-5 978-0-521-69542-8},
	url = {https://www.cambridge.org/core/product/identifier/9781139025355/type/book},
	abstract = {Description logics (DLs) have a long tradition in computer science and knowledge representation, being designed so that domain knowledge can be described and so that computers can reason about this knowledge. DLs have recently gained increased importance since they form the logical basis of widely used ontology languages, in particular the web ontology language OWL. Written by four renowned experts, this is the first textbook on description logics. It is suitable for self-study by graduates and as the basis for a university course. Starting from a basic DL, the book introduces the reader to their syntax, semantics, reasoning problems and model theory and discusses the computational complexity of these reasoning problems and algorithms to solve them. It then explores a variety of reasoning techniques, knowledge-based applications and tools and it describes the relationship between DLs and OWL.},
	language = {en},
	urldate = {2024-05-04},
	publisher = {Cambridge University Press},
	author = {Baader, Franz and Horrocks, Ian and Lutz, Carsten and Sattler, Uli},
	month = apr,
	year = {2017},
	doi = {10.1017/9781139025355},
}

@book{baader_introduction_2017-4,
	edition = {1},
	title = {An {Introduction} to {Description} {Logic}},
	copyright = {https://www.cambridge.org/core/terms},
	isbn = {978-0-521-87361-1 978-1-139-02535-5 978-0-521-69542-8},
	url = {https://www.cambridge.org/core/product/identifier/9781139025355/type/book},
	abstract = {Description logics (DLs) have a long tradition in computer science and knowledge representation, being designed so that domain knowledge can be described and so that computers can reason about this knowledge. DLs have recently gained increased importance since they form the logical basis of widely used ontology languages, in particular the web ontology language OWL. Written by four renowned experts, this is the first textbook on description logics. It is suitable for self-study by graduates and as the basis for a university course. Starting from a basic DL, the book introduces the reader to their syntax, semantics, reasoning problems and model theory and discusses the computational complexity of these reasoning problems and algorithms to solve them. It then explores a variety of reasoning techniques, knowledge-based applications and tools and it describes the relationship between DLs and OWL.},
	language = {en},
	urldate = {2024-05-04},
	publisher = {Cambridge University Press},
	author = {Baader, Franz and Horrocks, Ian and Lutz, Carsten and Sattler, Uli},
	month = apr,
	year = {2017},
	doi = {10.1017/9781139025355},
}

@book{baader_introduction_2017-5,
	edition = {1},
	title = {An {Introduction} to {Description} {Logic}},
	copyright = {https://www.cambridge.org/core/terms},
	isbn = {978-0-521-87361-1 978-1-139-02535-5 978-0-521-69542-8},
	url = {https://www.cambridge.org/core/product/identifier/9781139025355/type/book},
	abstract = {Description logics (DLs) have a long tradition in computer science and knowledge representation, being designed so that domain knowledge can be described and so that computers can reason about this knowledge. DLs have recently gained increased importance since they form the logical basis of widely used ontology languages, in particular the web ontology language OWL. Written by four renowned experts, this is the first textbook on description logics. It is suitable for self-study by graduates and as the basis for a university course. Starting from a basic DL, the book introduces the reader to their syntax, semantics, reasoning problems and model theory and discusses the computational complexity of these reasoning problems and algorithms to solve them. It then explores a variety of reasoning techniques, knowledge-based applications and tools and it describes the relationship between DLs and OWL.},
	language = {en},
	urldate = {2024-05-04},
	publisher = {Cambridge University Press},
	author = {Baader, Franz and Horrocks, Ian and Lutz, Carsten and Sattler, Uli},
	month = apr,
	year = {2017},
	doi = {10.1017/9781139025355},
}

@article{gruber_translation_1993-1,
	title = {A translation approach to portable ontologies},
	journal = {Academic Press Limited},
	author = {Gruber, Thomas},
	year = {1993},
	file = {1-s2.0-S1042814383710083-main.pdf:C\:\\Users\\julia\\Zotero\\storage\\S7P9DW2K\\1-s2.0-S1042814383710083-main.pdf:application/pdf},
}

@misc{mulford_swrl_2020,
	title = {{SWRL} with {Professor} {Bernardo} {Cuenca} {Grau}},
	url = {https://medium.com/oxford-semantic-technologies/swrl-with-professor-bernardo-cuenca-grau-7ff2d41f9791},
	journal = {Oxford Semantic Technologies},
	author = {Mulford, Felicity},
	year = {2020},
}

@article{novalija_ontoplus_2011,
	title = {{OntoPlus}: {Text}-driven ontology extension using ontology content, structure and co-occurrence information},
	volume = {24},
	copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
	issn = {09507051},
	shorttitle = {{OntoPlus}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0950705111001110},
	doi = {10.1016/j.knosys.2011.06.002},
	abstract = {This paper addresses the process of semi-automatic text-driven ontology extension using ontology content, structure and co-occurrence information. A novel OntoPlus methodology is proposed for semi-automatic ontology extension based on text mining methods. It allows for the effective extension of the large ontologies, providing a ranked list of potentially relevant concepts and relationships given a new concept (e.g., glossary term) to be inserted in the ontology. A number of experiments are conducted, evaluating measures for ranking correspondence between existing ontology concepts and new domain concepts suggested for the ontology extension. Measures for ranking are based on incorporating ontology content, structure and co-occurrence information. The experiments are performed using a well known Cyc ontology and textual material from two domains – ﬁnances and, ﬁsheries \& aquaculture. Our experiments show that the best results are achieved by combining content, structure and co-occurrence information. Furthermore, ontology content and structure seem to be more important than co-occurrence for our data in the ﬁnancial domain. At the same time, ontology content and co-occurrence seem to have higher importance for our ﬁsheries \& aquaculture domain.},
	language = {en},
	number = {8},
	urldate = {2024-07-02},
	journal = {Knowledge-Based Systems},
	author = {Novalija, Inna and Mladenić, Dunja and Bradeško, Luka},
	month = dec,
	year = {2011},
	pages = {1261--1276},
	file = {1-s2.0-S0950705111001110-main.pdf:D\:\\Dokumente\\05 Uni\\8. Semester\\01 Großer Beleg\\Literaturrecherche\\Extension\\1-s2.0-S0950705111001110-main.pdf:application/pdf},
}

@article{liu_semi-automatic_2005,
	title = {Semi-{Automatic} {Ontology} {Extension} {Using} {Spreading} {Activation}},
	abstract = {This paper describes a system to semi-automatically extend and refine ontologies by mining textual data from the Web sites of international online media. Expanding a seed ontology creates a semantic network through co-occurrence analysis, trigger phrase analysis, and disambiguation based on the WordNet lexical dictionary. Spreading activation then processes this semantic network to find the most probable candidates for inclusion in an extended ontology. Approaches to identifying hierarchical relationships such as subsumption, head noun analysis and WordNet consultation are used to confirm and classify the found relationships. Using a seed ontology on "climate change" as an example, this paper demonstrates how spreading activation improves the result by naturally integrating the mentioned methods.},
	language = {en},
	journal = {Proceedings of I-KNOW ’05},
	author = {Liu, Wei and Weichselbraun, Albert and Scharl, Arno and Chang, Elizabeth},
	year = {2005},
	file = {19943_downloaded_stream_461.pdf:D\:\\Dokumente\\05 Uni\\8. Semester\\01 Großer Beleg\\Literaturrecherche\\Extension\\19943_downloaded_stream_461.pdf:application/pdf},
}

@article{schutz_relext_2005,
	title = {{RelExt} : {A} {Tool} for {Relation} {Extraction} from {Text} in {Ontology} {Extension}},
	language = {en},
	journal = {The Semantic Web - ISWC 2005},
	author = {Schutz, Alexander and Buitelaar, Paul},
	year = {2005},
	file = {11574620.pdf:D\:\\Dokumente\\05 Uni\\8. Semester\\01 Großer Beleg\\Literaturrecherche\\Extension\\11574620.pdf:application/pdf},
}

@article{ghilardi_did_2006,
	title = {Did {I} {Damage} {My} {Ontology}? {A} {Case} for {Conservative} {Extensions} in {Description} {Logics}},
	abstract = {In computer science, ontologies are dynamic entities: to adapt them to new and evolving applications, it is necessary to frequently perform modiﬁcations such as the extension with new axioms and merging with other ontologies. We argue that, after performing such modiﬁcations, it is important to know whether the resulting ontology is a conservative extension of the original one. If this is not the case, then there may be unexpected consequences when using the modiﬁed ontology in place of the original one in applications. In this paper, we propose and investigate new reasoning problems based on the notion of conservative extension, assuming that ontologies are formulated as TBoxes in the description logic ALC. We show that the fundamental such reasoning problems are decidable and 2EXPTIME-complete. Additionally, we perform a ﬁner-grained analysis that distinguishes between the size of the original ontology and the size of the additional axioms. In particular, we show that there are algorithms whose runtime is ‘only’ exponential in the size of the original ontology, but double exponential in the size of the added axioms. If the size of the new axioms is small compared to the size of the ontology, these algorithms are thus not signiﬁcantly more complex than the standard reasoning services implemented in modern description logic reasoners. If the extension of an ontology is not conservative, our algorithm is capable of computing a concept that witnesses non-conservativeness. We show that the computed concepts are of (worst-case) minimal size.},
	language = {en},
	journal = {Proceedings of the Tenth International Conference on Principles of Knowledge Representation and Reasoning (KR'06)},
	author = {Ghilardi, Silvio},
	year = {2006},
	keywords = {überflogen},
	file = {KR06-021.pdf:D\:\\Dokumente\\05 Uni\\8. Semester\\01 Großer Beleg\\Literaturrecherche\\Extension\\KR06-021.pdf:application/pdf},
}

@article{althubaiti_combining_2020,
	title = {Combining lexical and context features for automatic ontology extension},
	volume = {11},
	issn = {2041-1480},
	url = {https://jbiomedsem.biomedcentral.com/articles/10.1186/s13326-019-0218-0},
	doi = {10.1186/s13326-019-0218-0},
	abstract = {Background: Ontologies are widely used across biology and biomedicine for the annotation of databases. Ontology development is often a manual, time-consuming, and expensive process. Automatic or semi-automatic identification of classes that can be added to an ontology can make ontology development more efficient.
Results: We developed a method that uses machine learning and word embeddings to identify words and phrases that are used to refer to an ontology class in biomedical Europe PMC full-text articles. Once labels and synonyms of a class are known, we use machine learning to identify the super-classes of a class. For this purpose, we identify lexical term variants, use word embeddings to capture context information, and rely on automated reasoning over ontologies to generate features, and we use an artificial neural network as classifier. We demonstrate the utility of our approach in identifying terms that refer to diseases in the Human Disease Ontology and to distinguish between different types of diseases.
Conclusions: Our method is capable of discovering labels that refer to a class in an ontology but are not present in an ontology, and it can identify whether a class should be a subclass of some high-level ontology classes. Our approach can therefore be used for the semi-automatic extension and quality control of ontologies. The algorithm, corpora and evaluation datasets are available at https://github.com/bio-ontology-research-group/ontology-extension.},
	language = {en},
	number = {1},
	urldate = {2024-07-02},
	journal = {Journal of Biomedical Semantics},
	author = {Althubaiti, Sara and Kafkas, Şenay and Abdelhakim, Marwa and Hoehndorf, Robert},
	month = dec,
	year = {2020},
	keywords = {irrelevant},
	pages = {1},
	file = {s13326-019-0218-0.pdf:D\:\\Dokumente\\05 Uni\\8. Semester\\01 Großer Beleg\\Literaturrecherche\\Extension\\s13326-019-0218-0.pdf:application/pdf},
}

@article{palmisano_rough_2011,
	title = {The {Rough} {Guide} to the {OWL} {API}: a tutorial - {Version} 3.2.3 for {OWL} 2},
	language = {en},
	journal = {Department of Computer Science University of Manchester},
	author = {Palmisano, Ignazio},
	month = jun,
	year = {2011},
	file = {owled2011_tutorial.pdf:D\:\\Dokumente\\05 Uni\\8. Semester\\01 Großer Beleg\\Literaturrecherche\\Praktisch\\owled2011_tutorial.pdf:application/pdf},
}

@article{serbak_protege_2020,
	title = {Protégé {Plugin} for {Change} and {Impact} {Visualization}},
	journal = {University of Zurich - Master's Thesis},
	author = {Serbak, Mirko},
	year = {2020},
	file = {Protege_Plugin_for_Change_and_Impact_Visualization.pdf:D\:\\Dokumente\\05 Uni\\8. Semester\\01 Großer Beleg\\Literaturrecherche\\Praktisch\\Protege_Plugin_for_Change_and_Impact_Visualization.pdf:application/pdf},
}

@article{musen_protege_2015,
	title = {The protégé project: a look back and a look forward},
	volume = {1},
	issn = {2372-3483},
	shorttitle = {The protégé project},
	url = {https://dl.acm.org/doi/10.1145/2757001.2757003},
	doi = {10.1145/2757001.2757003},
	language = {en},
	number = {4},
	urldate = {2024-08-16},
	journal = {AI Matters},
	author = {Musen, Mark A.},
	month = jun,
	year = {2015},
	pages = {4--12},
	file = {2757001.2757003.pdf:D\:\\Dokumente\\05 Uni\\8. Semester\\01 Großer Beleg\\Literaturrecherche\\Protege\\2757001.2757003.pdf:application/pdf},
}

@article{noy_protege-2000_2003,
	title = {Protégé-2000: {An} {Open}-{Source} {Ontology}-{Development} and {Knowledge}-{Acquisition} {Environment}},
	abstract = {Prot´eg´e-2000 is an open-source tool that assists users in the construction of large electronic knowledge bases. It has an intuitive user interface that enables developers to create and edit domain ontologies. Numerous plugins provide alternative visualization mechanisms, enable management of multiple ontologies, allow the use of inference engines and problem solvers with Prot´eg´e ontologies, and provide other functionality. The Prot´eg´e user community has more than 7000 members.},
	language = {en},
	journal = {AMIA Symposium},
	author = {Noy, Natalya F and Crubezy, Monica and Fergerson, Ray W and Knublauch, Holger and Tu, Samson W and Vendetti, Jennifer and Musen, Mark A},
	year = {2003},
	file = {Protege-2000_An_Open-Source_Ontology-Development_a.pdf:D\:\\Dokumente\\05 Uni\\8. Semester\\01 Großer Beleg\\Literaturrecherche\\Protege\\Protege-2000_An_Open-Source_Ontology-Development_a.pdf:application/pdf},
}

@article{gennari_evolution_2003,
	title = {The evolution of {Protégé}: an environment for knowledge-based systems development},
	volume = {58},
	copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
	issn = {10715819},
	shorttitle = {The evolution of {Protégé}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1071581902001271},
	doi = {10.1016/S1071-5819(02)00127-1},
	abstract = {The Protégé project has come a long way since Mark Musen first built the Protégé metatool for knowledge-based systems in 1987. The original tool was a small application, aimed at building knowledge-acquisition tools for a few specialized programs in medical planning. From this initial tool, the Protégé system has evolved into a durable, extensible platform for knowledge-based systems development and research. The current version, Protégé-2000, can be run on a variety of platforms, supports customized user-interface extensions, incorporates the Open Knowledge Base Connectivity (OKBC) knowledge model, interacts with standard storage formats such as relational databases, XML, and RDF, and has been used by hundreds of individuals and research groups. In this paper, we follow the evolution of the Protégé project through 3 distinct re-implementations. We describe our overall methodology, our design decisions, and the lessons we have learned over the duration of the project.. We believe that our success is one of infrastructure: Protégé is a flexible, well-supported, and robust development environment. Using Protégé, developers and domain experts can easily build effective knowledge-based systems, and researchers can explore ideas in a variety of knowledge-based d omains.},
	language = {en},
	number = {1},
	urldate = {2024-08-16},
	journal = {International Journal of Human-Computer Studies},
	author = {Gennari, John H and Musen, Mark A and Fergerson, Ray W and Grosso, William E and Crubézy, Monica and Eriksson, Henrik and Noy, Natalya F and Tu, Samson W},
	month = jan,
	year = {2003},
	pages = {89--123},
	file = {protege_evolution.pdf:D\:\\Dokumente\\05 Uni\\8. Semester\\01 Großer Beleg\\Literaturrecherche\\Protege\\protege_evolution.pdf:application/pdf},
}

@misc{ergin_all_2022,
	title = {All {The} {Universities} {In} {The} {World}},
	url = {https://www.kaggle.com/datasets/thedevastator/all-universities-in-the-world/code},
	author = {Ergin, Emirhan and Mwangi, Lewis and Agra, Lucas},
	year = {2022},
}

@article{noauthor_notitle_nodate-1,
}

@article{horridge_justification_2010,
	title = {Justification {Oriented} {Proofs} in {OWL}},
	journal = {Patel-Schneider, P.F., et al. The Semantic Web – ISWC 2010. ISWC 2010. Lecture Notes in Computer Science, vol 6496},
	author = {Horridge, M. and Parsia, B. and Sattler, U.},
	year = {2010},
}

@inproceedings{he_improve_2022,
	title = {Improve emotional speech synthesis quality by learning explicit and implicit representations with semi-supervised training},
	url = {https://www.isca-archive.org/interspeech_2022/he22d_interspeech.html},
	doi = {10.21437/Interspeech.2022-11336},
	abstract = {Due to the lack of high-quality emotional speech synthesis datasets, the naturalness and expressiveness of synthesized speech are still lacking in order to achieve human-like communication. And existing emotional speech synthesis system usually extracts emotional information only from reference audio and ignores sentiment information implicit in the text. Therefore, we propose a novel model to improve emotional speech synthesis quality by learning explicit and implicit representations with semi-supervised learning. In addition to explicit emotional representations from reference audio, we propose an implicit emotion representations learning method based on graph neural network, considering dependency relations of a sentence and text sentiment classification (TSC) task. For the lack of emotion-annotated datasets, we leverage large amounts of expressive datasets to reinforce training the proposed model with semi-supervised learning. Experiments show that the proposed method can improve the naturalness and expressiveness of synthetic speech and is better than the baseline model.},
	language = {en},
	urldate = {2024-10-15},
	booktitle = {Interspeech 2022},
	publisher = {ISCA},
	author = {He, Jiaxu and Gong, Cheng and Wang, Longbiao and Jin, Di and Wang, Xiaobao and Xu, Junhai and Dang, Jianwu},
	month = sep,
	year = {2022},
	pages = {5538--5542},
	file = {He et al. - 2022 - Improve emotional speech synthesis quality by lear.pdf:C\:\\Users\\julia\\Zotero\\storage\\KU6HKKML\\He et al. - 2022 - Improve emotional speech synthesis quality by lear.pdf:application/pdf},
}

@book{mantoro_neural_2021,
	address = {Cham},
	series = {Communications in {Computer} and {Information} {Science}},
	title = {Neural {Information} {Processing}: 28th {International} {Conference}, {ICONIP} 2021, {Sanur}, {Bali}, {Indonesia}, {December} 8–12, 2021, {Proceedings}, {Part} {V}},
	volume = {1516},
	copyright = {https://www.springer.com/tdm},
	isbn = {978-3-030-92306-8 978-3-030-92307-5},
	shorttitle = {Neural {Information} {Processing}},
	url = {https://link.springer.com/10.1007/978-3-030-92307-5},
	language = {en},
	urldate = {2024-10-15},
	publisher = {Springer International Publishing},
	editor = {Mantoro, Teddy and Lee, Minho and Ayu, Media Anugerah and Wong, Kok Wai and Hidayanto, Achmad Nizar},
	year = {2021},
	doi = {10.1007/978-3-030-92307-5},
	file = {Mantoro et al. - 2021 - Neural Information Processing 28th International .pdf:C\:\\Users\\julia\\Zotero\\storage\\8KSC5NDK\\Mantoro et al. - 2021 - Neural Information Processing 28th International .pdf:application/pdf},
}

@article{wei_neural_2024,
	title = {Neural {Architecture} {Search} for {GNN}-{Based} {Graph} {Classification}},
	volume = {42},
	issn = {1046-8188, 1558-2868},
	url = {https://dl.acm.org/doi/10.1145/3584945},
	doi = {10.1145/3584945},
	abstract = {Graph classification is an important problem with applications across many domains, for which graph neural networks (GNNs) have been state-of-the-art (SOTA) methods. In the literature, to adopt GNNs for the graph classification task, there are two groups of methods: global pooling and hierarchical pooling. The global pooling methods obtain the graph representation vectors by globally pooling all of the node embeddings together at the end of several GNN layers, whereas the hierarchical pooling methods provide one extra pooling operation between the GNN layers to extract hierarchical information and improve the graph representations. Both global and hierarchical pooling methods are effective in different scenarios. Due to highly diverse applications, it is challenging to design data-specific pooling methods with human expertise. To address this problem, we propose PAS (Pooling Architecture Search) to design adaptive pooling architectures by using the neural architecture search (NAS). To enable the search space design, we propose a unified pooling framework consisting of four modules: Aggregation, Pooling, Readout, and Merge. Two variants, PAS-G and PAS-NE, are provided to design the pooling operations in different scales. A set of candidate operations is designed in the search space using this framework. Then, existing human-designed pooling methods, including global and hierarchical ones, can be incorporated. To enable efficient search, a coarsening strategy is developed to continuously relax the search space, and then a differentiable search method can be adopted.
            
              We conduct extensive experiments on six real-world datasets, including the large-scale datasets MR and ogbg-molhiv. Experimental results in this article demonstrate the effectiveness and efficiency of the proposed PAS in designing the pooling architectures for graph classification. The Top-1 performance on two Open Graph Benchmark (OGB) datasets
              
                1
              
              further indicates the utility of PAS when facing diverse realistic data. The implementation of PAS is available at: https://github.com/AutoML-Research/PAS.},
	language = {en},
	number = {1},
	urldate = {2024-10-15},
	journal = {ACM Transactions on Information Systems},
	author = {Wei, Lanning and Zhao, Huan and He, Zhiqiang and Yao, Quanming},
	month = jan,
	year = {2024},
	pages = {1--29},
	file = {Wei et al. - 2024 - Neural Architecture Search for GNN-Based Graph Cla.pdf:C\:\\Users\\julia\\Zotero\\storage\\ZIAH43LR\\Wei et al. - 2024 - Neural Architecture Search for GNN-Based Graph Cla.pdf:application/pdf},
}

@article{yuan_explainability_nodate,
	title = {On {Explainability} of {Graph} {Neural} {Networks} via {Subgraph} {Explorations}},
	abstract = {We consider the problem of explaining the predictions of graph neural networks (GNNs), which otherwise are considered as black boxes. Existing methods invariably focus on explaining the importance of graph nodes or edges but ignore the substructures of graphs, which are more intuitive and human-intelligible. In this work, we propose a novel method, known as SubgraphX, to explain GNNs by identifying important subgraphs. Given a trained GNN model and an input graph, our SubgraphX explains its predictions by efﬁciently exploring different subgraphs with Monte Carlo tree search. To make the tree search more effective, we propose to use Shapley values as a measure of subgraph importance, which can also capture the interactions among different subgraphs. To expedite computations, we propose efﬁcient approximation schemes to compute Shapley values for graph data. Our work represents the ﬁrst attempt to explain GNNs via identifying subgraphs explicitly and directly. Experimental results show that our SubgraphX achieves signiﬁcantly improved explanations, while keeping computations at a reasonable level.},
	language = {en},
	author = {Yuan, Hao and Yu, Haiyang and Wang, Jie and Li, Kang and Ji, Shuiwang},
	file = {Yuan et al. - On Explainability of Graph Neural Networks via Sub.pdf:C\:\\Users\\julia\\Zotero\\storage\\CB59ZU8K\\Yuan et al. - On Explainability of Graph Neural Networks via Sub.pdf:application/pdf},
}

@article{veyrin-forrer_gnn_2024,
	title = {On {GNN} explainability with activation rules},
	volume = {38},
	issn = {1384-5810, 1573-756X},
	url = {https://link.springer.com/10.1007/s10618-022-00870-z},
	doi = {10.1007/s10618-022-00870-z},
	abstract = {GNNs are powerful models based on node representation learning that perform particularly well in many machine learning problems related to graphs. The major obstacle to the deployment of GNNs is mostly a problem of societal acceptability and trustworthiness, properties which require making explicit the internal functioning of such models. Here, we propose to mine activation rules in the hidden layers to understand how the GNNs perceive the world. The problem is not to discover activation rules that are individually highly discriminating for an output of the model. Instead, the challenge is to provide a small set of rules that cover all input graphs. To this end, we introduce the subjective activation pattern domain. We deﬁne an effective and principled algorithm to enumerate activations rules in each hidden layer. The proposed approach for quantifying the interest of these rules is rooted in information theory and is able to account for background knowledge on the input graph data. The activation rules can then be redescribed thanks to pattern languages involving interpretable features. We show that the activation rules provide insights on the characteristics used by the GNN to classify the graphs. Especially, this allows to identify the hidden features built by the GNN through its different layers. Also, these rules can subsequently be used for explaining GNN decisions. Experiments on both synthetic and real-life datasets show highly competitive performance, with up to 200\% improvement in ﬁdelity on explaining graph classiﬁcation over the SOTA methods.},
	language = {en},
	number = {5},
	urldate = {2024-10-15},
	journal = {Data Mining and Knowledge Discovery},
	author = {Veyrin-Forrer, Luca and Kamal, Ataollah and Duffner, Stefan and Plantevit, Marc and Robardet, Céline},
	month = sep,
	year = {2024},
	pages = {3227--3261},
	file = {Veyrin-Forrer et al. - 2024 - On GNN explainability with activation rules.pdf:C\:\\Users\\julia\\Zotero\\storage\\BQ2WESFA\\Veyrin-Forrer et al. - 2024 - On GNN explainability with activation rules.pdf:application/pdf},
}

@inproceedings{dai_towards_2021,
	address = {Virtual Event Queensland Australia},
	title = {Towards {Self}-{Explainable} {Graph} {Neural} {Network}},
	isbn = {978-1-4503-8446-9},
	url = {https://dl.acm.org/doi/10.1145/3459637.3482306},
	doi = {10.1145/3459637.3482306},
	abstract = {Graph Neural Networks (GNNs), which generalize the deep neural networks to graph-structured data, have achieved great success in modeling graphs. However, as an extension of deep learning for graphs, GNNs lack explainability, which largely limits their adoption in scenarios that demand the transparency of models. Though many efforts are taken to improve the explainability of deep learning, they mainly focus on i.i.d data, which cannot be directly applied to explain the predictions of GNNs because GNNs utilize both node features and graph topology to make predictions. There are only very few work on the explainability of GNNs and they focus on post-hoc explanations. Since post-hoc explanations are not directly obtained from the GNNs, they can be biased and misrepresent the true explanations. Therefore, in this paper, we study a novel problem of self-explainable GNNs which can simultaneously give predictions and explanations. We propose a new framework which can find 𝐾-nearest labeled nodes for each unlabeled node to give explainable node classification, where nearest labeled nodes are found by interpretable similarity module in terms of both node similarity and local structure similarity. Extensive experiments on real-world and synthetic datasets demonstrate the effectiveness of the proposed framework for explainable node classification.},
	language = {en},
	urldate = {2024-10-15},
	booktitle = {Proceedings of the 30th {ACM} {International} {Conference} on {Information} \& {Knowledge} {Management}},
	publisher = {ACM},
	author = {Dai, Enyan and Wang, Suhang},
	month = oct,
	year = {2021},
	pages = {302--311},
	file = {Dai und Wang - 2021 - Towards Self-Explainable Graph Neural Network.pdf:C\:\\Users\\julia\\Zotero\\storage\\ZPD5VEEX\\Dai und Wang - 2021 - Towards Self-Explainable Graph Neural Network.pdf:application/pdf},
}

@article{cucala_explainable_2022,
	title = {{EXPLAINABLE} {GNN}-{BASED} {MODELS} {OVER} {KNOWLEDGE} {GRAPHS}},
	abstract = {Graph Neural Networks (GNNs) are often used to learn transformations of graph data. While effective in practice, such approaches make predictions via numeric manipulations so their output cannot be easily explained symbolically. We propose a new family of GNN-based transformations of graph data that can be trained effectively, but where all predictions can be explained symbolically as logical inferences in Datalog—a well-known rule-based formalism. In particular, we show how to encode an input knowledge graph into a graph with numeric feature vectors, process this graph using a GNN, and decode the result into an output knowledge graph. We use a new class of monotonic GNNs (MGNNs) to ensure that this process is equivalent to a round of application of a set of Datalog rules. We also show that, given an arbitrary MGNN, we can automatically extract rules that completely characterise the transformation. We evaluate our approach by applying it to classiﬁcation tasks in knowledge graph completion.},
	language = {en},
	author = {Cucala, David Tena and Kostylev, Egor V and Grau, Bernardo Cuenca and Motik, Boris},
	year = {2022},
	file = {Cucala et al. - 2022 - EXPLAINABLE GNN-BASED MODELS OVER KNOWLEDGE GRAPHS.pdf:C\:\\Users\\julia\\Zotero\\storage\\H8STFWCE\\Cucala et al. - 2022 - EXPLAINABLE GNN-BASED MODELS OVER KNOWLEDGE GRAPHS.pdf:application/pdf},
}

@misc{li_survey_2023,
	title = {A {Survey} of {Explainable} {Graph} {Neural} {Networks}: {Taxonomy} and {Evaluation} {Metrics}},
	shorttitle = {A {Survey} of {Explainable} {Graph} {Neural} {Networks}},
	url = {http://arxiv.org/abs/2207.12599},
	abstract = {Graph neural networks (GNNs) have demonstrated a significant boost in prediction performance on the graph data. At the same time, the predictions made by these models are often hard to interpret. In that regard, many efforts have been made to explain the prediction mechanisms of these models from perspectives such as GNNExplainer, XGNN and PGExplainer. Although such works present systematic frameworks to interpret GNNs, a holistic review for explainable GNNs is unavailable. In this survey, we present a comprehensive review of explainability techniques developed for GNNs. We focus on explainable graph neural networks, categorize them based on the use of explainable methods. We further provide the common performance metrics for GNNs explanations and point out several future research directions.},
	language = {en},
	urldate = {2024-10-15},
	publisher = {arXiv},
	author = {Li, Yiqiao and Zhou, Jianlong and Verma, Sunny and Chen, Fang},
	month = may,
	year = {2023},
	note = {arXiv:2207.12599 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	file = {Li et al. - 2023 - A Survey of Explainable Graph Neural Networks Tax.pdf:C\:\\Users\\julia\\Zotero\\storage\\R9K276HT\\Li et al. - 2023 - A Survey of Explainable Graph Neural Networks Tax.pdf:application/pdf},
}

@misc{liu_survey_2023,
	title = {A {Survey} on {Graph} {Classification} and {Link} {Prediction} based on {GNN}},
	url = {http://arxiv.org/abs/2307.00865},
	abstract = {Traditional convolutional neural networks are limited to handling Euclidean space data, overlooking the vast realm of real-life scenarios represented as graph data, including transportation networks, social networks, and reference networks. The pivotal step in transferring convolutional neural networks to graph data analysis and processing lies in the construction of graph convolutional operators and graph pooling operators. This comprehensive review article delves into the world of graph convolutional neural networks. Firstly, it elaborates on the fundamentals of graph convolutional neural networks. Subsequently, it elucidates the graph neural network models based on attention mechanisms and autoencoders, summarizing their application in node classification, graph classification, and link prediction along with the associated datasets.},
	language = {en},
	urldate = {2024-10-15},
	publisher = {arXiv},
	author = {Liu, Xingyu and Chen, Juan and Wen, Quan},
	month = jul,
	year = {2023},
	note = {arXiv:2307.00865 [cs]},
	keywords = {Computer Science - Machine Learning},
	annote = {Comment: 18pages,4figures},
	file = {Liu et al. - 2023 - A Survey on Graph Classification and Link Predicti.pdf:C\:\\Users\\julia\\Zotero\\storage\\T5AA96H8\\Liu et al. - 2023 - A Survey on Graph Classification and Link Predicti.pdf:application/pdf},
}

@article{wu_comprehensive_2021,
	title = {A {Comprehensive} {Survey} on {Graph} {Neural} {Networks}},
	volume = {32},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	issn = {2162-237X, 2162-2388},
	url = {https://ieeexplore.ieee.org/document/9046288/},
	doi = {10.1109/TNNLS.2020.2978386},
	abstract = {Deep learning has revolutionized many machine learning tasks in recent years, ranging from image classiﬁcation and video processing to speech recognition and natural language understanding. The data in these tasks are typically represented in the Euclidean space. However, there is an increasing number of applications, where data are generated from non-Euclidean domains and are represented as graphs with complex relationships and interdependency between objects. The complexity of graph data has imposed signiﬁcant challenges on the existing machine learning algorithms. Recently, many studies on extending deep learning approaches for graph data have emerged. In this article, we provide a comprehensive overview of graph neural networks (GNNs) in data mining and machine learning ﬁelds. We propose a new taxonomy to divide the state-of-the-art GNNs into four categories, namely, recurrent GNNs, convolutional GNNs, graph autoencoders, and spatial–temporal GNNs. We further discuss the applications of GNNs across various domains and summarize the open-source codes, benchmark data sets, and model evaluation of GNNs. Finally, we propose potential research directions in this rapidly growing ﬁeld.},
	language = {en},
	number = {1},
	urldate = {2024-10-15},
	journal = {IEEE Transactions on Neural Networks and Learning Systems},
	author = {Wu, Zonghan and Pan, Shirui and Chen, Fengwen and Long, Guodong and Zhang, Chengqi and Yu, Philip S.},
	month = jan,
	year = {2021},
	pages = {4--24},
	file = {Wu et al. - 2021 - A Comprehensive Survey on Graph Neural Networks.pdf:C\:\\Users\\julia\\Zotero\\storage\\278U2S6P\\Wu et al. - 2021 - A Comprehensive Survey on Graph Neural Networks.pdf:application/pdf},
}

@inproceedings{wang_curgraph_2021,
	address = {Ljubljana Slovenia},
	title = {{CurGraph}: {Curriculum} {Learning} for {Graph} {Classification}},
	isbn = {978-1-4503-8312-7},
	shorttitle = {{CurGraph}},
	url = {https://dl.acm.org/doi/10.1145/3442381.3450025},
	doi = {10.1145/3442381.3450025},
	abstract = {Graph neural networks (GNNs) have achieved state-of-the-art performance on graph classification tasks. Existing work usually feeds graphs to GNNs in random order for training. However, graphs can vary greatly in their difficulty for classification, and we argue that GNNs can benefit from an easy-to-difficult curriculum, similar to the learning process of humans. Evaluating the difficulty of graphs is challenging due to the high irregularity of graph data. To address this issue, we present the CurGraph (Curriculum Learning for Graph Classification) framework, that analyzes the graph difficulty in the high-level semantic feature space. Specifically, we use the infomax method to obtain graph-level embeddings and a neural density estimator to model the embedding distributions. Then we calculate the difficulty scores of graphs based on the intra-class and inter-class distributions of their embeddings. Given the difficulty scores, CurGraph first exposes a GNN to easy graphs, before gradually moving on to hard ones. To provide a soft transition from easy to hard, we propose a smooth-step method, which utilizes a time-variant smooth function to filter out hard graphs. Thanks to CurGraph, a GNN learns from the graphs at the border of its capability, neither too easy or too hard, to gradually expand its border at each training step. Empirically, CurGraph yields significant gains for popular GNN models on graph classification and enables them to achieve superior performance on miscellaneous graphs.},
	language = {en},
	urldate = {2024-10-15},
	booktitle = {Proceedings of the {Web} {Conference} 2021},
	publisher = {ACM},
	author = {Wang, Yiwei and Wang, Wei and Liang, Yuxuan and Cai, Yujun and Hooi, Bryan},
	month = apr,
	year = {2021},
	pages = {1238--1248},
	file = {Wang et al. - 2021 - CurGraph Curriculum Learning for Graph Classifica.pdf:C\:\\Users\\julia\\Zotero\\storage\\ZIASPH4E\\Wang et al. - 2021 - CurGraph Curriculum Learning for Graph Classifica.pdf:application/pdf},
}

@misc{muller_dtgnn_2022,
	title = {{DT}+{GNN}: {A} {Fully} {Explainable} {Graph} {Neural} {Network} using {Decision} {Trees}},
	shorttitle = {{DT}+{GNN}},
	url = {http://arxiv.org/abs/2205.13234},
	abstract = {We propose the fully explainable Decision Tree Graph Neural Network (DT+GNN) architecture. In contrast to existing black-box GNNs and post-hoc explanation methods, the reasoning of DT+GNN can be inspected at every step. To achieve this, we ﬁrst construct a differentiable GNN layer, which uses a categorical state space for nodes and messages. This allows us to convert the trained MLPs in the GNN into decision trees. These trees are pruned using our newly proposed method to ensure they are small and easy to interpret. We can also use the decision trees to compute traditional explanations. We demonstrate on both real-world datasets and synthetic GNN explainability benchmarks that this architecture works as well as traditional GNNs. Furthermore, we leverage the explainability of DT+GNNs to ﬁnd interesting insights into many of these datasets, with some surprising results. We also provide an interactive web tool to inspect DT+GNN’s decision making.},
	language = {en},
	urldate = {2024-10-15},
	publisher = {arXiv},
	author = {Müller, Peter and Faber, Lukas and Martinkus, Karolis and Wattenhofer, Roger},
	month = may,
	year = {2022},
	note = {arXiv:2205.13234 [cs]},
	keywords = {Computer Science - Machine Learning},
	file = {Müller et al. - 2022 - DT+GNN A Fully Explainable Graph Neural Network u.pdf:C\:\\Users\\julia\\Zotero\\storage\\KXSAVMB5\\Müller et al. - 2022 - DT+GNN A Fully Explainable Graph Neural Network u.pdf:application/pdf},
}

@article{li_egnn_2022,
	title = {{EGNN}: {Constructing} explainable graph neural networks via knowledge distillation},
	volume = {241},
	issn = {09507051},
	shorttitle = {{EGNN}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0950705122001289},
	doi = {10.1016/j.knosys.2022.108345},
	abstract = {Graph neural networks are widely utilized for processing data represented by graphs, which renders them ubiquitous in daily life. Due to their excellent performance in extracting features from structural data, graph neural networks have attracted an increasing amount of attention from both academia and industry. Essentially, most GNN models learn representations of nodes by fully/randomly aggregating their neighbor features. However, these unsophisticatedly-designed aggregation schemes always lead to a lack of interpretability, compromising the scope of adoption of GNN models. This study attempts to construct a transparent and explainable GNN model by distilling knowledge from pretrained "blackbox" models. Specifically, by simultaneously preserving fidelity to the behaviors of the original model and optimizing the loss of prediction, a shallow graph neural network with explicit "contribution" weights between two nodes is trained. Next, a neighbor selection strategy is built upon these explicit weights to ensure high levels of performance and interpretability. To evaluate the proposed framework, our method is incorporated into four state-of-the-art models: GCN, GAT, GraphSAGE, and AM-GCN. Experimental results on three real-world datasets show the effectiveness of the proposed framework. © 2022 Elsevier B.V. All rights reserved.},
	language = {en},
	urldate = {2024-10-15},
	journal = {Knowledge-Based Systems},
	author = {Li, Yuan and Liu, Li and Wang, Guoyin and Du, Yong and Chen, Penggang},
	month = apr,
	year = {2022},
	pages = {108345},
	file = {Li et al. - 2022 - EGNN Constructing explainable graph neural networ.pdf:C\:\\Users\\julia\\Zotero\\storage\\HQ82A4VU\\Li et al. - 2022 - EGNN Constructing explainable graph neural networ.pdf:application/pdf},
}

@article{agarwal_evaluating_2023,
	title = {Evaluating explainability for graph neural networks},
	volume = {10},
	issn = {2052-4463},
	url = {https://www.nature.com/articles/s41597-023-01974-x},
	doi = {10.1038/s41597-023-01974-x},
	abstract = {Abstract
            
              As explanations are increasingly used to understand the behavior of graph neural networks (GNNs), evaluating the quality and reliability of GNN explanations is crucial. However, assessing the quality of GNN explanations is challenging as existing graph datasets have no or unreliable ground-truth explanations. Here, we introduce a synthetic graph data generator,
              Shape
              GG
              en
              , which can generate a variety of benchmark datasets (e.g., varying graph sizes, degree distributions, homophilic vs. heterophilic graphs) accompanied by ground-truth explanations. The flexibility to generate diverse synthetic datasets and corresponding ground-truth explanations allows
              Shape
              GG
              en
              to mimic the data in various real-world areas. We include
              Shape
              GG
              en
              and several real-world graph datasets in a graph explainability library, G
              raph
              XAI. In addition to synthetic and real-world graph datasets with ground-truth explanations, G
              raph
              XAI provides data loaders, data processing functions, visualizers, GNN model implementations, and evaluation metrics to benchmark GNN explainability methods.},
	language = {en},
	number = {1},
	urldate = {2024-10-15},
	journal = {Scientific Data},
	author = {Agarwal, Chirag and Queen, Owen and Lakkaraju, Himabindu and Zitnik, Marinka},
	month = mar,
	year = {2023},
	pages = {144},
	file = {Agarwal et al. - 2023 - Evaluating explainability for graph neural network.pdf:C\:\\Users\\julia\\Zotero\\storage\\8UG3Q2GS\\Agarwal et al. - 2023 - Evaluating explainability for graph neural network.pdf:application/pdf},
}

@misc{li_explainability_2022,
	title = {Explainability in {Graph} {Neural} {Networks}: {An} {Experimental} {Survey}},
	shorttitle = {Explainability in {Graph} {Neural} {Networks}},
	url = {http://arxiv.org/abs/2203.09258},
	abstract = {Graph neural networks (GNNs) have been extensively developed for graph representation learning in various application domains. However, similar to all other neural networks models, GNNs suffer from the black-box problem as people cannot understand the mechanism underlying them. To solve this problem, several GNN explainability methods have been proposed to explain the decisions made by GNNs. In this survey, we give an overview of the state-of-the-art GNN explainability methods and how they are evaluated. Furthermore, we propose a new evaluation metric and conduct thorough experiments to compare GNN explainability methods on real world datasets. We also suggest future directions for GNN explainability.},
	language = {en},
	urldate = {2024-10-15},
	publisher = {arXiv},
	author = {Li, Peibo and Yang, Yixing and Pagnucco, Maurice and Song, Yang},
	month = mar,
	year = {2022},
	note = {arXiv:2203.09258 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	file = {Li et al. - 2022 - Explainability in Graph Neural Networks An Experi.pdf:C\:\\Users\\julia\\Zotero\\storage\\WNVIU72R\\Li et al. - 2022 - Explainability in Graph Neural Networks An Experi.pdf:application/pdf},
}

@article{yuan_explainability_2022,
	title = {Explainability in {Graph} {Neural} {Networks}: {A} {Taxonomic} {Survey}},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	issn = {0162-8828, 2160-9292, 1939-3539},
	shorttitle = {Explainability in {Graph} {Neural} {Networks}},
	url = {https://ieeexplore.ieee.org/document/9875989/},
	doi = {10.1109/TPAMI.2022.3204236},
	abstract = {Deep learning methods are achieving ever-increasing performance on many artiﬁcial intelligence tasks. A major limitation of deep models is that they are not amenable to interpretability. This limitation can be circumvented by developing post hoc techniques to explain predictions, giving rise to the area of explainability. Recently, explainability of deep models on images and texts has achieved signiﬁcant progress. In the area of graph data, graph neural networks (GNNs) and their explainability are experiencing rapid developments. However, there is neither a uniﬁed treatment of GNN explainability methods, nor a standard benchmark and testbed for evaluations. In this survey, we provide a uniﬁed and taxonomic view of current GNN explainability methods. Our uniﬁed and taxonomic treatments of this subject shed lights on the commonalities and differences of existing methods and set the stage for further methodological developments. To facilitate evaluations, we provide a testbed for GNN explainability, including datasets, common algorithms and evaluation metrics. Furthermore, we conduct comprehensive experiments to compare and analyze the performance of many techniques. Altogether, this work provides a uniﬁed methodological treatment of GNN explainability and a standardized testbed for evaluations.},
	language = {en},
	urldate = {2024-10-15},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Yuan, Hao and Yu, Haiyang and Gui, Shurui and Ji, Shuiwang},
	year = {2022},
	pages = {1--19},
	file = {Yuan et al. - 2022 - Explainability in Graph Neural Networks A Taxonom.pdf:C\:\\Users\\julia\\Zotero\\storage\\6DET7W8T\\Yuan et al. - 2022 - Explainability in Graph Neural Networks A Taxonom.pdf:application/pdf},
}

@book{holzinger_xxai_2022,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {{xxAI} - {Beyond} {Explainable} {AI}: {International} {Workshop}, {Held} in {Conjunction} with {ICML} 2020, {July} 18, 2020, {Vienna}, {Austria}, {Revised} and {Extended} {Papers}},
	volume = {13200},
	copyright = {https://creativecommons.org/licenses/by/4.0},
	isbn = {978-3-031-04082-5 978-3-031-04083-2},
	shorttitle = {{xxAI} - {Beyond} {Explainable} {AI}},
	url = {https://link.springer.com/10.1007/978-3-031-04083-2},
	language = {en},
	urldate = {2024-10-15},
	publisher = {Springer International Publishing},
	editor = {Holzinger, Andreas and Goebel, Randy and Fong, Ruth and Moon, Taesup and Müller, Klaus-Robert and Samek, Wojciech},
	year = {2022},
	doi = {10.1007/978-3-031-04083-2},
	file = {Holzinger et al. - 2022 - xxAI - Beyond Explainable AI International Worksh.pdf:C\:\\Users\\julia\\Zotero\\storage\\IGQ6S5DB\\Holzinger et al. - 2022 - xxAI - Beyond Explainable AI International Worksh.pdf:application/pdf},
}

@article{minh_explainable_2022,
	title = {Explainable artificial intelligence: a comprehensive review},
	volume = {55},
	issn = {0269-2821, 1573-7462},
	shorttitle = {Explainable artificial intelligence},
	url = {https://link.springer.com/10.1007/s10462-021-10088-y},
	doi = {10.1007/s10462-021-10088-y},
	abstract = {Thanks to the exponential growth in computing power and vast amounts of data, artificial intelligence (AI) has witnessed remarkable developments in recent years, enabling it to be ubiquitously adopted in our daily lives. Even though AI-powered systems have brought competitive advantages, the black-box nature makes them lack transparency and prevents them from explaining their decisions. This issue has motivated the introduction of explainable artificial intelligence (XAI), which promotes AI algorithms that can show their internal process and explain how they made decisions. The number of XAI research has increased significantly in recent years, but there lacks a unified and comprehensive review of the latest XAI progress. This review aims to bridge the gap by discovering the critical perspectives of the rapidly growing body of research associated with XAI. After offering the readers a solid XAI background, we analyze and review various XAI methods, which are grouped into (i) pre-modeling explainability, (ii) interpretable model, and (iii) post-modeling explainability. We also pay attention to the current methods that dedicate to interpret and analyze deep learning methods. In addition, we systematically discuss various XAI challenges, such as the trade-off between the performance and the explainability, evaluation methods, security, and policy. Finally, we show the standard approaches that are leveraged to deal with the mentioned challenges.},
	language = {en},
	number = {5},
	urldate = {2024-10-15},
	journal = {Artificial Intelligence Review},
	author = {Minh, Dang and Wang, H. Xiang and Li, Y. Fen and Nguyen, Tan N.},
	month = jun,
	year = {2022},
	pages = {3503--3568},
	file = {Minh et al. - 2022 - Explainable artificial intelligence a comprehensi.pdf:C\:\\Users\\julia\\Zotero\\storage\\PPQ84SFL\\Minh et al. - 2022 - Explainable artificial intelligence a comprehensi.pdf:application/pdf},
}

@article{angelov_explainable_2021,
	title = {Explainable artificial intelligence: an analytical review},
	volume = {11},
	issn = {1942-4787, 1942-4795},
	shorttitle = {Explainable artificial intelligence},
	url = {https://wires.onlinelibrary.wiley.com/doi/10.1002/widm.1424},
	doi = {10.1002/widm.1424},
	abstract = {This paper provides a brief analytical review of the current state-of-the-art in relation to the explainability of artificial intelligence in the context of recent advances in machine learning and deep learning. The paper starts with a brief historical introduction and a taxonomy, and formulates the main challenges in terms of explainability building on the recently formulated National Institute of Standards four principles of explainability. Recently published methods related to the topic are then critically reviewed and analyzed. Finally, future directions for research are suggested.},
	language = {en},
	number = {5},
	urldate = {2024-10-15},
	journal = {WIREs Data Mining and Knowledge Discovery},
	author = {Angelov, Plamen P. and Soares, Eduardo A. and Jiang, Richard and Arnold, Nicholas I. and Atkinson, Peter M.},
	month = sep,
	year = {2021},
	pages = {e1424},
	file = {Angelov et al. - 2021 - Explainable artificial intelligence an analytical.pdf:C\:\\Users\\julia\\Zotero\\storage\\4Z53QMYP\\Angelov et al. - 2021 - Explainable artificial intelligence an analytical.pdf:application/pdf},
}

@inproceedings{dosilovic_explainable_2018,
	address = {Opatija},
	title = {Explainable artificial intelligence: {A} survey},
	isbn = {978-953-233-095-3},
	shorttitle = {Explainable artificial intelligence},
	url = {https://ieeexplore.ieee.org/document/8400040/},
	doi = {10.23919/MIPRO.2018.8400040},
	abstract = {In the last decade, with availability of large datasets and more com puting power, machine learning systems have achieved (super)human performance in a wide variety of tasks. Examples of this rapid development can be seen in image recognition, speech analysis, strategic game planning and many more. The problem with many state-ofthe-art models is a lack of transparency and interpretability. The lack of thereof is a major drawback in many applications, e.g. health care and finance, where rationale for model's decision is a requirement for trust. In the light of these issues, explainable artificial intelligence (XAI) has become an area of interest in research community. This paper summarizes recent developments in XAI in supervised learning, starts a discussion on its connection with artificial general intelligence, and gives proposals for further research directions.},
	language = {en},
	urldate = {2024-10-15},
	booktitle = {2018 41st {International} {Convention} on {Information} and {Communication} {Technology}, {Electronics} and {Microelectronics} ({MIPRO})},
	publisher = {IEEE},
	author = {Dosilovic, Filip Karlo and Brcic, Mario and Hlupic, Nikica},
	month = may,
	year = {2018},
	pages = {0210--0215},
	file = {Dosilovic et al. - 2018 - Explainable artificial intelligence A survey.pdf:C\:\\Users\\julia\\Zotero\\storage\\Y94ZTS3U\\Dosilovic et al. - 2018 - Explainable artificial intelligence A survey.pdf:application/pdf},
}

@book{iliadis_artificial_2023,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Artificial {Neural} {Networks} and {Machine} {Learning} – {ICANN} 2023: 32nd {International} {Conference} on {Artificial} {Neural} {Networks}, {Heraklion}, {Crete}, {Greece}, {September} 26–29, 2023, {Proceedings}, {Part} {IV}},
	volume = {14257},
	copyright = {https://www.springernature.com/gp/researchers/text-and-data-mining},
	isbn = {978-3-031-44215-5 978-3-031-44216-2},
	shorttitle = {Artificial {Neural} {Networks} and {Machine} {Learning} – {ICANN} 2023},
	url = {https://link.springer.com/10.1007/978-3-031-44216-2},
	language = {en},
	urldate = {2024-10-15},
	publisher = {Springer Nature Switzerland},
	editor = {Iliadis, Lazaros and Papaleonidas, Antonios and Angelov, Plamen and Jayne, Chrisina},
	year = {2023},
	doi = {10.1007/978-3-031-44216-2},
	file = {Iliadis et al. - 2023 - Artificial Neural Networks and Machine Learning – .pdf:C\:\\Users\\julia\\Zotero\\storage\\V5HPFIUQ\\Iliadis et al. - 2023 - Artificial Neural Networks and Machine Learning – .pdf:application/pdf},
}

@incollection{getoor_graphical_2007,
	title = {Graphical {Models} in a {Nutshell}},
	isbn = {978-0-262-25623-0},
	url = {https://direct.mit.edu/books/book/3811/chapter/125067/Graphical-Models-in-a-Nutshell},
	language = {en},
	urldate = {2024-10-15},
	booktitle = {Introduction to {Statistical} {Relational} {Learning}},
	publisher = {The MIT Press},
	author = {Koller, Daphne and Friedman, Nir and Getoor, Lise and Taskar, Ben},
	editor = {Getoor, Lise and Taskar, Ben},
	month = aug,
	year = {2007},
	doi = {10.7551/mitpress/7432.003.0004},
	pages = {13--56},
	file = {Koller et al. - 2007 - Graphical Models in a Nutshell.pdf:C\:\\Users\\julia\\Zotero\\storage\\GU36QF5J\\Koller et al. - 2007 - Graphical Models in a Nutshell.pdf:application/pdf},
}

@article{cucala_explainable_2022-1,
	title = {{EXPLAINABLE} {GNN}-{BASED} {MODELS} {OVER} {KNOWLEDGE} {GRAPHS}},
	abstract = {Graph Neural Networks (GNNs) are often used to learn transformations of graph data. While effective in practice, such approaches make predictions via numeric manipulations so their output cannot be easily explained symbolically. We propose a new family of GNN-based transformations of graph data that can be trained effectively, but where all predictions can be explained symbolically as logical inferences in Datalog—a well-known rule-based formalism. In particular, we show how to encode an input knowledge graph into a graph with numeric feature vectors, process this graph using a GNN, and decode the result into an output knowledge graph. We use a new class of monotonic GNNs (MGNNs) to ensure that this process is equivalent to a round of application of a set of Datalog rules. We also show that, given an arbitrary MGNN, we can automatically extract rules that completely characterise the transformation. We evaluate our approach by applying it to classiﬁcation tasks in knowledge graph completion.},
	language = {en},
	author = {Cucala, David Tena and Kostylev, Egor V and Grau, Bernardo Cuenca and Motik, Boris},
	year = {2022},
	keywords = {ungelesen},
	file = {1827_explainable_gnn_based_models_o.pdf:D\:\\Dokumente\\05 Uni\\9. Semester\\03 Analyse eines Forschungsthemas\\Literatur\\1827_explainable_gnn_based_models_o.pdf:application/pdf},
}

@misc{li_survey_2023-1,
	title = {A {Survey} of {Explainable} {Graph} {Neural} {Networks}: {Taxonomy} and {Evaluation} {Metrics}},
	shorttitle = {A {Survey} of {Explainable} {Graph} {Neural} {Networks}},
	url = {http://arxiv.org/abs/2207.12599},
	abstract = {Graph neural networks (GNNs) have demonstrated a significant boost in prediction performance on the graph data. At the same time, the predictions made by these models are often hard to interpret. In that regard, many efforts have been made to explain the prediction mechanisms of these models from perspectives such as GNNExplainer, XGNN and PGExplainer. Although such works present systematic frameworks to interpret GNNs, a holistic review for explainable GNNs is unavailable. In this survey, we present a comprehensive review of explainability techniques developed for GNNs. We focus on explainable graph neural networks, categorize them based on the use of explainable methods. We further provide the common performance metrics for GNNs explanations and point out several future research directions.},
	language = {en},
	urldate = {2024-10-15},
	publisher = {arXiv},
	author = {Li, Yiqiao and Zhou, Jianlong and Verma, Sunny and Chen, Fang},
	month = may,
	year = {2023},
	note = {arXiv:2207.12599 [cs]},
	keywords = {gelesen, Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	file = {A Survey of Explainable Graph Neural Networks Taxonomy and Evaluation Metrics.pdf:D\:\\Dokumente\\05 Uni\\9. Semester\\03 Analyse eines Forschungsthemas\\Literatur\\A Survey of Explainable Graph Neural Networks Taxonomy and Evaluation Metrics.pdf:application/pdf},
}

@misc{liu_survey_2023-1,
	title = {A {Survey} on {Graph} {Classification} and {Link} {Prediction} based on {GNN}},
	url = {http://arxiv.org/abs/2307.00865},
	abstract = {Traditional convolutional neural networks are limited to handling Euclidean space data, overlooking the vast realm of real-life scenarios represented as graph data, including transportation networks, social networks, and reference networks. The pivotal step in transferring convolutional neural networks to graph data analysis and processing lies in the construction of graph convolutional operators and graph pooling operators. This comprehensive review article delves into the world of graph convolutional neural networks. Firstly, it elaborates on the fundamentals of graph convolutional neural networks. Subsequently, it elucidates the graph neural network models based on attention mechanisms and autoencoders, summarizing their application in node classification, graph classification, and link prediction along with the associated datasets.},
	language = {en},
	urldate = {2024-10-15},
	publisher = {arXiv},
	author = {Liu, Xingyu and Chen, Juan and Wen, Quan},
	month = jul,
	year = {2023},
	note = {arXiv:2307.00865 [cs]},
	keywords = {ungelesen, Computer Science - Machine Learning},
	annote = {Comment: 18pages,4figures},
	file = {A Survey on Graph Classification and Link Prediction based on GNN.pdf:D\:\\Dokumente\\05 Uni\\9. Semester\\03 Analyse eines Forschungsthemas\\Literatur\\A Survey on Graph Classification and Link Prediction based on GNN.pdf:application/pdf},
}

@article{wu_comprehensive_2021-1,
	title = {A {Comprehensive} {Survey} on {Graph} {Neural} {Networks}},
	volume = {32},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	issn = {2162-237X, 2162-2388},
	url = {https://ieeexplore.ieee.org/document/9046288/},
	doi = {10.1109/TNNLS.2020.2978386},
	abstract = {Deep learning has revolutionized many machine learning tasks in recent years, ranging from image classiﬁcation and video processing to speech recognition and natural language understanding. The data in these tasks are typically represented in the Euclidean space. However, there is an increasing number of applications, where data are generated from non-Euclidean domains and are represented as graphs with complex relationships and interdependency between objects. The complexity of graph data has imposed signiﬁcant challenges on the existing machine learning algorithms. Recently, many studies on extending deep learning approaches for graph data have emerged. In this article, we provide a comprehensive overview of graph neural networks (GNNs) in data mining and machine learning ﬁelds. We propose a new taxonomy to divide the state-of-the-art GNNs into four categories, namely, recurrent GNNs, convolutional GNNs, graph autoencoders, and spatial–temporal GNNs. We further discuss the applications of GNNs across various domains and summarize the open-source codes, benchmark data sets, and model evaluation of GNNs. Finally, we propose potential research directions in this rapidly growing ﬁeld.},
	language = {en},
	number = {1},
	urldate = {2024-10-15},
	journal = {IEEE Transactions on Neural Networks and Learning Systems},
	author = {Wu, Zonghan and Pan, Shirui and Chen, Fengwen and Long, Guodong and Zhang, Chengqi and Yu, Philip S.},
	month = jan,
	year = {2021},
	keywords = {gelesen},
	pages = {4--24},
	file = {A_Comprehensive_Survey_on_Graph_Neural_Networks.pdf:D\:\\Dokumente\\05 Uni\\9. Semester\\03 Analyse eines Forschungsthemas\\Literatur\\A_Comprehensive_Survey_on_Graph_Neural_Networks.pdf:application/pdf},
}

@inproceedings{wang_curgraph_2021-1,
	address = {Ljubljana Slovenia},
	title = {{CurGraph}: {Curriculum} {Learning} for {Graph} {Classification}},
	isbn = {978-1-4503-8312-7},
	shorttitle = {{CurGraph}},
	url = {https://dl.acm.org/doi/10.1145/3442381.3450025},
	doi = {10.1145/3442381.3450025},
	abstract = {Graph neural networks (GNNs) have achieved state-of-the-art performance on graph classification tasks. Existing work usually feeds graphs to GNNs in random order for training. However, graphs can vary greatly in their difficulty for classification, and we argue that GNNs can benefit from an easy-to-difficult curriculum, similar to the learning process of humans. Evaluating the difficulty of graphs is challenging due to the high irregularity of graph data. To address this issue, we present the CurGraph (Curriculum Learning for Graph Classification) framework, that analyzes the graph difficulty in the high-level semantic feature space. Specifically, we use the infomax method to obtain graph-level embeddings and a neural density estimator to model the embedding distributions. Then we calculate the difficulty scores of graphs based on the intra-class and inter-class distributions of their embeddings. Given the difficulty scores, CurGraph first exposes a GNN to easy graphs, before gradually moving on to hard ones. To provide a soft transition from easy to hard, we propose a smooth-step method, which utilizes a time-variant smooth function to filter out hard graphs. Thanks to CurGraph, a GNN learns from the graphs at the border of its capability, neither too easy or too hard, to gradually expand its border at each training step. Empirically, CurGraph yields significant gains for popular GNN models on graph classification and enables them to achieve superior performance on miscellaneous graphs.},
	language = {en},
	urldate = {2024-10-15},
	booktitle = {Proceedings of the {Web} {Conference} 2021},
	publisher = {ACM},
	author = {Wang, Yiwei and Wang, Wei and Liang, Yuxuan and Cai, Yujun and Hooi, Bryan},
	month = apr,
	year = {2021},
	keywords = {ungelesen},
	pages = {1238--1248},
	file = {CurGraph Curriculum Learning for Graph Classification.pdf:D\:\\Dokumente\\05 Uni\\9. Semester\\03 Analyse eines Forschungsthemas\\Literatur\\CurGraph Curriculum Learning for Graph Classification.pdf:application/pdf},
}

@misc{muller_dtgnn_2022-1,
	title = {{DT}+{GNN}: {A} {Fully} {Explainable} {Graph} {Neural} {Network} using {Decision} {Trees}},
	shorttitle = {{DT}+{GNN}},
	url = {http://arxiv.org/abs/2205.13234},
	abstract = {We propose the fully explainable Decision Tree Graph Neural Network (DT+GNN) architecture. In contrast to existing black-box GNNs and post-hoc explanation methods, the reasoning of DT+GNN can be inspected at every step. To achieve this, we ﬁrst construct a differentiable GNN layer, which uses a categorical state space for nodes and messages. This allows us to convert the trained MLPs in the GNN into decision trees. These trees are pruned using our newly proposed method to ensure they are small and easy to interpret. We can also use the decision trees to compute traditional explanations. We demonstrate on both real-world datasets and synthetic GNN explainability benchmarks that this architecture works as well as traditional GNNs. Furthermore, we leverage the explainability of DT+GNNs to ﬁnd interesting insights into many of these datasets, with some surprising results. We also provide an interactive web tool to inspect DT+GNN’s decision making.},
	language = {en},
	urldate = {2024-10-15},
	publisher = {arXiv},
	author = {Müller, Peter and Faber, Lukas and Martinkus, Karolis and Wattenhofer, Roger},
	month = may,
	year = {2022},
	note = {arXiv:2205.13234 [cs]},
	keywords = {gelesen, Computer Science - Machine Learning},
	file = {DT+GNN A Fully Explainable Graph Neural Network using Decision Trees.pdf:D\:\\Dokumente\\05 Uni\\9. Semester\\03 Analyse eines Forschungsthemas\\Literatur\\DT+GNN A Fully Explainable Graph Neural Network using Decision Trees.pdf:application/pdf},
}

@article{li_egnn_2022-1,
	title = {{EGNN}: {Constructing} explainable graph neural networks via knowledge distillation},
	volume = {241},
	issn = {09507051},
	shorttitle = {{EGNN}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0950705122001289},
	doi = {10.1016/j.knosys.2022.108345},
	abstract = {Graph neural networks are widely utilized for processing data represented by graphs, which renders them ubiquitous in daily life. Due to their excellent performance in extracting features from structural data, graph neural networks have attracted an increasing amount of attention from both academia and industry. Essentially, most GNN models learn representations of nodes by fully/randomly aggregating their neighbor features. However, these unsophisticatedly-designed aggregation schemes always lead to a lack of interpretability, compromising the scope of adoption of GNN models. This study attempts to construct a transparent and explainable GNN model by distilling knowledge from pretrained "blackbox" models. Specifically, by simultaneously preserving fidelity to the behaviors of the original model and optimizing the loss of prediction, a shallow graph neural network with explicit "contribution" weights between two nodes is trained. Next, a neighbor selection strategy is built upon these explicit weights to ensure high levels of performance and interpretability. To evaluate the proposed framework, our method is incorporated into four state-of-the-art models: GCN, GAT, GraphSAGE, and AM-GCN. Experimental results on three real-world datasets show the effectiveness of the proposed framework. © 2022 Elsevier B.V. All rights reserved.},
	language = {en},
	urldate = {2024-10-15},
	journal = {Knowledge-Based Systems},
	author = {Li, Yuan and Liu, Li and Wang, Guoyin and Du, Yong and Chen, Penggang},
	month = apr,
	year = {2022},
	keywords = {ungelesen},
	pages = {108345},
	file = {EGNN Constructing explainable graph neural networks via knowledge.pdf:D\:\\Dokumente\\05 Uni\\9. Semester\\03 Analyse eines Forschungsthemas\\Literatur\\EGNN Constructing explainable graph neural networks via knowledge.pdf:application/pdf},
}

@article{agarwal_evaluating_2023-1,
	title = {Evaluating explainability for graph neural networks},
	volume = {10},
	issn = {2052-4463},
	url = {https://www.nature.com/articles/s41597-023-01974-x},
	doi = {10.1038/s41597-023-01974-x},
	abstract = {Abstract
            
              As explanations are increasingly used to understand the behavior of graph neural networks (GNNs), evaluating the quality and reliability of GNN explanations is crucial. However, assessing the quality of GNN explanations is challenging as existing graph datasets have no or unreliable ground-truth explanations. Here, we introduce a synthetic graph data generator,
              Shape
              GG
              en
              , which can generate a variety of benchmark datasets (e.g., varying graph sizes, degree distributions, homophilic vs. heterophilic graphs) accompanied by ground-truth explanations. The flexibility to generate diverse synthetic datasets and corresponding ground-truth explanations allows
              Shape
              GG
              en
              to mimic the data in various real-world areas. We include
              Shape
              GG
              en
              and several real-world graph datasets in a graph explainability library, G
              raph
              XAI. In addition to synthetic and real-world graph datasets with ground-truth explanations, G
              raph
              XAI provides data loaders, data processing functions, visualizers, GNN model implementations, and evaluation metrics to benchmark GNN explainability methods.},
	language = {en},
	number = {1},
	urldate = {2024-10-15},
	journal = {Scientific Data},
	author = {Agarwal, Chirag and Queen, Owen and Lakkaraju, Himabindu and Zitnik, Marinka},
	month = mar,
	year = {2023},
	keywords = {ungelesen},
	pages = {144},
	file = {Evaluating explainability for graph neural networks.pdf:D\:\\Dokumente\\05 Uni\\9. Semester\\03 Analyse eines Forschungsthemas\\Literatur\\Evaluating explainability for graph neural networks.pdf:application/pdf},
}

@misc{li_explainability_2022-1,
	title = {Explainability in {Graph} {Neural} {Networks}: {An} {Experimental} {Survey}},
	shorttitle = {Explainability in {Graph} {Neural} {Networks}},
	url = {http://arxiv.org/abs/2203.09258},
	abstract = {Graph neural networks (GNNs) have been extensively developed for graph representation learning in various application domains. However, similar to all other neural networks models, GNNs suffer from the black-box problem as people cannot understand the mechanism underlying them. To solve this problem, several GNN explainability methods have been proposed to explain the decisions made by GNNs. In this survey, we give an overview of the state-of-the-art GNN explainability methods and how they are evaluated. Furthermore, we propose a new evaluation metric and conduct thorough experiments to compare GNN explainability methods on real world datasets. We also suggest future directions for GNN explainability.},
	language = {en},
	urldate = {2024-10-15},
	publisher = {arXiv},
	author = {Li, Peibo and Yang, Yixing and Pagnucco, Maurice and Song, Yang},
	month = mar,
	year = {2022},
	note = {arXiv:2203.09258 [cs]},
	keywords = {ungelesen, Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	file = {Explainability in Graph Neural Networks An Experimental Survey.pdf:D\:\\Dokumente\\05 Uni\\9. Semester\\03 Analyse eines Forschungsthemas\\Literatur\\Explainability in Graph Neural Networks An Experimental Survey.pdf:application/pdf},
}

@article{yuan_explainability_2022-1,
	title = {Explainability in {Graph} {Neural} {Networks}: {A} {Taxonomic} {Survey}},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	issn = {0162-8828, 2160-9292, 1939-3539},
	shorttitle = {Explainability in {Graph} {Neural} {Networks}},
	url = {https://ieeexplore.ieee.org/document/9875989/},
	doi = {10.1109/TPAMI.2022.3204236},
	abstract = {Deep learning methods are achieving ever-increasing performance on many artiﬁcial intelligence tasks. A major limitation of deep models is that they are not amenable to interpretability. This limitation can be circumvented by developing post hoc techniques to explain predictions, giving rise to the area of explainability. Recently, explainability of deep models on images and texts has achieved signiﬁcant progress. In the area of graph data, graph neural networks (GNNs) and their explainability are experiencing rapid developments. However, there is neither a uniﬁed treatment of GNN explainability methods, nor a standard benchmark and testbed for evaluations. In this survey, we provide a uniﬁed and taxonomic view of current GNN explainability methods. Our uniﬁed and taxonomic treatments of this subject shed lights on the commonalities and differences of existing methods and set the stage for further methodological developments. To facilitate evaluations, we provide a testbed for GNN explainability, including datasets, common algorithms and evaluation metrics. Furthermore, we conduct comprehensive experiments to compare and analyze the performance of many techniques. Altogether, this work provides a uniﬁed methodological treatment of GNN explainability and a standardized testbed for evaluations.},
	language = {en},
	urldate = {2024-10-15},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Yuan, Hao and Yu, Haiyang and Gui, Shurui and Ji, Shuiwang},
	year = {2022},
	keywords = {ungelesen},
	pages = {1--19},
	file = {Explainability_in_Graph_Neural_Networks_A_Taxonomic_Survey.pdf:D\:\\Dokumente\\05 Uni\\9. Semester\\03 Analyse eines Forschungsthemas\\Literatur\\Explainability_in_Graph_Neural_Networks_A_Taxonomic_Survey.pdf:application/pdf},
}

@book{holzinger_xxai_2022-1,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {{xxAI} - {Beyond} {Explainable} {AI}: {International} {Workshop}, {Held} in {Conjunction} with {ICML} 2020, {July} 18, 2020, {Vienna}, {Austria}, {Revised} and {Extended} {Papers}},
	volume = {13200},
	copyright = {https://creativecommons.org/licenses/by/4.0},
	isbn = {978-3-031-04082-5 978-3-031-04083-2},
	shorttitle = {{xxAI} - {Beyond} {Explainable} {AI}},
	url = {https://link.springer.com/10.1007/978-3-031-04083-2},
	language = {en},
	urldate = {2024-10-15},
	publisher = {Springer International Publishing},
	editor = {Holzinger, Andreas and Goebel, Randy and Fong, Ruth and Moon, Taesup and Müller, Klaus-Robert and Samek, Wojciech},
	year = {2022},
	doi = {10.1007/978-3-031-04083-2},
	keywords = {ungelesen},
	annote = {13

},
	file = {Explainable AI Methods - A Brief Overview.pdf:D\:\\Dokumente\\05 Uni\\9. Semester\\03 Analyse eines Forschungsthemas\\Literatur\\Explainable AI Methods - A Brief Overview.pdf:application/pdf},
}

@article{minh_explainable_2022-1,
	title = {Explainable artificial intelligence: a comprehensive review},
	volume = {55},
	issn = {0269-2821, 1573-7462},
	shorttitle = {Explainable artificial intelligence},
	url = {https://link.springer.com/10.1007/s10462-021-10088-y},
	doi = {10.1007/s10462-021-10088-y},
	abstract = {Thanks to the exponential growth in computing power and vast amounts of data, artificial intelligence (AI) has witnessed remarkable developments in recent years, enabling it to be ubiquitously adopted in our daily lives. Even though AI-powered systems have brought competitive advantages, the black-box nature makes them lack transparency and prevents them from explaining their decisions. This issue has motivated the introduction of explainable artificial intelligence (XAI), which promotes AI algorithms that can show their internal process and explain how they made decisions. The number of XAI research has increased significantly in recent years, but there lacks a unified and comprehensive review of the latest XAI progress. This review aims to bridge the gap by discovering the critical perspectives of the rapidly growing body of research associated with XAI. After offering the readers a solid XAI background, we analyze and review various XAI methods, which are grouped into (i) pre-modeling explainability, (ii) interpretable model, and (iii) post-modeling explainability. We also pay attention to the current methods that dedicate to interpret and analyze deep learning methods. In addition, we systematically discuss various XAI challenges, such as the trade-off between the performance and the explainability, evaluation methods, security, and policy. Finally, we show the standard approaches that are leveraged to deal with the mentioned challenges.},
	language = {en},
	number = {5},
	urldate = {2024-10-15},
	journal = {Artificial Intelligence Review},
	author = {Minh, Dang and Wang, H. Xiang and Li, Y. Fen and Nguyen, Tan N.},
	month = jun,
	year = {2022},
	keywords = {ungelesen},
	pages = {3503--3568},
	file = {Explainable artificial intelligence a comprehensive review.pdf:D\:\\Dokumente\\05 Uni\\9. Semester\\03 Analyse eines Forschungsthemas\\Literatur\\Explainable artificial intelligence a comprehensive review.pdf:application/pdf},
}

@article{angelov_explainable_2021-1,
	title = {Explainable artificial intelligence: an analytical review},
	volume = {11},
	issn = {1942-4787, 1942-4795},
	shorttitle = {Explainable artificial intelligence},
	url = {https://wires.onlinelibrary.wiley.com/doi/10.1002/widm.1424},
	doi = {10.1002/widm.1424},
	abstract = {This paper provides a brief analytical review of the current state-of-the-art in relation to the explainability of artificial intelligence in the context of recent advances in machine learning and deep learning. The paper starts with a brief historical introduction and a taxonomy, and formulates the main challenges in terms of explainability building on the recently formulated National Institute of Standards four principles of explainability. Recently published methods related to the topic are then critically reviewed and analyzed. Finally, future directions for research are suggested.},
	language = {en},
	number = {5},
	urldate = {2024-10-15},
	journal = {WIREs Data Mining and Knowledge Discovery},
	author = {Angelov, Plamen P. and Soares, Eduardo A. and Jiang, Richard and Arnold, Nicholas I. and Atkinson, Peter M.},
	month = sep,
	year = {2021},
	keywords = {ungelesen},
	pages = {e1424},
	file = {Explainable artificial intelligence an analytical review.pdf:D\:\\Dokumente\\05 Uni\\9. Semester\\03 Analyse eines Forschungsthemas\\Literatur\\Explainable artificial intelligence an analytical review.pdf:application/pdf},
}

@inproceedings{dosilovic_explainable_2018-1,
	address = {Opatija},
	title = {Explainable artificial intelligence: {A} survey},
	isbn = {978-953-233-095-3},
	shorttitle = {Explainable artificial intelligence},
	url = {https://ieeexplore.ieee.org/document/8400040/},
	doi = {10.23919/MIPRO.2018.8400040},
	abstract = {In the last decade, with availability of large datasets and more com puting power, machine learning systems have achieved (super)human performance in a wide variety of tasks. Examples of this rapid development can be seen in image recognition, speech analysis, strategic game planning and many more. The problem with many state-ofthe-art models is a lack of transparency and interpretability. The lack of thereof is a major drawback in many applications, e.g. health care and finance, where rationale for model's decision is a requirement for trust. In the light of these issues, explainable artificial intelligence (XAI) has become an area of interest in research community. This paper summarizes recent developments in XAI in supervised learning, starts a discussion on its connection with artificial general intelligence, and gives proposals for further research directions.},
	language = {en},
	urldate = {2024-10-15},
	booktitle = {2018 41st {International} {Convention} on {Information} and {Communication} {Technology}, {Electronics} and {Microelectronics} ({MIPRO})},
	publisher = {IEEE},
	author = {Dosilovic, Filip Karlo and Brcic, Mario and Hlupic, Nikica},
	month = may,
	year = {2018},
	keywords = {ungelesen},
	pages = {0210--0215},
	file = {Explainable_artificial_intelligence_A_survey.pdf:D\:\\Dokumente\\05 Uni\\9. Semester\\03 Analyse eines Forschungsthemas\\Literatur\\Explainable_artificial_intelligence_A_survey.pdf:application/pdf},
}

@book{romanova_gnn_2023,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {{GNN} {Graph} {Classification} {Method} to {Discover} {Climate} {Change} {Patterns}},
	volume = {14257},
	copyright = {https://www.springernature.com/gp/researchers/text-and-data-mining},
	isbn = {978-3-031-44215-5 978-3-031-44216-2},
	shorttitle = {Artificial {Neural} {Networks} and {Machine} {Learning} – {ICANN} 2023},
	url = {https://link.springer.com/10.1007/978-3-031-44216-2},
	language = {en},
	urldate = {2024-10-15},
	publisher = {Springer Nature Switzerland},
	editor = {Romanova, Alex},
	year = {2023},
	doi = {10.1007/978-3-031-44216-2},
	keywords = {ungelesen, 388},
	file = {GNN Graph Classification Method to Discover Climate Change Patterns.pdf:D\:\\Dokumente\\05 Uni\\9. Semester\\03 Analyse eines Forschungsthemas\\Literatur\\GNN Graph Classification Method to Discover Climate Change Patterns.pdf:application/pdf},
}

@incollection{getoor_graphical_2007-1,
	title = {Graphical {Models} in a {Nutshell}},
	isbn = {978-0-262-25623-0},
	url = {https://direct.mit.edu/books/book/3811/chapter/125067/Graphical-Models-in-a-Nutshell},
	language = {en},
	urldate = {2024-10-15},
	booktitle = {Introduction to {Statistical} {Relational} {Learning}},
	publisher = {The MIT Press},
	author = {Koller, Daphne and Friedman, Nir and Getoor, Lise and Taskar, Ben},
	editor = {Getoor, Lise and Taskar, Ben},
	month = aug,
	year = {2007},
	doi = {10.7551/mitpress/7432.003.0004},
	pages = {13--56},
	file = {Graphical Models in a Nutshell.pdf:D\:\\Dokumente\\05 Uni\\9. Semester\\03 Analyse eines Forschungsthemas\\Literatur\\Graphical Models in a Nutshell.pdf:application/pdf},
}

@inproceedings{he_improve_2022-1,
	title = {Improve emotional speech synthesis quality by learning explicit and implicit representations with semi-supervised training},
	url = {https://www.isca-archive.org/interspeech_2022/he22d_interspeech.html},
	doi = {10.21437/Interspeech.2022-11336},
	abstract = {Due to the lack of high-quality emotional speech synthesis datasets, the naturalness and expressiveness of synthesized speech are still lacking in order to achieve human-like communication. And existing emotional speech synthesis system usually extracts emotional information only from reference audio and ignores sentiment information implicit in the text. Therefore, we propose a novel model to improve emotional speech synthesis quality by learning explicit and implicit representations with semi-supervised learning. In addition to explicit emotional representations from reference audio, we propose an implicit emotion representations learning method based on graph neural network, considering dependency relations of a sentence and text sentiment classification (TSC) task. For the lack of emotion-annotated datasets, we leverage large amounts of expressive datasets to reinforce training the proposed model with semi-supervised learning. Experiments show that the proposed method can improve the naturalness and expressiveness of synthetic speech and is better than the baseline model.},
	language = {en},
	urldate = {2024-10-15},
	booktitle = {Interspeech 2022},
	publisher = {ISCA},
	author = {He, Jiaxu and Gong, Cheng and Wang, Longbiao and Jin, Di and Wang, Xiaobao and Xu, Junhai and Dang, Jianwu},
	month = sep,
	year = {2022},
	keywords = {ungelesen},
	pages = {5538--5542},
	file = {Improve emotional speech synthesis quality by learning explicit and implicit.pdf:D\:\\Dokumente\\05 Uni\\9. Semester\\03 Analyse eines Forschungsthemas\\Literatur\\Improve emotional speech synthesis quality by learning explicit and implicit.pdf:application/pdf},
}

@book{mantoro_neural_2021-1,
	address = {Cham},
	series = {Communications in {Computer} and {Information} {Science}},
	title = {Neural {Information} {Processing}: 28th {International} {Conference}, {ICONIP} 2021, {Sanur}, {Bali}, {Indonesia}, {December} 8–12, 2021, {Proceedings}, {Part} {V}},
	volume = {1516},
	copyright = {https://www.springer.com/tdm},
	isbn = {978-3-030-92306-8 978-3-030-92307-5},
	shorttitle = {Neural {Information} {Processing}},
	url = {https://link.springer.com/10.1007/978-3-030-92307-5},
	language = {en},
	urldate = {2024-10-15},
	publisher = {Springer International Publishing},
	editor = {Mantoro, Teddy and Lee, Minho and Ayu, Media Anugerah and Wong, Kok Wai and Hidayanto, Achmad Nizar},
	year = {2021},
	doi = {10.1007/978-3-030-92307-5},
	keywords = {ungelesen},
	file = {Know-GNN An Explainable Knowledge-Guided Graph Neural Network for Fraud Detection.pdf:D\:\\Dokumente\\05 Uni\\9. Semester\\03 Analyse eines Forschungsthemas\\Literatur\\Know-GNN An Explainable Knowledge-Guided Graph Neural Network for Fraud Detection.pdf:application/pdf},
}

@article{wei_neural_2024-1,
	title = {Neural {Architecture} {Search} for {GNN}-{Based} {Graph} {Classification}},
	volume = {42},
	issn = {1046-8188, 1558-2868},
	url = {https://dl.acm.org/doi/10.1145/3584945},
	doi = {10.1145/3584945},
	abstract = {Graph classification is an important problem with applications across many domains, for which graph neural networks (GNNs) have been state-of-the-art (SOTA) methods. In the literature, to adopt GNNs for the graph classification task, there are two groups of methods: global pooling and hierarchical pooling. The global pooling methods obtain the graph representation vectors by globally pooling all of the node embeddings together at the end of several GNN layers, whereas the hierarchical pooling methods provide one extra pooling operation between the GNN layers to extract hierarchical information and improve the graph representations. Both global and hierarchical pooling methods are effective in different scenarios. Due to highly diverse applications, it is challenging to design data-specific pooling methods with human expertise. To address this problem, we propose PAS (Pooling Architecture Search) to design adaptive pooling architectures by using the neural architecture search (NAS). To enable the search space design, we propose a unified pooling framework consisting of four modules: Aggregation, Pooling, Readout, and Merge. Two variants, PAS-G and PAS-NE, are provided to design the pooling operations in different scales. A set of candidate operations is designed in the search space using this framework. Then, existing human-designed pooling methods, including global and hierarchical ones, can be incorporated. To enable efficient search, a coarsening strategy is developed to continuously relax the search space, and then a differentiable search method can be adopted.
            
              We conduct extensive experiments on six real-world datasets, including the large-scale datasets MR and ogbg-molhiv. Experimental results in this article demonstrate the effectiveness and efficiency of the proposed PAS in designing the pooling architectures for graph classification. The Top-1 performance on two Open Graph Benchmark (OGB) datasets
              
                1
              
              further indicates the utility of PAS when facing diverse realistic data. The implementation of PAS is available at: https://github.com/AutoML-Research/PAS.},
	language = {en},
	number = {1},
	urldate = {2024-10-15},
	journal = {ACM Transactions on Information Systems},
	author = {Wei, Lanning and Zhao, Huan and He, Zhiqiang and Yao, Quanming},
	month = jan,
	year = {2024},
	keywords = {ungelesen},
	pages = {1--29},
	file = {Neural Architecture Search for GNN-Based Graph Classification.pdf:D\:\\Dokumente\\05 Uni\\9. Semester\\03 Analyse eines Forschungsthemas\\Literatur\\Neural Architecture Search for GNN-Based Graph Classification.pdf:application/pdf},
}

@article{yuan_explainability_nodate-1,
	title = {On {Explainability} of {Graph} {Neural} {Networks} via {Subgraph} {Explorations}},
	abstract = {We consider the problem of explaining the predictions of graph neural networks (GNNs), which otherwise are considered as black boxes. Existing methods invariably focus on explaining the importance of graph nodes or edges but ignore the substructures of graphs, which are more intuitive and human-intelligible. In this work, we propose a novel method, known as SubgraphX, to explain GNNs by identifying important subgraphs. Given a trained GNN model and an input graph, our SubgraphX explains its predictions by efﬁciently exploring different subgraphs with Monte Carlo tree search. To make the tree search more effective, we propose to use Shapley values as a measure of subgraph importance, which can also capture the interactions among different subgraphs. To expedite computations, we propose efﬁcient approximation schemes to compute Shapley values for graph data. Our work represents the ﬁrst attempt to explain GNNs via identifying subgraphs explicitly and directly. Experimental results show that our SubgraphX achieves signiﬁcantly improved explanations, while keeping computations at a reasonable level.},
	language = {en},
	author = {Yuan, Hao and Yu, Haiyang and Wang, Jie and Li, Kang and Ji, Shuiwang},
	keywords = {ungelesen},
	file = {On Explainability of Graph Neural Networks via Subgraph Explorations.pdf:D\:\\Dokumente\\05 Uni\\9. Semester\\03 Analyse eines Forschungsthemas\\Literatur\\On Explainability of Graph Neural Networks via Subgraph Explorations.pdf:application/pdf},
}

@article{veyrin-forrer_gnn_2024-1,
	title = {On {GNN} explainability with activation rules},
	volume = {38},
	issn = {1384-5810, 1573-756X},
	url = {https://link.springer.com/10.1007/s10618-022-00870-z},
	doi = {10.1007/s10618-022-00870-z},
	abstract = {GNNs are powerful models based on node representation learning that perform particularly well in many machine learning problems related to graphs. The major obstacle to the deployment of GNNs is mostly a problem of societal acceptability and trustworthiness, properties which require making explicit the internal functioning of such models. Here, we propose to mine activation rules in the hidden layers to understand how the GNNs perceive the world. The problem is not to discover activation rules that are individually highly discriminating for an output of the model. Instead, the challenge is to provide a small set of rules that cover all input graphs. To this end, we introduce the subjective activation pattern domain. We deﬁne an effective and principled algorithm to enumerate activations rules in each hidden layer. The proposed approach for quantifying the interest of these rules is rooted in information theory and is able to account for background knowledge on the input graph data. The activation rules can then be redescribed thanks to pattern languages involving interpretable features. We show that the activation rules provide insights on the characteristics used by the GNN to classify the graphs. Especially, this allows to identify the hidden features built by the GNN through its different layers. Also, these rules can subsequently be used for explaining GNN decisions. Experiments on both synthetic and real-life datasets show highly competitive performance, with up to 200\% improvement in ﬁdelity on explaining graph classiﬁcation over the SOTA methods.},
	language = {en},
	number = {5},
	urldate = {2024-10-15},
	journal = {Data Mining and Knowledge Discovery},
	author = {Veyrin-Forrer, Luca and Kamal, Ataollah and Duffner, Stefan and Plantevit, Marc and Robardet, Céline},
	month = sep,
	year = {2024},
	keywords = {ungelesen},
	pages = {3227--3261},
	file = {On GNN explainability with activation rules.pdf:D\:\\Dokumente\\05 Uni\\9. Semester\\03 Analyse eines Forschungsthemas\\Literatur\\On GNN explainability with activation rules.pdf:application/pdf},
}

@inproceedings{dai_towards_2021-1,
	address = {Virtual Event Queensland Australia},
	title = {Towards {Self}-{Explainable} {Graph} {Neural} {Network}},
	isbn = {978-1-4503-8446-9},
	url = {https://dl.acm.org/doi/10.1145/3459637.3482306},
	doi = {10.1145/3459637.3482306},
	abstract = {Graph Neural Networks (GNNs), which generalize the deep neural networks to graph-structured data, have achieved great success in modeling graphs. However, as an extension of deep learning for graphs, GNNs lack explainability, which largely limits their adoption in scenarios that demand the transparency of models. Though many efforts are taken to improve the explainability of deep learning, they mainly focus on i.i.d data, which cannot be directly applied to explain the predictions of GNNs because GNNs utilize both node features and graph topology to make predictions. There are only very few work on the explainability of GNNs and they focus on post-hoc explanations. Since post-hoc explanations are not directly obtained from the GNNs, they can be biased and misrepresent the true explanations. Therefore, in this paper, we study a novel problem of self-explainable GNNs which can simultaneously give predictions and explanations. We propose a new framework which can find 𝐾-nearest labeled nodes for each unlabeled node to give explainable node classification, where nearest labeled nodes are found by interpretable similarity module in terms of both node similarity and local structure similarity. Extensive experiments on real-world and synthetic datasets demonstrate the effectiveness of the proposed framework for explainable node classification.},
	language = {en},
	urldate = {2024-10-15},
	booktitle = {Proceedings of the 30th {ACM} {International} {Conference} on {Information} \& {Knowledge} {Management}},
	publisher = {ACM},
	author = {Dai, Enyan and Wang, Suhang},
	month = oct,
	year = {2021},
	keywords = {gelesen},
	pages = {302--311},
	file = {Towards Self-Explainable Graph Neural Network.pdf:D\:\\Dokumente\\05 Uni\\9. Semester\\03 Analyse eines Forschungsthemas\\Literatur\\Towards Self-Explainable Graph Neural Network.pdf:application/pdf},
}

@article{singh_boosting_2019,
	title = {{BOOSTING} {ROBUSTNESS} {CERTIFICATION} {OF} {NEURAL} {NETWORKS}},
	abstract = {We present a novel approach for the certiﬁcation of neural networks against adversarial perturbations which combines scalable overapproximation methods with precise (mixed integer) linear programming. This results in signiﬁcantly better precision than state-of-the-art veriﬁers on challenging feedforward and convolutional neural networks with piecewise linear activation functions.},
	language = {en},
	author = {Singh, Gagandeep and Gehr, Timon},
	year = {2019},
	keywords = {gelesen},
	file = {1421_boosting_robustness_certificat.pdf:D\:\\Dokumente\\05 Uni\\9. Semester\\03 Analyse eines Forschungsthemas\\Literatur\\Proposed\\1421_boosting_robustness_certificat.pdf:application/pdf},
}

@inproceedings{gehr_ai2_2018,
	address = {San Francisco, CA},
	title = {{AI2}: {Safety} and {Robustness} {Certification} of {Neural} {Networks} with {Abstract} {Interpretation}},
	isbn = {978-1-5386-4353-2},
	shorttitle = {{AI2}},
	url = {https://ieeexplore.ieee.org/document/8418593/},
	doi = {10.1109/SP.2018.00058},
	abstract = {We present AI2, the ﬁrst sound and scalable analyzer for deep neural networks. Based on overapproximation, AI2 can automatically prove safety properties (e.g., robustness) of realistic neural networks (e.g., convolutional neural networks). The key insight behind AI2 is to phrase reasoning about safety and robustness of neural networks in terms of classic abstract interpretation, enabling us to leverage decades of advances in that area. Concretely, we introduce abstract transformers that capture the behavior of fully connected and convolutional neural network layers with rectiﬁed linear unit activations (ReLU), as well as max pooling layers. This allows us to handle real-world neural networks, which are often built out of those types of layers. We present a complete implementation of AI2 together with an extensive evaluation on 20 neural networks. Our results demonstrate that: (i) AI2 is precise enough to prove useful speciﬁcations (e.g., robustness), (ii) AI2 can be used to certify the effectiveness of state-of-the-art defenses for neural networks, (iii) AI2 is signiﬁcantly faster than existing analyzers based on symbolic analysis, which often take hours to verify simple fully connected networks, and (iv) AI2 can handle deep convolutional networks, which are beyond the reach of existing methods.},
	language = {en},
	urldate = {2024-10-16},
	booktitle = {2018 {IEEE} {Symposium} on {Security} and {Privacy} ({SP})},
	publisher = {IEEE},
	author = {Gehr, Timon and Mirman, Matthew and Drachsler-Cohen, Dana and Tsankov, Petar and Chaudhuri, Swarat and Vechev, Martin},
	month = may,
	year = {2018},
	pages = {3--18},
	file = {AI2_Safety_and_Robustness_Certification_of_Neural_Networks_with_Abstract_Interpretation.pdf:D\:\\Dokumente\\05 Uni\\9. Semester\\03 Analyse eines Forschungsthemas\\Literatur\\Proposed\\AI2_Safety_and_Robustness_Certification_of_Neural_Networks_with_Abstract_Interpretation.pdf:application/pdf},
}

@inproceedings{sikdar_attributed_2022,
	address = {Virtual Event AZ USA},
	title = {Attributed {Graph} {Modeling} with {Vertex} {Replacement} {Grammars}},
	isbn = {978-1-4503-9132-0},
	url = {https://dl.acm.org/doi/10.1145/3488560.3498492},
	doi = {10.1145/3488560.3498492},
	abstract = {Recent work at the intersection of formal language theory and graph theory has explored graph grammars for graph modeling. However, existing models and formalisms can only operate on homogeneous (i.e., untyped or unattributed) graphs. We relax this restriction and introduce the Attributed Vertex Replacement Grammar (AVRG), which can be efficiently extracted from heterogeneous (i.e., typed, colored, or attributed) graphs. Unlike current state-ofthe-art methods, which train enormous models over complicated deep neural architectures, the AVRG model is unsupervised and interpretable. It is based on context-free string grammars and works by encoding graph rewriting rules into a graph grammar containing graphlets and instructions on how they fit together. We show that the AVRG can encode succinct models of input graphs yet faithfully preserve their structure and assortativity properties. Experiments on large real-world datasets show that graphs generated from the AVRG model exhibit substructures and attribute configurations that match those found in the input networks.},
	language = {en},
	urldate = {2024-10-16},
	booktitle = {Proceedings of the {Fifteenth} {ACM} {International} {Conference} on {Web} {Search} and {Data} {Mining}},
	publisher = {ACM},
	author = {Sikdar, Satyaki and Shah, Neil and Weninger, Tim},
	month = feb,
	year = {2022},
	keywords = {gelesen},
	pages = {928--936},
	file = {Attributed Graph Modeling with Vertex Replacement Grammars.pdf:D\:\\Dokumente\\05 Uni\\9. Semester\\03 Analyse eines Forschungsthemas\\Literatur\\Proposed\\Attributed Graph Modeling with Vertex Replacement Grammars.pdf:application/pdf},
}

@article{jeon_pl4xgl_2024,
	title = {{PL4XGL}: {A} {Programming} {Language} {Approach} to {Explainable} {Graph} {Learning}},
	volume = {8},
	issn = {2475-1421},
	shorttitle = {{PL4XGL}},
	url = {https://dl.acm.org/doi/10.1145/3656464},
	doi = {10.1145/3656464},
	abstract = {MINSEOK JEON, Korea University, Republic of Korea JIHYEOK PARK, Korea University, Republic of Korea HAKJOO OH, Korea University, Republic of Korea In this article, we present a new, language-based approach to explainable graph learning. Though graph neural networks (GNNs) have shown impressive performance in various graph learning tasks, they have severe limitations in explainability, hindering their use in decision-critical applications. To address these limitations, several GNN explanation techniques have been proposed using a post-hoc explanation approach providing subgraphs as explanations for classiﬁcation results. Unfortunately, however, they have two fundamental drawbacks in terms of 1) additional explanation costs and 2) the correctness of the explanations. This paper aims to address these problems by developing a new graph-learning method based on programming language techniques. Our key idea is two-fold: 1) designing a graph description language (GDL) to explain the classiﬁcation results and 2) developing a new GDL-based interpretable classiﬁcation model instead of GNN-based models. Our graph-learning model, called PL4XGL, consists of a set of candidate GDL programs with labels and quality scores. For a given graph component, it searches the best GDL program describing the component and provides the corresponding label as the classiﬁcation result and the program as the explanation. In our approach, learning from data is formulated as a program-synthesis problem, and we present top-down and bottom-up algorithms for synthesizing GDL programs from training data. Evaluation using widely-used datasets demonstrates that PL4XGL produces high-quality explanations that outperform those produced by the state-of-the-art GNN explanation technique, SubgraphX. We also show that PL4XGL achieves competitive classiﬁcation accuracy comparable to popular GNN models. CCS Concepts: • Software and its engineering → Domain speciﬁc languages.},
	language = {en},
	number = {PLDI},
	urldate = {2024-10-16},
	journal = {Proceedings of the ACM on Programming Languages},
	author = {Jeon, Minseok and Park, Jihyeok and Oh, Hakjoo},
	month = jun,
	year = {2024},
	keywords = {gelesen},
	pages = {2148--2173},
	file = {PL4XGL A Programming Language Approach to Explainable.pdf:D\:\\Dokumente\\05 Uni\\9. Semester\\03 Analyse eines Forschungsthemas\\Literatur\\Proposed\\PL4XGL A Programming Language Approach to Explainable.pdf:application/pdf},
}

@misc{mao_position_2024,
	title = {Position: {Graph} {Foundation} {Models} are {Already} {Here}},
	shorttitle = {Position},
	url = {http://arxiv.org/abs/2402.02216},
	abstract = {Graph Foundation Models (GFMs) are emerging as a significant research topic in the graph domain, aiming to develop graph models trained on extensive and diverse data to enhance their applicability across various tasks and domains. Developing GFMs presents unique challenges over traditional Graph Neural Networks (GNNs), which are typically trained from scratch for specific tasks on particular datasets The primary challenge in constructing GFMs lies in effectively leveraging vast and diverse graph data to achieve positive transfer. Drawing inspiration from existing foundation models in the CV and NLP domains, we propose a novel perspective for the GFM development by advocating for a “graph vocabulary”, in which the basic transferable units underlying graphs encode the invariance on graphs. We ground the graph vocabulary construction from essential aspects including network analysis, expressiveness, and stability. Such a vocabulary perspective can potentially advance the future GFM design in line with the neural scaling laws. All relevant resources for GFMs design can be found at here.},
	language = {en},
	urldate = {2024-10-16},
	publisher = {arXiv},
	author = {Mao, Haitao and Chen, Zhikai and Tang, Wenzhuo and Zhao, Jianan and Ma, Yao and Zhao, Tong and Shah, Neil and Galkin, Mikhail and Tang, Jiliang},
	month = may,
	year = {2024},
	note = {arXiv:2402.02216 [cs]},
	keywords = {gelesen, Computer Science - Machine Learning},
	annote = {Comment: 23 pages, 2 figures},
	file = {Position Graph Foundation Models are Already Here.pdf:D\:\\Dokumente\\05 Uni\\9. Semester\\03 Analyse eines Forschungsthemas\\Literatur\\Proposed\\Position Graph Foundation Models are Already Here.pdf:application/pdf},
}

@book{mantoro_neural_2021-2,
	address = {Cham},
	series = {Communications in {Computer} and {Information} {Science}},
	title = {Neural {Information} {Processing}: 28th {International} {Conference}, {ICONIP} 2021, {Sanur}, {Bali}, {Indonesia}, {December} 8–12, 2021, {Proceedings}, {Part} {V}},
	volume = {1516},
	copyright = {https://www.springer.com/tdm},
	isbn = {978-3-030-92306-8 978-3-030-92307-5},
	shorttitle = {Neural {Information} {Processing}},
	url = {https://link.springer.com/10.1007/978-3-030-92307-5},
	language = {en},
	urldate = {2024-10-24},
	publisher = {Springer International Publishing},
	editor = {Mantoro, Teddy and Lee, Minho and Ayu, Media Anugerah and Wong, Kok Wai and Hidayanto, Achmad Nizar},
	year = {2021},
	doi = {10.1007/978-3-030-92307-5},
	file = {Mantoro et al. - 2021 - Neural Information Processing 28th International .pdf:C\:\\Users\\julia\\Zotero\\storage\\8Q2NXUXI\\Mantoro et al. - 2021 - Neural Information Processing 28th International .pdf:application/pdf},
}

@inproceedings{sikdar_attributed_2022-1,
	address = {Virtual Event AZ USA},
	title = {Attributed {Graph} {Modeling} with {Vertex} {Replacement} {Grammars}},
	isbn = {978-1-4503-9132-0},
	url = {https://dl.acm.org/doi/10.1145/3488560.3498492},
	doi = {10.1145/3488560.3498492},
	abstract = {Recent work at the intersection of formal language theory and graph theory has explored graph grammars for graph modeling. However, existing models and formalisms can only operate on homogeneous (i.e., untyped or unattributed) graphs. We relax this restriction and introduce the Attributed Vertex Replacement Grammar (AVRG), which can be efficiently extracted from heterogeneous (i.e., typed, colored, or attributed) graphs. Unlike current state-ofthe-art methods, which train enormous models over complicated deep neural architectures, the AVRG model is unsupervised and interpretable. It is based on context-free string grammars and works by encoding graph rewriting rules into a graph grammar containing graphlets and instructions on how they fit together. We show that the AVRG can encode succinct models of input graphs yet faithfully preserve their structure and assortativity properties. Experiments on large real-world datasets show that graphs generated from the AVRG model exhibit substructures and attribute configurations that match those found in the input networks.},
	language = {en},
	urldate = {2024-10-24},
	booktitle = {Proceedings of the {Fifteenth} {ACM} {International} {Conference} on {Web} {Search} and {Data} {Mining}},
	publisher = {ACM},
	author = {Sikdar, Satyaki and Shah, Neil and Weninger, Tim},
	month = feb,
	year = {2022},
	pages = {928--936},
	file = {Sikdar et al. - 2022 - Attributed Graph Modeling with Vertex Replacement .pdf:C\:\\Users\\julia\\Zotero\\storage\\QR9DIJYY\\Sikdar et al. - 2022 - Attributed Graph Modeling with Vertex Replacement .pdf:application/pdf},
}

@book{heckel_graph_2020,
	address = {Cham},
	title = {Graph {Transformation} for {Software} {Engineers}: {With} {Applications} to {Model}-{Based} {Development} and {Domain}-{Specific} {Language} {Engineering}},
	copyright = {http://www.springer.com/tdm},
	isbn = {978-3-030-43915-6 978-3-030-43916-3},
	shorttitle = {Graph {Transformation} for {Software} {Engineers}},
	url = {http://link.springer.com/10.1007/978-3-030-43916-3},
	language = {en},
	urldate = {2024-12-04},
	publisher = {Springer International Publishing},
	author = {Heckel, Reiko and Taentzer, Gabriele},
	year = {2020},
	doi = {10.1007/978-3-030-43916-3},
	keywords = {gelesen},
	file = {978-3-030-43916-3.pdf:D\:\\Dokumente\\05 Uni\\9. Semester\\03 Analyse eines Forschungsthemas\\Literatur\\Kernels\\978-3-030-43916-3.pdf:application/pdf},
}

@article{borgwardt_graph_2020,
	title = {Graph {Kernels}: {State}-of-the-{Art} and {Future} {Challenges}},
	volume = {13},
	issn = {1935-8237, 1935-8245},
	shorttitle = {Graph {Kernels}},
	url = {http://arxiv.org/abs/2011.03854},
	doi = {10.1561/2200000076},
	abstract = {Graph-structured data are an integral part of many application domains, including chemoinformatics, computational biology, neuroimaging, and social network analysis. Over the last two decades, numerous graph kernels, i.e. kernel functions between graphs, have been proposed to solve the problem of assessing the similarity between graphs, thereby making it possible to perform predictions in both classiﬁcation and regression settings. This manuscript provides a review of existing graph kernels, their applications, software plus data resources, and an empirical comparison of state-of-the-art graph kernels.},
	language = {en},
	number = {5-6},
	urldate = {2024-12-04},
	journal = {Foundations and Trends® in Machine Learning},
	author = {Borgwardt, Karsten and Ghisu, Elisabetta and Llinares-López, Felipe and O'Bray, Leslie and Rieck, Bastian},
	year = {2020},
	note = {arXiv:2011.03854 [cs]},
	keywords = {gelesen, Computer Science - Machine Learning, Statistics - Machine Learning},
	pages = {531--712},
	annote = {Comment: Accepted by Foundations and Trends in Machine Learning, 2020},
	file = {2011.03854v2.pdf:D\:\\Dokumente\\05 Uni\\9. Semester\\03 Analyse eines Forschungsthemas\\Literatur\\Kernels\\2011.03854v2.pdf:application/pdf},
}

@article{kriege_survey_2020,
	title = {A survey on graph kernels},
	volume = {5},
	issn = {2364-8228},
	url = {https://appliednetsci.springeropen.com/articles/10.1007/s41109-019-0195-3},
	doi = {10.1007/s41109-019-0195-3},
	abstract = {Graph kernels have become an established and widely-used technique for solving classification tasks on graphs. This survey gives a comprehensive overview of techniques for kernel-based graph classification developed in the past 15 years. We describe and categorize graph kernels based on properties inherent to their design, such as the nature of their extracted graph features, their method of computation and their applicability to problems in practice. In an extensive experimental evaluation, we study the classification accuracy of a large suite of graph kernels on established benchmarks as well as new datasets. We compare the performance of popular kernels with several baseline methods and study the effect of applying a Gaussian RBF kernel to the metric induced by a graph kernel. In doing so, we find that simple baselines become competitive after this transformation on some datasets. Moreover, we study the extent to which existing graph kernels agree in their predictions (and prediction errors) and obtain a data-driven categorization of kernels as result. Finally, based on our experimental results, we derive a practitioner’s guide to kernel-based graph classification.},
	language = {en},
	number = {1},
	urldate = {2024-12-04},
	journal = {Applied Network Science},
	author = {Kriege, Nils M. and Johansson, Fredrik D. and Morris, Christopher},
	month = dec,
	year = {2020},
	keywords = {gelesen},
	pages = {6},
	file = {s41109-019-0195-3.pdf:D\:\\Dokumente\\05 Uni\\9. Semester\\03 Analyse eines Forschungsthemas\\Literatur\\Kernels\\s41109-019-0195-3.pdf:application/pdf},
}

@article{nikolentzos_graph_2021,
	title = {Graph {Kernels}: {A} {Survey}},
	volume = {72},
	issn = {1076-9757},
	shorttitle = {Graph {Kernels}},
	url = {http://jair.org/index.php/jair/article/view/13225},
	doi = {10.1613/jair.1.13225},
	abstract = {Graph kernels have attracted a lot of attention during the last decade, and have evolved into a rapidly developing branch of learning on structured data. During the past 20 years, the considerable research activity that occurred in the ﬁeld resulted in the development of dozens of graph kernels, each focusing on speciﬁc structural properties of graphs. Graph kernels have proven successful in a wide range of domains, ranging from social networks to bioinformatics. The goal of this survey is to provide a unifying view of the literature on graph kernels. In particular, we present a comprehensive overview of a wide range of graph kernels. Furthermore, we perform an experimental evaluation of several of those kernels on publicly available datasets, and provide a comparative study. Finally, we discuss key applications of graph kernels, and outline some challenges that remain to be addressed.},
	language = {en},
	urldate = {2024-12-04},
	journal = {Journal of Artificial Intelligence Research},
	author = {Nikolentzos, Giannis and Siglidis, Giannis and Vazirgiannis, Michalis},
	month = nov,
	year = {2021},
	keywords = {gelesen},
	pages = {943--1027},
	file = {sminton,+13225-Article+(PDF)-28923-1-11-20211118.pdf:D\:\\Dokumente\\05 Uni\\9. Semester\\03 Analyse eines Forschungsthemas\\Literatur\\Kernels\\sminton,+13225-Article+(PDF)-28923-1-11-20211118.pdf:application/pdf},
}

@book{pulkki_communication_nodate,
	title = {Communication {Acoustics}: {An} {Introduction} to {Speech}, {Audio} and {Psychoacoustics}},
	author = {Pulkki, Ville and Karjalainen, Matti},
}

@misc{sanchez-lengeling_gentle_2021,
	title = {A {Gentle} {Introduction} to {Graph} {Neural} {Networks}},
	publisher = {Distill},
	author = {Sanchez-Lengeling, Benjamin and Reif, Emily and Pearce, Adam and Wiltschko, Alexander B.},
	year = {2021},
	keywords = {gelesen},
}

@misc{daigavane_understanding_2021,
	title = {Understanding {Convolutions} on {Graphs}},
	publisher = {Distill},
	author = {Daigavane, Ameya and Ravindran, Balaraman and Aggarwal, Gaurav},
	year = {2021},
	keywords = {gelesen},
}

@misc{ying_gnnexplainer_2019,
	title = {{GNNExplainer}: {Generating} {Explanations} for {Graph} {Neural} {Networks}},
	shorttitle = {{GNNExplainer}},
	url = {http://arxiv.org/abs/1903.03894},
	doi = {10.48550/arXiv.1903.03894},
	abstract = {Graph Neural Networks (GNNs) are a powerful tool for machine learning on graphs. GNNs combine node feature information with the graph structure by recursively passing neural messages along edges of the input graph. However, incorporating both graph structure and feature information leads to complex models and explaining predictions made by GNNs remains unsolved. Here we propose GNNEXPLAINER, the ﬁrst general, model-agnostic approach for providing interpretable explanations for predictions of any GNN-based model on any graph-based machine learning task. Given an instance, GNNEXPLAINER identiﬁes a compact subgraph structure and a small subset of node features that have a crucial role in GNN’s prediction. Further, GNNEXPLAINER can generate consistent and concise explanations for an entire class of instances. We formulate GNNEXPLAINER as an optimization task that maximizes the mutual information between a GNN’s prediction and distribution of possible subgraph structures. Experiments on synthetic and real-world graphs show that our approach can identify important graph structures as well as node features, and outperforms alternative baseline approaches by up to 43.0\% in explanation accuracy. GNNEXPLAINER provides a variety of beneﬁts, from the ability to visualize semantically relevant structures to interpretability, to giving insights into errors of faulty GNNs.},
	language = {en},
	urldate = {2025-01-19},
	publisher = {arXiv},
	author = {Ying, Rex and Bourgeois, Dylan and You, Jiaxuan and Zitnik, Marinka and Leskovec, Jure},
	month = nov,
	year = {2019},
	note = {arXiv:1903.03894 [cs]},
	keywords = {gelesen, Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {GNNExplainer.pdf:D\:\\Dokumente\\05 Uni\\9. Semester\\03 Analyse eines Forschungsthemas\\Literatur\\GNNExplainer.pdf:application/pdf},
}

@article{noauthor_notitle_nodate-2,
}

@misc{kwiatkowska_when_2023,
	title = {When to {Trust} {AI}: {Advances} and {Challenges} for {Certification} of {Neural} {Networks}},
	shorttitle = {When to {Trust} {AI}},
	url = {http://arxiv.org/abs/2309.11196},
	doi = {10.48550/arXiv.2309.11196},
	abstract = {Artificial intelligence (AI) has been advancing at a fast pace and it is now poised for deployment in a wide range of applications, such as autonomous systems, medical diagnosis and natural language processing. Early adoption of AI technology for real-world applications has not been without problems, particularly for neural networks, which may be unstable and susceptible to adversarial examples. In the longer term, appropriate safety assurance techniques need to be developed to reduce potential harm due to avoidable system failures and ensure trustworthiness. Focusing on certification and explainability, this paper provides an overview of techniques that have been developed to ensure safety of AI decisions and discusses future challenges.},
	language = {en},
	urldate = {2025-01-25},
	publisher = {arXiv},
	author = {Kwiatkowska, Marta and Zhang, Xiyue},
	month = sep,
	year = {2023},
	note = {arXiv:2309.11196 [cs]},
	keywords = {ungelesen, Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Cryptography and Security, Computer Science - Symbolic Computation},
	file = {When to trust ai.pdf:D\:\\Dokumente\\05 Uni\\9. Semester\\03 Analyse eines Forschungsthemas\\Literatur\\When to trust ai.pdf:application/pdf},
}

@article{blosser_consumer_2024,
	title = {A consumer perspective of {AI} certification – the current certification landscape, consumer approval and directions for future research},
	volume = {58},
	copyright = {https://www.emerald.com/insight/site-policies},
	issn = {0309-0566, 0309-0566},
	url = {https://www.emerald.com/insight/content/doi/10.1108/EJM-01-2023-0009/full/html},
	doi = {10.1108/EJM-01-2023-0009},
	abstract = {Purpose – In spite of the merits of artiﬁcial intelligence (AI) in marketing and social media, harm to consumers has prompted calls for AI auditing/certiﬁcation. Understanding consumers’ approval of AI certiﬁcation entities is vital for its effectiveness and companies’ choice of certiﬁcation. This study aims to generate important insights into the consumer perspective of AI certiﬁcations and stimulate future research.},
	language = {en},
	number = {2},
	urldate = {2025-01-25},
	journal = {European Journal of Marketing},
	author = {Blösser, Myrthe and Weihrauch, Andrea},
	month = feb,
	year = {2024},
	keywords = {ungelesen},
	pages = {441--470},
	file = {Certification_Consumer_Perspective.pdf:D\:\\Dokumente\\05 Uni\\9. Semester\\03 Analyse eines Forschungsthemas\\Literatur\\Certification_Consumer_Perspective.pdf:application/pdf},
}

@misc{shen_natural_2018,
	title = {Natural {TTS} {Synthesis} by {Conditioning} {WaveNet} on {Mel} {Spectrogram} {Predictions}},
	url = {http://arxiv.org/abs/1712.05884},
	doi = {10.48550/arXiv.1712.05884},
	abstract = {This paper describes Tacotron 2, a neural network architecture for speech synthesis directly from text. The system is composed of a recurrent sequence-to-sequence feature prediction network that maps character embeddings to mel-scale spectrograms, followed by a modiﬁed WaveNet model acting as a vocoder to synthesize time-domain waveforms from those spectrograms. Our model achieves a mean opinion score (MOS) of 4.53 comparable to a MOS of 4.58 for professionally recorded speech. To validate our design choices, we present ablation studies of key components of our system and evaluate the impact of using mel spectrograms as the conditioning input to WaveNet instead of linguistic, duration, and F0 features. We further show that using this compact acoustic intermediate representation allows for a signiﬁcant reduction in the size of the WaveNet architecture.},
	language = {en},
	urldate = {2025-01-27},
	publisher = {arXiv},
	author = {Shen, Jonathan and Pang, Ruoming and Weiss, Ron J. and Schuster, Mike and Jaitly, Navdeep and Yang, Zongheng and Chen, Zhifeng and Zhang, Yu and Wang, Yuxuan and Skerry-Ryan, R. J. and Saurous, Rif A. and Agiomyrgiannakis, Yannis and Wu, Yonghui},
	month = feb,
	year = {2018},
	note = {arXiv:1712.05884 [cs]},
	keywords = {Computer Science - Computation and Language},
	annote = {Comment: Accepted to ICASSP 2018},
	file = {Shen et al. - 2018 - Natural TTS Synthesis by Conditioning WaveNet on M.pdf:C\:\\Users\\julia\\Zotero\\storage\\2LW7CI6R\\Shen et al. - 2018 - Natural TTS Synthesis by Conditioning WaveNet on M.pdf:application/pdf},
}

@misc{cho_multi-speaker_2021,
	title = {Multi-speaker {Emotional} {Text}-to-speech {Synthesizer}},
	url = {http://arxiv.org/abs/2112.03557},
	doi = {10.48550/arXiv.2112.03557},
	abstract = {We present a methodology to train our multi-speaker emotional text-to-speech synthesizer that can express speech for 10 speakers’ 7 different emotions. All silences from audio samples are removed prior to learning. This results in fast learning by our model. Curriculum learning is applied to train our model efﬁciently. Our model is ﬁrst trained with a large single-speaker neutral dataset, and then trained with neutral speech from all speakers. Finally, our model is trained using datasets of emotional speech from all speakers. In each stage, training samples of each speaker-emotion pair have equal probability to appear in mini-batches. Through this procedure, our model can synthesize speech for all targeted speakers and emotions. Our synthesized audio sets are available on our web page.},
	language = {en},
	urldate = {2025-01-27},
	publisher = {arXiv},
	author = {Cho, Sungjae and Lee, Soo-Young},
	month = dec,
	year = {2021},
	note = {arXiv:2112.03557 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Neural and Evolutionary Computing},
	annote = {Comment: 2 pages; Published in the Proceedings of Interspeech 2021; Presented in Show and Tell; For the published paper, see https://www.isca-speech.org/archive/interspeech\_2021/cho21\_interspeech.html},
	file = {Cho und Lee - 2021 - Multi-speaker Emotional Text-to-speech Synthesizer.pdf:C\:\\Users\\julia\\Zotero\\storage\\6WK6W66T\\Cho und Lee - 2021 - Multi-speaker Emotional Text-to-speech Synthesizer.pdf:application/pdf},
}

@misc{diatlova_emospeech_2023,
	title = {{EmoSpeech}: {Guiding} {FastSpeech2} {Towards} {Emotional} {Text} to {Speech}},
	shorttitle = {{EmoSpeech}},
	url = {http://arxiv.org/abs/2307.00024},
	doi = {10.48550/arXiv.2307.00024},
	abstract = {State-of-the-art speech synthesis models try to get as close as possible to the human voice. Hence, modelling emotions is an essential part of Text-To-Speech (TTS) research. In our work, we selected FastSpeech2 as the starting point and proposed a series of modifications for synthesizing emotional speech. According to automatic and human evaluation, our model, EmoSpeech, surpasses existing models regarding both MOS score and emotion recognition accuracy in generated speech. We provided a detailed ablation study for every extension to FastSpeech2 architecture that forms EmoSpeech. The uneven distribution of emotions in the text is crucial for better, synthesized speech and intonation perception. Our model includes a conditioning mechanism that effectively handles this issue by allowing emotions to contribute to each phone with varying intensity levels. The human assessment indicates that proposed modifications generate audio with higher MOS and emotional expressiveness.},
	language = {en},
	urldate = {2025-01-27},
	publisher = {arXiv},
	author = {Diatlova, Daria and Shutov, Vitaly},
	month = jun,
	year = {2023},
	note = {arXiv:2307.00024 [eess]},
	keywords = {Computer Science - Machine Learning, Computer Science - Sound, Electrical Engineering and Systems Science - Audio and Speech Processing},
	file = {Diatlova und Shutov - 2023 - EmoSpeech Guiding FastSpeech2 Towards Emotional T.pdf:C\:\\Users\\julia\\Zotero\\storage\\HCCS5UKP\\Diatlova und Shutov - 2023 - EmoSpeech Guiding FastSpeech2 Towards Emotional T.pdf:application/pdf},
}

@article{cahn_generation_2000,
	title = {The {Generation} of {A} ect in {Synthesized} {Speech}},
	abstract = {Synthesized speech need not be expressionless. By identifying the e ects of emotion on speech and choosing an appropriate representation, the generation of a ect is possible and can become computational. I describe a program {\textbar} the A ect Editor {\textbar} which implements an acoustical model of speech and generates synthesizer instructions to produce the desired a ect. The authenticity of the a ect is limited by synthesizer capabilities and by incomplete descriptions of the acoustical and perceptual phenomena. However, the results of an experiment show that this approach produces synthesized speech with recognizable, and, at times, natural, a ect.},
	language = {en},
	author = {Cahn, Janet E},
	year = {2000},
	file = {Cahn - The Generation of A ect in Synthesized Speech.pdf:C\:\\Users\\julia\\Zotero\\storage\\MXXFRQD3\\Cahn - The Generation of A ect in Synthesized Speech.pdf:application/pdf},
}

@misc{gtts,
	author = {Pierre Nicholas Durette},
	title = {gTTS: Google Text-to-Speech},
	year = {2019},
	howpublished = {\url{https://github.com/pndurette/gTTS}},
	note = {Version 2.2.3}
}

@article{van2016wavenet,
	title={Wavenet: A generative model for raw audio},
	author={Van Den Oord, Aaron and Dieleman, Sander and Zen, Heiga and Simonyan, Karen and Vinyals, Oriol and Graves, Alex and Kalchbrenner, Nal and Senior, Andrew and Kavukcuoglu, Koray and others},
	journal={arXiv preprint arXiv:1609.03499},
	volume={12},
	year={2016}
}

@article{casanova2024xtts,
	title={XTTS: a Massively Multilingual Zero-Shot Text-to-Speech Model},
	author={Casanova, Edresson and Davis, Kelly and G{\"o}lge, Eren and G{\"o}knar, G{\"o}rkem and Gulea, Iulian and Hart, Logan and Aljafari, Aya and Meyer, Joshua and Morais, Reuben and Olayemi, Samuel and others},
	journal={arXiv preprint arXiv:2406.04904},
	year={2024}
}

@article{zhou2022emotional,
	title={Emotional voice conversion: Theory, databases and ESD},
	author={Zhou, Kun and Sisman, Berrak and Liu, Rui and Li, Haizhou},
	journal={Speech Communication},
	volume={137},
	pages={1--18},
	year={2022},
	publisher={Elsevier}
}

@article{ren2020fastspeech,
	title={Fastspeech 2: Fast and high-quality end-to-end text to speech},
	author={Ren, Yi and Hu, Chenxu and Tan, Xu and Qin, Tao and Zhao, Sheng and Zhao, Zhou and Liu, Tie-Yan},
	journal={arXiv preprint arXiv:2006.04558},
	year={2020}
}

@ARTICLE{griffin1984lim,
	author={Griffin, D. and Jae Lim},
	journal={IEEE Transactions on Acoustics, Speech, and Signal Processing}, 
	title={Signal estimation from modified short-time Fourier transform}, 
	year={1984},
	volume={32},
	number={2},
	pages={236-243},
	keywords={Fourier transforms;Iterative algorithms;Discrete Fourier transforms;Speech enhancement;Hardware;Signal processing;Degradation;Estimation theory;Monitoring;Sampling methods},
	doi={10.1109/TASSP.1984.1164317}
}

@article{allen1977short,
	title={Short term spectral analysis, synthesis, and modification by discrete Fourier transform},
	author={Allen, Jonathan},
	journal={IEEE transactions on acoustics, speech, and signal processing},
	volume={25},
	number={3},
	pages={235--238},
	year={1977},
	publisher={IEEE}
}

@article{betker2023better,
	title={Better speech synthesis through scaling},
	author={Betker, James},
	journal={arXiv preprint arXiv:2305.07243},
	year={2023}
}

@inproceedings{NIPS2017_7a98af17,
	author = {van den Oord, Aaron and Vinyals, Oriol and kavukcuoglu, koray},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
	pages = {},
	publisher = {Curran Associates, Inc.},
	title = {Neural Discrete Representation Learning},
	url = {https://proceedings.neurips.cc/paper_files/paper/2017/file/7a98af17e63a0ac09ce2e96d03992fbc-Paper.pdf},
	volume = {30},
	year = {2017}
}

@article{kong2020hifi,
	title={Hifi-gan: Generative adversarial networks for efficient and high fidelity speech synthesis},
	author={Kong, Jungil and Kim, Jaehyeon and Bae, Jaekyoung},
	journal={Advances in neural information processing systems},
	volume={33},
	pages={17022--17033},
	year={2020}
}

@article{radford2019language,
	title={Language models are unsupervised multitask learners},
	author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
	journal={OpenAI blog},
	volume={1},
	number={8},
	pages={9},
	year={2019}
}

@inproceedings{kameoka2018stargan,
	title={Stargan-vc: Non-parallel many-to-many voice conversion using star generative adversarial networks},
	author={Kameoka, Hirokazu and Kaneko, Takuhiro and Tanaka, Kou and Hojo, Nobukatsu},
	booktitle={2018 IEEE Spoken Language Technology Workshop (SLT)},
	pages={266--273},
	year={2018},
	organization={IEEE}
}

@inproceedings{kaneko2018cyclegan,
	title={Cyclegan-vc: Non-parallel voice conversion using cycle-consistent adversarial networks},
	author={Kaneko, Takuhiro and Kameoka, Hirokazu},
	booktitle={2018 26th European Signal Processing Conference (EUSIPCO)},
	pages={2100--2104},
	year={2018},
	organization={IEEE}
}

@article{goodfellow2020generative,
	title={Generative adversarial networks},
	author={Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
	journal={Communications of the ACM},
	volume={63},
	number={11},
	pages={139--144},
	year={2020},
	publisher={ACM New York, NY, USA}
}

@inproceedings{McFee2015librosaAA,
	title={librosa: Audio and Music Signal Analysis in Python},
	author={Brian McFee and Colin Raffel and Dawen Liang and Daniel P. W. Ellis and Matt McVicar and Eric Battenberg and Oriol Nieto},
	booktitle={SciPy},
	year={2015},
	url={https://api.semanticscholar.org/CorpusID:33504}
}
